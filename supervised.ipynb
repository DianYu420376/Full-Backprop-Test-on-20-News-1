{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Training a fully supervised one layer NMF on 20 news group dataset\n",
    "'''\n",
    "# define some global variables\n",
    "save_PATH = 'saved_data/'\n",
    "save_filename = 'supervised_one_layer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "# import package\n",
    "%load_ext memory_profiler\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import Ipynb_importer\n",
    "from deep_nmf import Deep_NMF, Energy_Loss_Func, Fro_Norm\n",
    "from writer import Writer\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from auxillary_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the dataset for twenty news\n",
    "from twenty_news_group_data_loading import data, Y, target,L20, L50, L90, sparsedata_cr_entr, sparsedata_L2#, get_whole_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the network \n",
    "m = data.shape[1]\n",
    "k = 20\n",
    "c = 20\n",
    "lambd = 1e-4\n",
    "net = Deep_NMF([m, k], c)\n",
    "loss_func = Energy_Loss_Func(lambd = lambd, classification_type = 'L2')\n",
    "data_input = data*1000\n",
    "dataset = sparsedata_L2(data_input, 1000*Y)\n",
    "criterion = Fro_Norm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try initializing the network with the unsupervised version\n",
    "#A = np.load(save_PATH + '20_news_group_A.npy')\n",
    "#net.lsqnonneglst[0].A.data = torch.from_numpy(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.linear.weight.data = torch.randn(net.linear.weight.data.shape).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training the classifier\n",
      "tensor(8.9547, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(9.4363, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(9.2187, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(9.0418, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(9.0210, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(9.0781, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(9.2136, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(8.8685, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(9.1673, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(9.2372, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(8.9671, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(9.0832, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(9.3886, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(9.2111, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(9.5321, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(8.7915, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(9.1512, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(8.9699, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(9.3230, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(9.3494, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(9.0719, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(9.0445, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(9.3054, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(9.2190, dtype=torch.float64)\n",
      "training the classifier\n",
      "tensor(9.3543, dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-53587c6ff370>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m#train the linear classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mS_lst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'training the classifier'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\Deep NMF\\Code\\Cathy Code\\Full-Backprop-Test-on-20-News-1\\deep_nmf.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mS_lst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlsqnonneglst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m             \u001b[0mS_lst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\Deep NMF\\Code\\Cathy Code\\Full-Backprop-Test-on-20-News-1\\lsqnonneg_module.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mLsqNonnegF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\Deep NMF\\Code\\Cathy Code\\Full-Backprop-Test-on-20-News-1\\lsqnonneg_module.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(ctx, input, A)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# output[i,:] = argmin_{s >= 0} ||X[i,:] - s*A||_F^2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# this is slightly different from what we do in NMF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[1;33m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlsqnonneg_tensor_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[1;31m# normalize the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m#output_sum = torch.sum(output, dim =1) + 1e-10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\Deep NMF\\Code\\Cathy Code\\Full-Backprop-Test-on-20-News-1\\lsqnonneg_module.py\u001b[0m in \u001b[0;36mlsqnonneg_tensor_version\u001b[1;34m(C, D)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnnls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m         \u001b[0mres_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\nnls.py\u001b[0m in \u001b[0;36mnnls\u001b[1;34m(A, b, maxiter)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \"\"\"\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masarray_chkfinite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36masarray_chkfinite\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m   1229\u001b[0m     \"\"\"\n\u001b[0;32m   1230\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1231\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtypecodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'AllFloat'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1232\u001b[0m         raise ValueError(\n\u001b[0;32m   1233\u001b[0m             \"array must not contain infs or NaNs\")\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training process!\n",
    "\n",
    "# setting training parameters\n",
    "batchsize = 40\n",
    "epoch = 4\n",
    "lr_nmf = 1000000\n",
    "lr_cl = 1\n",
    "loss_lst = []\n",
    "history = Writer()\n",
    "# train!\n",
    "for epo in range(epoch):\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size = batchsize, shuffle = True)\n",
    "    total_loss = 0\n",
    "    for (i, (inputs, label)) in enumerate(dataloader):\n",
    "        inputs = inputs.view([inputs.shape[0], inputs.shape[2]])\n",
    "        label = label.view([label.shape[0], -1])\n",
    "        inputs, label = Variable(inputs), Variable(label)\n",
    "        \n",
    "        #train the lsqnonneg layers\n",
    "#         print('training the nmf layer')\n",
    "#         #for k in range(10):\n",
    "#         net.zero_grad()\n",
    "#         S_lst,pred = net(inputs)\n",
    "#         loss = loss_func(inputs, S_lst,list(net.lsqnonneglst.parameters()),pred,label)\n",
    "#         loss.backward()\n",
    "#         loss_lst.append(loss.data)\n",
    "#         total_loss += loss.data\n",
    "#         print(loss.data)\n",
    "#         for A in net.lsqnonneglst.parameters():\n",
    "#             A.data = A.data.sub_(lr_nmf*A.grad.data)\n",
    "#             A.data = A.data.clamp(min = 0)\n",
    "        for A in net.lsqnonneglst.parameters():\n",
    "            A.requires_grad = False\n",
    "        \n",
    "        #train the linear classifier\n",
    "        S_lst, pred = net(inputs)\n",
    "        print('training the classifier')\n",
    "        for k in range(1):\n",
    "            net.zero_grad()\n",
    "            pred = net.linear(S_lst[-1].data)\n",
    "            loss = criterion(pred, label)\n",
    "            loss.backward()\n",
    "            #print(loss.data)\n",
    "            #loss_lst.append(loss.data)\n",
    "            for A in net.linear.parameters():\n",
    "                A.data = A.data.sub_(lr_cl*A.grad.data)\n",
    "        loss1 = loss_func(inputs, S_lst, list(net.lsqnonneglst.parameters()), pred, label)\n",
    "        print(loss1.data)\n",
    "#         for A in net.lsqnonneglst.parameters():\n",
    "#             A.requires_grad = True\n",
    "#         %memit\n",
    "        #while True:\n",
    "            #pass\n",
    "    # should be deleted later on\n",
    "    print('epoch = ', epo, '\\n', total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_lst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 1 tensor(12.6814, dtype=torch.float64)\n",
      "27.797811269760132\n",
      "current at batch: 2 tensor(12.6812, dtype=torch.float64)\n",
      "25.6742844581604\n",
      "current at batch: 3 tensor(12.6807, dtype=torch.float64)\n",
      "25.306217670440674\n",
      "current at batch: 4 tensor(12.6806, dtype=torch.float64)\n",
      "29.324053287506104\n",
      "current at batch: 5 tensor(12.6798, dtype=torch.float64)\n",
      "28.071542739868164\n",
      "current at batch: 6 tensor(12.6794, dtype=torch.float64)\n",
      "24.927058458328247\n",
      "current at batch: 7 tensor(12.6781, dtype=torch.float64)\n",
      "20.392109870910645\n",
      "current at batch: 8 tensor(12.6763, dtype=torch.float64)\n",
      "15.623805522918701\n",
      "current at batch: 9 tensor(12.6733, dtype=torch.float64)\n",
      "13.157130002975464\n",
      "current at batch: 10 tensor(12.6676, dtype=torch.float64)\n",
      "11.220972299575806\n",
      "current at batch: 11 tensor(12.6607, dtype=torch.float64)\n",
      "8.328207731246948\n",
      "current at batch: 12 tensor(12.6470, dtype=torch.float64)\n",
      "6.750073432922363\n",
      "current at batch: 13 tensor(12.6270, dtype=torch.float64)\n",
      "6.984508752822876\n",
      "current at batch: 14 tensor(12.6002, dtype=torch.float64)\n",
      "6.6878437995910645\n",
      "current at batch: 15 tensor(12.5678, dtype=torch.float64)\n",
      "7.453166484832764\n",
      "current at batch: 16 tensor(12.5112, dtype=torch.float64)\n",
      "7.140843868255615\n",
      "current at batch: 17 tensor(12.4189, dtype=torch.float64)\n",
      "5.313577651977539\n",
      "current at batch: 18 tensor(12.3037, dtype=torch.float64)\n",
      "5.288407564163208\n",
      "current at batch: 19 tensor(12.1833, dtype=torch.float64)\n",
      "5.016176700592041\n",
      "current at batch: 20 tensor(11.9253, dtype=torch.float64)\n",
      "5.045920133590698\n",
      "current at batch: 21 tensor(11.6027, dtype=torch.float64)\n",
      "5.078600883483887\n",
      "current at batch: 22 tensor(11.3764, dtype=torch.float64)\n",
      "5.084320545196533\n",
      "current at batch: 23 tensor(11.0580, dtype=torch.float64)\n",
      "5.025112152099609\n",
      "current at batch: 24 tensor(10.6380, dtype=torch.float64)\n",
      "5.093927621841431\n",
      "current at batch: 25 tensor(10.5241, dtype=torch.float64)\n",
      "5.047315835952759\n",
      "current at batch: 26 tensor(10.1396, dtype=torch.float64)\n",
      "5.032040596008301\n",
      "current at batch: 27 tensor(10.0545, dtype=torch.float64)\n",
      "4.968594074249268\n",
      "current at batch: 28 tensor(9.8208, dtype=torch.float64)\n",
      "5.000903367996216\n",
      "current at batch: 29 tensor(10.0978, dtype=torch.float64)\n",
      "5.487433910369873\n",
      "current at batch: 30 tensor(10.0183, dtype=torch.float64)\n",
      "5.121415376663208\n",
      "current at batch: 31 tensor(9.8214, dtype=torch.float64)\n",
      "5.16597843170166\n",
      "current at batch: 32 tensor(9.8668, dtype=torch.float64)\n",
      "5.147755146026611\n",
      "current at batch: 33 tensor(9.7954, dtype=torch.float64)\n",
      "5.749722242355347\n",
      "current at batch: 34 tensor(9.4109, dtype=torch.float64)\n",
      "5.499638319015503\n",
      "current at batch: 35 tensor(9.8100, dtype=torch.float64)\n",
      "5.407814264297485\n",
      "current at batch: 36 tensor(9.8316, dtype=torch.float64)\n",
      "5.46849799156189\n",
      "current at batch: 37 tensor(9.9880, dtype=torch.float64)\n",
      "6.624754905700684\n",
      "current at batch: 38 tensor(9.5891, dtype=torch.float64)\n",
      "6.890530824661255\n",
      "current at batch: 39 tensor(9.8891, dtype=torch.float64)\n",
      "9.54714846611023\n",
      "current at batch: 40 tensor(9.7655, dtype=torch.float64)\n",
      "9.451584100723267\n",
      "current at batch: 41 tensor(9.6714, dtype=torch.float64)\n",
      "11.295321702957153\n",
      "current at batch: 42 tensor(9.8716, dtype=torch.float64)\n",
      "13.437267065048218\n",
      "current at batch: 43 tensor(9.7990, dtype=torch.float64)\n",
      "12.531720876693726\n",
      "current at batch: 44 tensor(9.7849, dtype=torch.float64)\n",
      "13.55537748336792\n",
      "current at batch: 45 tensor(9.9023, dtype=torch.float64)\n",
      "15.244287490844727\n",
      "current at batch: 46 tensor(9.8122, dtype=torch.float64)\n",
      "14.841357469558716\n",
      "current at batch: 47 tensor(9.6666, dtype=torch.float64)\n",
      "15.796275615692139\n",
      "current at batch: 48 tensor(9.7117, dtype=torch.float64)\n",
      "15.282201051712036\n",
      "current at batch: 49 tensor(9.7190, dtype=torch.float64)\n",
      "16.20290184020996\n",
      "current at batch: 50 tensor(9.5287, dtype=torch.float64)\n",
      "15.48391580581665\n",
      "current at batch: 51 tensor(9.6566, dtype=torch.float64)\n",
      "15.422053575515747\n",
      "current at batch: 52 tensor(9.8362, dtype=torch.float64)\n",
      "12.78157377243042\n",
      "current at batch: 53 tensor(9.5665, dtype=torch.float64)\n",
      "12.051634550094604\n",
      "current at batch: 54 tensor(9.7642, dtype=torch.float64)\n",
      "11.657931566238403\n",
      "current at batch: 55 tensor(9.7559, dtype=torch.float64)\n",
      "12.081665277481079\n",
      "current at batch: 56 tensor(9.7826, dtype=torch.float64)\n",
      "12.414664506912231\n",
      "current at batch: 57 tensor(9.5809, dtype=torch.float64)\n",
      "12.547298908233643\n",
      "current at batch: 58 tensor(9.4265, dtype=torch.float64)\n",
      "12.297690153121948\n",
      "current at batch: 59 tensor(10.0082, dtype=torch.float64)\n",
      "13.387186765670776\n",
      "current at batch: 60 tensor(9.5274, dtype=torch.float64)\n",
      "12.002095460891724\n",
      "current at batch: 61 tensor(9.7116, dtype=torch.float64)\n",
      "12.297081708908081\n",
      "current at batch: 62 tensor(9.6219, dtype=torch.float64)\n",
      "14.659478187561035\n",
      "current at batch: 63 tensor(9.6692, dtype=torch.float64)\n",
      "16.716224670410156\n",
      "current at batch: 64 tensor(9.9118, dtype=torch.float64)\n",
      "18.03125262260437\n",
      "current at batch: 65 tensor(9.6274, dtype=torch.float64)\n",
      "17.12653398513794\n",
      "current at batch: 66 tensor(9.6700, dtype=torch.float64)\n",
      "18.233904123306274\n",
      "current at batch: 67 tensor(9.5788, dtype=torch.float64)\n",
      "17.4689724445343\n",
      "current at batch: 68 tensor(9.8825, dtype=torch.float64)\n",
      "18.135596752166748\n",
      "current at batch: 69 tensor(9.8645, dtype=torch.float64)\n",
      "16.87879467010498\n",
      "current at batch: 70 tensor(9.7949, dtype=torch.float64)\n",
      "16.785064697265625\n",
      "current at batch: 71 tensor(9.5366, dtype=torch.float64)\n",
      "15.677518844604492\n",
      "current at batch: 72 tensor(9.6244, dtype=torch.float64)\n",
      "16.045105457305908\n",
      "current at batch: 73 tensor(9.8933, dtype=torch.float64)\n",
      "15.126095533370972\n",
      "current at batch: 74 tensor(9.9553, dtype=torch.float64)\n",
      "11.597364664077759\n",
      "current at batch: 75 tensor(9.7086, dtype=torch.float64)\n",
      "11.23476529121399\n",
      "current at batch: 76 tensor(9.6766, dtype=torch.float64)\n",
      "12.422440767288208\n",
      "current at batch: 77 tensor(9.8094, dtype=torch.float64)\n",
      "13.202680826187134\n",
      "current at batch: 78 tensor(9.7187, dtype=torch.float64)\n",
      "13.073539972305298\n",
      "current at batch: 79 tensor(9.7434, dtype=torch.float64)\n",
      "11.785868406295776\n",
      "current at batch: 80 tensor(9.7681, dtype=torch.float64)\n",
      "13.141879081726074\n",
      "current at batch: 81 tensor(9.9045, dtype=torch.float64)\n",
      "12.928246974945068\n",
      "current at batch: 82 tensor(9.5230, dtype=torch.float64)\n",
      "12.212837219238281\n",
      "current at batch: 83 tensor(9.5710, dtype=torch.float64)\n",
      "15.382587909698486\n",
      "current at batch: 84 tensor(9.4540, dtype=torch.float64)\n",
      "15.359359502792358\n",
      "current at batch: 85 tensor(9.8140, dtype=torch.float64)\n",
      "17.834940433502197\n",
      "current at batch: 86 tensor(9.6063, dtype=torch.float64)\n",
      "16.373558044433594\n",
      "current at batch: 87 tensor(9.7875, dtype=torch.float64)\n",
      "17.620184183120728\n",
      "current at batch: 88 tensor(9.5194, dtype=torch.float64)\n",
      "17.70025634765625\n",
      "current at batch: 89 tensor(9.8958, dtype=torch.float64)\n",
      "16.49506139755249\n",
      "current at batch: 90 tensor(9.9320, dtype=torch.float64)\n",
      "18.766834020614624\n",
      "current at batch: 91 tensor(9.8295, dtype=torch.float64)\n",
      "17.67919635772705\n",
      "current at batch: 92 tensor(9.8338, dtype=torch.float64)\n",
      "17.772093772888184\n",
      "current at batch: 93 tensor(9.5405, dtype=torch.float64)\n",
      "14.29897165298462\n",
      "current at batch: 94 tensor(9.6064, dtype=torch.float64)\n",
      "13.020342350006104\n",
      "current at batch: 95 tensor(9.5835, dtype=torch.float64)\n",
      "12.62106466293335\n",
      "current at batch: 96 tensor(9.6928, dtype=torch.float64)\n",
      "13.079251050949097\n",
      "current at batch: 97 tensor(9.8520, dtype=torch.float64)\n",
      "12.90534234046936\n",
      "current at batch: 98 tensor(9.8738, dtype=torch.float64)\n",
      "12.672332763671875\n",
      "current at batch: 99 tensor(10.2272, dtype=torch.float64)\n",
      "14.40347671508789\n",
      "current at batch: 100 tensor(10.0542, dtype=torch.float64)\n",
      "13.7870614528656\n",
      "current at batch: 101 tensor(9.7372, dtype=torch.float64)\n",
      "13.917200565338135\n",
      "current at batch: 102 tensor(9.6717, dtype=torch.float64)\n",
      "16.764699459075928\n",
      "current at batch: 103 tensor(9.7635, dtype=torch.float64)\n",
      "17.00062084197998\n",
      "current at batch: 104 tensor(9.4636, dtype=torch.float64)\n",
      "14.615190744400024\n",
      "current at batch: 105 tensor(9.8511, dtype=torch.float64)\n",
      "17.15123987197876\n",
      "current at batch: 106 tensor(9.7884, dtype=torch.float64)\n",
      "16.098935842514038\n",
      "current at batch: 107 tensor(9.8578, dtype=torch.float64)\n",
      "17.062453746795654\n",
      "current at batch: 108 tensor(9.7262, dtype=torch.float64)\n",
      "15.578660726547241\n",
      "current at batch: 109 tensor(9.7685, dtype=torch.float64)\n",
      "17.007089614868164\n",
      "current at batch: 110 tensor(9.4674, dtype=torch.float64)\n",
      "16.09075355529785\n",
      "current at batch: 111 tensor(9.7387, dtype=torch.float64)\n",
      "15.045908689498901\n",
      "current at batch: 112 tensor(9.8907, dtype=torch.float64)\n",
      "11.955749988555908\n",
      "current at batch: 113 tensor(9.6555, dtype=torch.float64)\n",
      "13.031019687652588\n",
      "current at batch: 114 tensor(9.8460, dtype=torch.float64)\n",
      "11.949491262435913\n",
      "current at batch: 115 tensor(9.7095, dtype=torch.float64)\n",
      "12.974029064178467\n",
      "current at batch: 116 tensor(9.7651, dtype=torch.float64)\n",
      "12.43025541305542\n",
      "current at batch: 117 tensor(9.7377, dtype=torch.float64)\n",
      "13.578495979309082\n",
      "current at batch: 118 tensor(9.7236, dtype=torch.float64)\n",
      "12.890897512435913\n",
      "current at batch: 119 tensor(9.6825, dtype=torch.float64)\n",
      "14.295042991638184\n",
      "current at batch: 120 tensor(9.8380, dtype=torch.float64)\n",
      "14.458062648773193\n",
      "current at batch: 121 tensor(9.6449, dtype=torch.float64)\n",
      "15.002178192138672\n",
      "current at batch: 122 tensor(9.8690, dtype=torch.float64)\n",
      "18.975433111190796\n",
      "current at batch: 123 tensor(9.5120, dtype=torch.float64)\n",
      "17.431312799453735\n",
      "current at batch: 124 tensor(9.9303, dtype=torch.float64)\n",
      "19.203591346740723\n",
      "current at batch: 125 tensor(9.7605, dtype=torch.float64)\n",
      "18.87624192237854\n",
      "current at batch: 126 tensor(9.7282, dtype=torch.float64)\n",
      "18.296810388565063\n",
      "current at batch: 127 tensor(9.5903, dtype=torch.float64)\n",
      "17.611080169677734\n",
      "current at batch: 128 tensor(9.5389, dtype=torch.float64)\n",
      "17.96152901649475\n",
      "current at batch: 129 tensor(10.0157, dtype=torch.float64)\n",
      "19.92358160018921\n",
      "current at batch: 130 tensor(9.7477, dtype=torch.float64)\n",
      "19.009219646453857\n",
      "current at batch: 131 tensor(9.5241, dtype=torch.float64)\n",
      "17.154342889785767\n",
      "current at batch: 132 tensor(9.6603, dtype=torch.float64)\n",
      "13.696822166442871\n",
      "current at batch: 133 tensor(9.7513, dtype=torch.float64)\n",
      "12.212101221084595\n",
      "current at batch: 134 tensor(9.5400, dtype=torch.float64)\n",
      "12.155012369155884\n",
      "current at batch: 135 tensor(9.7149, dtype=torch.float64)\n",
      "12.704257726669312\n",
      "current at batch: 136 tensor(9.6829, dtype=torch.float64)\n",
      "12.902916193008423\n",
      "current at batch: 137 tensor(9.6157, dtype=torch.float64)\n",
      "12.265116930007935\n",
      "current at batch: 138 tensor(9.7545, dtype=torch.float64)\n",
      "12.906537771224976\n",
      "current at batch: 139 tensor(9.4641, dtype=torch.float64)\n",
      "11.469146013259888\n",
      "current at batch: 140 tensor(9.5532, dtype=torch.float64)\n",
      "13.583653926849365\n",
      "current at batch: 141 tensor(9.4412, dtype=torch.float64)\n",
      "17.870481729507446\n",
      "current at batch: 142 tensor(9.5846, dtype=torch.float64)\n",
      "19.51356863975525\n",
      "current at batch: 143 tensor(9.9398, dtype=torch.float64)\n",
      "21.360283851623535\n",
      "current at batch: 144 tensor(9.5706, dtype=torch.float64)\n",
      "22.648379802703857\n",
      "current at batch: 145 tensor(9.8287, dtype=torch.float64)\n",
      "24.357604265213013\n",
      "current at batch: 146 tensor(9.6118, dtype=torch.float64)\n",
      "22.39740014076233\n",
      "current at batch: 147 tensor(9.8549, dtype=torch.float64)\n",
      "22.902508974075317\n",
      "current at batch: 148 tensor(9.7721, dtype=torch.float64)\n",
      "23.62224769592285\n",
      "current at batch: 149 tensor(9.7580, dtype=torch.float64)\n",
      "23.622733116149902\n",
      "current at batch: 150 tensor(9.8664, dtype=torch.float64)\n",
      "24.6933753490448\n",
      "current at batch: 151 tensor(10.0462, dtype=torch.float64)\n",
      "23.821189641952515\n",
      "current at batch: 152 tensor(9.9806, dtype=torch.float64)\n",
      "24.662819147109985\n",
      "current at batch: 153 tensor(9.6273, dtype=torch.float64)\n",
      "21.41431450843811\n",
      "current at batch: 154 tensor(9.6986, dtype=torch.float64)\n",
      "17.26834201812744\n",
      "current at batch: 155 tensor(9.7432, dtype=torch.float64)\n",
      "19.117874145507812\n",
      "current at batch: 156 tensor(9.4614, dtype=torch.float64)\n",
      "18.449981451034546\n",
      "current at batch: 157 tensor(9.9018, dtype=torch.float64)\n",
      "19.059711933135986\n",
      "current at batch: 158 tensor(9.7290, dtype=torch.float64)\n",
      "19.44968295097351\n",
      "current at batch: 159 tensor(9.9378, dtype=torch.float64)\n",
      "21.82803773880005\n",
      "current at batch: 160 tensor(9.8749, dtype=torch.float64)\n",
      "18.17589521408081\n",
      "current at batch: 161 tensor(9.9101, dtype=torch.float64)\n",
      "19.15606117248535\n",
      "current at batch: 162 tensor(9.4696, dtype=torch.float64)\n",
      "17.59180974960327\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-8776f40ec03b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m        \u001b[1;31m#train the lsqnonneg layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mS_lst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS_lst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlsqnonneglst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\Deep NMF\\Code\\Cathy Code\\Full-Backprop-Test-on-20-News-1\\deep_nmf.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mS_lst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlsqnonneglst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m             \u001b[0mS_lst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\Deep NMF\\Code\\Cathy Code\\Full-Backprop-Test-on-20-News-1\\lsqnonneg_module.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mLsqNonnegF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\Deep NMF\\Code\\Cathy Code\\Full-Backprop-Test-on-20-News-1\\lsqnonneg_module.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(ctx, input, A)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# output[i,:] = argmin_{s >= 0} ||X[i,:] - s*A||_F^2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# this is slightly different from what we do in NMF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[1;33m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlsqnonneg_tensor_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[1;31m# normalize the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m#output_sum = torch.sum(output, dim =1) + 1e-10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\Deep NMF\\Code\\Cathy Code\\Full-Backprop-Test-on-20-News-1\\lsqnonneg_module.py\u001b[0m in \u001b[0;36mlsqnonneg_tensor_version\u001b[1;34m(C, D)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnnls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m         \u001b[0mres_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\nnls.py\u001b[0m in \u001b[0;36mnnls\u001b[1;34m(A, b, maxiter)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_nnls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"too many iterations\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training process!\n",
    "import time\n",
    "# setting training parameters\n",
    "batchsize = 100\n",
    "epoch = 40\n",
    "lr = 5000\n",
    "lr_nmf = 5000\n",
    "lr_cl = 5000\n",
    "loss_lst = []\n",
    "# train!\n",
    "for epo in range(epoch):\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size = batchsize, shuffle = True)\n",
    "    total_loss = 0\n",
    "    for (i, (inputs, label)) in enumerate(dataloader):\n",
    "        t1 = time.time()\n",
    "        inputs = inputs.view([inputs.shape[0], inputs.shape[2]])\n",
    "        label = label.view([label.shape[0], -1])\n",
    "        inputs, label = Variable(inputs), Variable(label)\n",
    "       #train the lsqnonneg layers\n",
    "        net.zero_grad()\n",
    "        S_lst,pred = net(inputs)\n",
    "        loss = loss_func(inputs, S_lst,list(net.lsqnonneglst.parameters()),pred,label)\n",
    "        loss.backward()\n",
    "        loss_lst.append(loss.data)\n",
    "        total_loss += loss.data\n",
    "        print('current at batch:', i+1, loss.data)\n",
    "        t2 = time.time()\n",
    "        print(t2 - t1)\n",
    "        for A in net.parameters():\n",
    "            A.data = A.data.sub_(lr*A.grad.data)\n",
    "        for A in net.lsqnonneglst.parameters():\n",
    "            A.data = A.data.clamp(min = 0)\n",
    "    print('epoch = ', epo, '\\n', total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the data\n",
    "np.savez(save_PATH + save_filename,\n",
    "         param_lst = list(net.parameters()), loss_lst = loss_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_num =  189 \n",
      "\n",
      "current at batch: 0\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Dropbox\\Deep NMF\\Code\\Cathy Code\\Full-Backprop-Test-on-20-News-1\\auxillary_functions.py\u001b[0m in \u001b[0;36mget_whole_output\u001b[1;34m(net, dataset, param_lst)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mtotal_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\Deep NMF\\Code\\Cathy Code\\Full-Backprop-Test-on-20-News-1\\twenty_news_group_data_loading.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.uint16. The only supported types are: double, float, float16, int64, int32, and uint8.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c7eeddd548b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# # Get the whole output of the whole dataset (running forward propagation on the whole dataset)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_whole_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# Get the accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m accuracy = torch.sum(torch.argmax(pred, 1) \n",
      "\u001b[1;32m~\\Dropbox\\Deep NMF\\Code\\Cathy Code\\Full-Backprop-Test-on-20-News-1\\auxillary_functions.py\u001b[0m in \u001b[0;36mget_whole_output\u001b[1;34m(net, dataset, param_lst)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mtotal_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mtotal_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\Deep NMF\\Code\\Cathy Code\\Full-Backprop-Test-on-20-News-1\\twenty_news_group_data_loading.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36mtodense\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    844\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mshares\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    845\u001b[0m         \"\"\"\n\u001b[1;32m--> 846\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    848\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    945\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# plot the loss curve\n",
    "plt.plot(loss_lst)\n",
    "plt.show()\n",
    "# # Get the whole output of the whole dataset (running forward propagation on the whole dataset)\n",
    "S, pred = get_whole_output(net, dataset)\n",
    "# Get the accuracy\n",
    "accuracy = torch.sum(torch.argmax(pred, 1) \n",
    "                      == torch.argmax(torch.from_numpy(Y),1)).float()/len(dataset)\n",
    "# print(accuracy)\n",
    "# # Get the reconstruction error\n",
    "# A_np = net.lsqnonneglst[0].A.data.numpy()\n",
    "# S_np = S.data.numpy()\n",
    "# fro_error, fro_X = calc_reconstruction_error(data_input, A_np, S_np)\n",
    "# print(fro_error/fro_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the data\n",
    "np.savez(save_PATH + save_filename, S = S, pred = pred,\n",
    "         param_lst = list(net.parameters()), loss_lst = loss_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
