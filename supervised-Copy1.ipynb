{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Training a fully supervised one layer NMF on 20 news group dataset\n",
    "'''\n",
    "# define some global variables\n",
    "save_PATH = 'saved_data/'\n",
    "save_filename = 'supervised_one_layer_pinv_run2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "# import package\n",
    "%load_ext memory_profiler\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import Ipynb_importer\n",
    "from deep_nmf import Deep_NMF, Energy_Loss_Func, Fro_Norm\n",
    "from writer import Writer\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from auxillary_functions import *\n",
    "from pinv import PinvF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset for twenty news\n",
    "from twenty_news_group_data_loading import data, Y, target,L20, L50, L90, sparsedata_cr_entr, sparsedata_L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network \n",
    "m = data.shape[1]\n",
    "k = 20\n",
    "c = 20\n",
    "lambd = 1e-4\n",
    "net = Deep_NMF([m, k])\n",
    "loss_func = Energy_Loss_Func(lambd = lambd, classification_type = 'L2')\n",
    "data_input = data*1000\n",
    "dataset = sparsedata_L2(data_input, 1000*Y)\n",
    "criterion = Fro_Norm()\n",
    "pinv = PinvF.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try initializing the network with the unsupervised version\n",
    "#A = np.load(save_PATH + '20_news_group_A.npy')\n",
    "#net.lsqnonneglst[0].A.data = torch.from_numpy(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 1 tensor(10.0113, dtype=torch.float64)\n",
      "9.946182012557983\n",
      "current at batch: 2 tensor(9.1165, dtype=torch.float64)\n",
      "6.87500524520874\n",
      "current at batch: 3 tensor(9.3729, dtype=torch.float64)\n",
      "6.507164716720581\n",
      "current at batch: 4 tensor(9.5512, dtype=torch.float64)\n",
      "6.8034987449646\n",
      "current at batch: 5 tensor(9.3837, dtype=torch.float64)\n",
      "6.655431270599365\n",
      "current at batch: 6 tensor(9.2185, dtype=torch.float64)\n",
      "6.187631368637085\n",
      "current at batch: 7 tensor(9.1113, dtype=torch.float64)\n",
      "5.296981334686279\n",
      "current at batch: 8 tensor(9.0991, dtype=torch.float64)\n",
      "6.1240363121032715\n",
      "current at batch: 9 tensor(9.2288, dtype=torch.float64)\n",
      "6.406382322311401\n",
      "current at batch: 10 tensor(9.1096, dtype=torch.float64)\n",
      "6.867548942565918\n",
      "current at batch: 11 tensor(9.3226, dtype=torch.float64)\n",
      "6.955356121063232\n",
      "current at batch: 12 tensor(8.8933, dtype=torch.float64)\n",
      "6.5497214794158936\n",
      "current at batch: 13 tensor(8.8484, dtype=torch.float64)\n",
      "6.064436912536621\n",
      "current at batch: 14 tensor(9.2586, dtype=torch.float64)\n",
      "6.125134468078613\n",
      "current at batch: 15 tensor(8.4938, dtype=torch.float64)\n",
      "5.7032470703125\n",
      "current at batch: 16 tensor(9.3746, dtype=torch.float64)\n",
      "6.0518105030059814\n",
      "current at batch: 17 tensor(9.2645, dtype=torch.float64)\n",
      "5.952411651611328\n",
      "current at batch: 18 tensor(8.7484, dtype=torch.float64)\n",
      "5.39850640296936\n",
      "current at batch: 19 tensor(8.5880, dtype=torch.float64)\n",
      "5.471860647201538\n",
      "current at batch: 20 tensor(8.9280, dtype=torch.float64)\n",
      "6.407982349395752\n",
      "current at batch: 21 tensor(9.3217, dtype=torch.float64)\n",
      "5.592403888702393\n",
      "current at batch: 22 tensor(8.8805, dtype=torch.float64)\n",
      "5.403261423110962\n",
      "current at batch: 23 tensor(8.7393, dtype=torch.float64)\n",
      "5.318106651306152\n",
      "current at batch: 24 tensor(9.0641, dtype=torch.float64)\n",
      "5.546431064605713\n",
      "current at batch: 25 tensor(8.9542, dtype=torch.float64)\n",
      "5.518683671951294\n",
      "current at batch: 26 tensor(8.6868, dtype=torch.float64)\n",
      "5.546987056732178\n",
      "current at batch: 27 tensor(8.4452, dtype=torch.float64)\n",
      "5.489290475845337\n",
      "current at batch: 28 tensor(9.0999, dtype=torch.float64)\n",
      "5.296999931335449\n",
      "current at batch: 29 tensor(8.8784, dtype=torch.float64)\n",
      "5.67198920249939\n",
      "current at batch: 30 tensor(9.3562, dtype=torch.float64)\n",
      "5.140732049942017\n",
      "current at batch: 31 tensor(8.3157, dtype=torch.float64)\n",
      "5.333349227905273\n",
      "current at batch: 32 tensor(8.8787, dtype=torch.float64)\n",
      "5.584497451782227\n",
      "current at batch: 33 tensor(9.1570, dtype=torch.float64)\n",
      "5.2317914962768555\n",
      "current at batch: 34 tensor(8.9137, dtype=torch.float64)\n",
      "5.343862056732178\n",
      "current at batch: 35 tensor(9.1001, dtype=torch.float64)\n",
      "5.406358242034912\n",
      "current at batch: 36 tensor(8.5934, dtype=torch.float64)\n",
      "5.167622327804565\n",
      "current at batch: 37 tensor(8.5956, dtype=torch.float64)\n",
      "5.679847240447998\n",
      "current at batch: 38 tensor(8.4149, dtype=torch.float64)\n",
      "5.737217664718628\n",
      "current at batch: 39 tensor(8.3810, dtype=torch.float64)\n",
      "5.416285991668701\n",
      "current at batch: 40 tensor(8.3584, dtype=torch.float64)\n",
      "5.492565631866455\n",
      "current at batch: 41 tensor(8.3232, dtype=torch.float64)\n",
      "5.20524787902832\n",
      "current at batch: 42 tensor(8.6296, dtype=torch.float64)\n",
      "5.387587547302246\n",
      "current at batch: 43 tensor(8.5365, dtype=torch.float64)\n",
      "5.869265794754028\n",
      "current at batch: 44 tensor(8.1061, dtype=torch.float64)\n",
      "5.332988500595093\n",
      "current at batch: 45 tensor(8.4926, dtype=torch.float64)\n",
      "5.647873640060425\n",
      "current at batch: 46 tensor(8.3280, dtype=torch.float64)\n",
      "5.046988010406494\n",
      "current at batch: 47 tensor(9.0575, dtype=torch.float64)\n",
      "6.1251232624053955\n",
      "current at batch: 48 tensor(8.5306, dtype=torch.float64)\n",
      "6.031387805938721\n",
      "current at batch: 49 tensor(8.5306, dtype=torch.float64)\n",
      "5.970853328704834\n",
      "current at batch: 50 tensor(8.5457, dtype=torch.float64)\n",
      "5.265735626220703\n",
      "current at batch: 51 tensor(9.0788, dtype=torch.float64)\n",
      "5.068432807922363\n",
      "current at batch: 52 tensor(8.8785, dtype=torch.float64)\n",
      "5.615267515182495\n",
      "current at batch: 53 tensor(8.4164, dtype=torch.float64)\n",
      "5.178503513336182\n",
      "current at batch: 54 tensor(8.2158, dtype=torch.float64)\n",
      "5.062602519989014\n",
      "current at batch: 55 tensor(8.4190, dtype=torch.float64)\n",
      "4.9041218757629395\n",
      "current at batch: 56 tensor(7.9115, dtype=torch.float64)\n",
      "5.262454271316528\n",
      "current at batch: 57 tensor(8.4116, dtype=torch.float64)\n",
      "4.9375998973846436\n",
      "current at batch: 58 tensor(8.6562, dtype=torch.float64)\n",
      "5.275494575500488\n",
      "current at batch: 59 tensor(7.9102, dtype=torch.float64)\n",
      "4.835426092147827\n",
      "current at batch: 60 tensor(7.9933, dtype=torch.float64)\n",
      "5.286226987838745\n",
      "current at batch: 61 tensor(8.0692, dtype=torch.float64)\n",
      "5.218853950500488\n",
      "current at batch: 62 tensor(8.3010, dtype=torch.float64)\n",
      "5.508214712142944\n",
      "current at batch: 63 tensor(8.0995, dtype=torch.float64)\n",
      "5.403318643569946\n",
      "current at batch: 64 tensor(8.1362, dtype=torch.float64)\n",
      "5.034835338592529\n",
      "current at batch: 65 tensor(7.8834, dtype=torch.float64)\n",
      "5.196831464767456\n",
      "current at batch: 66 tensor(8.7534, dtype=torch.float64)\n",
      "6.062716007232666\n",
      "current at batch: 67 tensor(8.0887, dtype=torch.float64)\n",
      "6.36730694770813\n",
      "current at batch: 68 tensor(8.3200, dtype=torch.float64)\n",
      "6.634358882904053\n",
      "current at batch: 69 tensor(7.9399, dtype=torch.float64)\n",
      "7.8773276805877686\n",
      "current at batch: 70 tensor(7.8833, dtype=torch.float64)\n",
      "9.368285417556763\n",
      "current at batch: 71 tensor(8.0867, dtype=torch.float64)\n",
      "7.9814772605896\n",
      "current at batch: 72 tensor(8.2269, dtype=torch.float64)\n",
      "6.2129528522491455\n",
      "current at batch: 73 tensor(7.7158, dtype=torch.float64)\n",
      "7.378841876983643\n",
      "current at batch: 74 tensor(7.9002, dtype=torch.float64)\n",
      "7.338377952575684\n",
      "current at batch: 75 tensor(8.0295, dtype=torch.float64)\n",
      "5.386358261108398\n",
      "current at batch: 76 tensor(7.9107, dtype=torch.float64)\n",
      "5.124583721160889\n",
      "current at batch: 77 tensor(7.5843, dtype=torch.float64)\n",
      "5.651212930679321\n",
      "current at batch: 78 tensor(8.1083, dtype=torch.float64)\n",
      "5.867695331573486\n",
      "current at batch: 79 tensor(7.4389, dtype=torch.float64)\n",
      "5.730343341827393\n",
      "current at batch: 80 tensor(7.5620, dtype=torch.float64)\n",
      "6.56264591217041\n",
      "current at batch: 81 tensor(7.7541, dtype=torch.float64)\n",
      "6.4532554149627686\n",
      "current at batch: 82 tensor(7.9970, dtype=torch.float64)\n",
      "7.531404256820679\n",
      "current at batch: 83 tensor(7.5385, dtype=torch.float64)\n",
      "8.794922113418579\n",
      "current at batch: 84 tensor(8.2796, dtype=torch.float64)\n",
      "8.007368326187134\n",
      "current at batch: 85 tensor(7.6289, dtype=torch.float64)\n",
      "6.25291633605957\n",
      "current at batch: 86 tensor(7.5811, dtype=torch.float64)\n",
      "6.34155535697937\n",
      "current at batch: 87 tensor(7.7569, dtype=torch.float64)\n",
      "5.772697925567627\n",
      "current at batch: 88 tensor(7.6325, dtype=torch.float64)\n",
      "5.765742301940918\n",
      "current at batch: 89 tensor(7.3717, dtype=torch.float64)\n",
      "5.689321041107178\n",
      "current at batch: 90 tensor(7.2554, dtype=torch.float64)\n",
      "5.859529972076416\n",
      "current at batch: 91 tensor(7.2546, dtype=torch.float64)\n",
      "5.906408309936523\n",
      "current at batch: 92 tensor(7.4338, dtype=torch.float64)\n",
      "6.299772024154663\n",
      "current at batch: 93 tensor(7.8623, dtype=torch.float64)\n",
      "6.32459568977356\n",
      "current at batch: 94 tensor(7.2269, dtype=torch.float64)\n",
      "6.443156003952026\n",
      "current at batch: 95 tensor(7.2223, dtype=torch.float64)\n",
      "5.986292123794556\n",
      "current at batch: 96 tensor(7.0704, dtype=torch.float64)\n",
      "6.520107746124268\n",
      "current at batch: 97 tensor(6.6469, dtype=torch.float64)\n",
      "6.687679290771484\n",
      "current at batch: 98 tensor(7.2756, dtype=torch.float64)\n",
      "6.391624212265015\n",
      "current at batch: 99 tensor(7.8238, dtype=torch.float64)\n",
      "6.187665224075317\n",
      "current at batch: 100 tensor(7.8664, dtype=torch.float64)\n",
      "6.465130805969238\n",
      "current at batch: 101 tensor(7.1077, dtype=torch.float64)\n",
      "6.9054999351501465\n",
      "current at batch: 102 tensor(7.8211, dtype=torch.float64)\n",
      "6.515810489654541\n",
      "current at batch: 103 tensor(7.3338, dtype=torch.float64)\n",
      "6.638488531112671\n",
      "current at batch: 104 tensor(7.1783, dtype=torch.float64)\n",
      "7.112112283706665\n",
      "current at batch: 105 tensor(7.2396, dtype=torch.float64)\n",
      "6.962411165237427\n",
      "current at batch: 106 tensor(7.7987, dtype=torch.float64)\n",
      "6.7231903076171875\n",
      "current at batch: 107 tensor(7.5893, dtype=torch.float64)\n",
      "7.965299606323242\n",
      "current at batch: 108 tensor(7.5181, dtype=torch.float64)\n",
      "8.81688666343689\n",
      "current at batch: 109 tensor(6.5159, dtype=torch.float64)\n",
      "8.464268445968628\n",
      "current at batch: 110 tensor(7.1930, dtype=torch.float64)\n",
      "10.573823928833008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 111 tensor(7.7038, dtype=torch.float64)\n",
      "9.091758966445923\n",
      "current at batch: 112 tensor(7.8617, dtype=torch.float64)\n",
      "7.6046624183654785\n",
      "current at batch: 113 tensor(7.0926, dtype=torch.float64)\n",
      "8.104194164276123\n",
      "current at batch: 114 tensor(7.7580, dtype=torch.float64)\n",
      "9.484628200531006\n",
      "current at batch: 115 tensor(7.1492, dtype=torch.float64)\n",
      "9.56841254234314\n",
      "current at batch: 116 tensor(7.5726, dtype=torch.float64)\n",
      "7.689764499664307\n",
      "current at batch: 117 tensor(7.3642, dtype=torch.float64)\n",
      "8.293324708938599\n",
      "current at batch: 118 tensor(7.3929, dtype=torch.float64)\n",
      "9.625255584716797\n",
      "current at batch: 119 tensor(7.5185, dtype=torch.float64)\n",
      "8.77468729019165\n",
      "current at batch: 120 tensor(7.2447, dtype=torch.float64)\n",
      "6.853615999221802\n",
      "current at batch: 121 tensor(7.2560, dtype=torch.float64)\n",
      "8.103506565093994\n",
      "current at batch: 122 tensor(7.3591, dtype=torch.float64)\n",
      "9.453375816345215\n",
      "current at batch: 123 tensor(7.3371, dtype=torch.float64)\n",
      "8.859471559524536\n",
      "current at batch: 124 tensor(7.4636, dtype=torch.float64)\n",
      "6.734566688537598\n",
      "current at batch: 125 tensor(7.5111, dtype=torch.float64)\n",
      "9.074307441711426\n",
      "current at batch: 126 tensor(7.5935, dtype=torch.float64)\n",
      "8.440288543701172\n",
      "current at batch: 127 tensor(7.4697, dtype=torch.float64)\n",
      "7.0783302783966064\n",
      "current at batch: 128 tensor(7.4586, dtype=torch.float64)\n",
      "9.65697431564331\n",
      "current at batch: 129 tensor(7.5391, dtype=torch.float64)\n",
      "9.791361808776855\n",
      "current at batch: 130 tensor(7.5655, dtype=torch.float64)\n",
      "7.800476312637329\n",
      "current at batch: 131 tensor(6.5296, dtype=torch.float64)\n",
      "8.689072132110596\n",
      "current at batch: 132 tensor(7.5810, dtype=torch.float64)\n",
      "7.859408140182495\n",
      "current at batch: 133 tensor(6.6905, dtype=torch.float64)\n",
      "8.03261947631836\n",
      "current at batch: 134 tensor(7.0245, dtype=torch.float64)\n",
      "7.7608911991119385\n",
      "current at batch: 135 tensor(7.1373, dtype=torch.float64)\n",
      "6.927199363708496\n",
      "current at batch: 136 tensor(7.7407, dtype=torch.float64)\n",
      "6.535111427307129\n",
      "current at batch: 137 tensor(7.1490, dtype=torch.float64)\n",
      "6.656381368637085\n",
      "current at batch: 138 tensor(7.3593, dtype=torch.float64)\n",
      "6.4237847328186035\n",
      "current at batch: 139 tensor(6.8839, dtype=torch.float64)\n",
      "6.504796981811523\n",
      "current at batch: 140 tensor(7.6781, dtype=torch.float64)\n",
      "6.265754222869873\n",
      "current at batch: 141 tensor(7.1930, dtype=torch.float64)\n",
      "6.026450872421265\n",
      "current at batch: 142 tensor(7.3744, dtype=torch.float64)\n",
      "6.531384229660034\n",
      "current at batch: 143 tensor(7.4717, dtype=torch.float64)\n",
      "6.511251926422119\n",
      "current at batch: 144 tensor(7.4972, dtype=torch.float64)\n",
      "6.140756368637085\n",
      "current at batch: 145 tensor(7.5620, dtype=torch.float64)\n",
      "5.859199285507202\n",
      "current at batch: 146 tensor(6.6503, dtype=torch.float64)\n",
      "6.1407482624053955\n",
      "current at batch: 147 tensor(7.6468, dtype=torch.float64)\n",
      "6.661144733428955\n",
      "current at batch: 148 tensor(7.1888, dtype=torch.float64)\n",
      "6.093872785568237\n",
      "current at batch: 149 tensor(7.2816, dtype=torch.float64)\n",
      "6.600093126296997\n",
      "current at batch: 150 tensor(7.0667, dtype=torch.float64)\n",
      "6.312628984451294\n",
      "current at batch: 151 tensor(7.2659, dtype=torch.float64)\n",
      "6.422004461288452\n",
      "current at batch: 152 tensor(7.3492, dtype=torch.float64)\n",
      "6.335908889770508\n",
      "current at batch: 153 tensor(7.4164, dtype=torch.float64)\n",
      "6.3126301765441895\n",
      "current at batch: 154 tensor(7.4084, dtype=torch.float64)\n",
      "6.207981586456299\n",
      "current at batch: 155 tensor(7.6873, dtype=torch.float64)\n",
      "6.687630891799927\n",
      "current at batch: 156 tensor(7.2262, dtype=torch.float64)\n",
      "5.984497785568237\n",
      "current at batch: 157 tensor(7.3735, dtype=torch.float64)\n",
      "6.5144312381744385\n",
      "current at batch: 158 tensor(6.9880, dtype=torch.float64)\n",
      "6.037166118621826\n",
      "current at batch: 159 tensor(7.4359, dtype=torch.float64)\n",
      "6.973026275634766\n",
      "current at batch: 160 tensor(7.5757, dtype=torch.float64)\n",
      "6.609512567520142\n",
      "current at batch: 161 tensor(7.9554, dtype=torch.float64)\n",
      "6.703279495239258\n",
      "current at batch: 162 tensor(7.7430, dtype=torch.float64)\n",
      "6.297011852264404\n",
      "current at batch: 163 tensor(7.2479, dtype=torch.float64)\n",
      "7.287061452865601\n",
      "current at batch: 164 tensor(7.3799, dtype=torch.float64)\n",
      "6.4522411823272705\n",
      "current at batch: 165 tensor(7.2273, dtype=torch.float64)\n",
      "6.839691400527954\n",
      "current at batch: 166 tensor(7.8154, dtype=torch.float64)\n",
      "6.9367358684539795\n",
      "current at batch: 167 tensor(7.5203, dtype=torch.float64)\n",
      "6.750312089920044\n",
      "current at batch: 168 tensor(7.4310, dtype=torch.float64)\n",
      "6.980143070220947\n",
      "current at batch: 169 tensor(7.7064, dtype=torch.float64)\n",
      "6.743334770202637\n",
      "current at batch: 170 tensor(7.6712, dtype=torch.float64)\n",
      "7.021966934204102\n",
      "current at batch: 171 tensor(7.2993, dtype=torch.float64)\n",
      "6.703262090682983\n",
      "current at batch: 172 tensor(7.9379, dtype=torch.float64)\n",
      "7.105449676513672\n",
      "current at batch: 173 tensor(7.3238, dtype=torch.float64)\n",
      "6.86810302734375\n",
      "current at batch: 174 tensor(7.4001, dtype=torch.float64)\n",
      "6.486255407333374\n",
      "current at batch: 175 tensor(7.2238, dtype=torch.float64)\n",
      "6.672013998031616\n",
      "current at batch: 176 tensor(7.2454, dtype=torch.float64)\n",
      "6.560543537139893\n",
      "current at batch: 177 tensor(7.0741, dtype=torch.float64)\n",
      "6.765765190124512\n",
      "current at batch: 178 tensor(7.2438, dtype=torch.float64)\n",
      "6.578258514404297\n",
      "current at batch: 179 tensor(7.2595, dtype=torch.float64)\n",
      "6.639541149139404\n",
      "current at batch: 180 tensor(7.3209, dtype=torch.float64)\n",
      "7.687679290771484\n",
      "current at batch: 181 tensor(7.8377, dtype=torch.float64)\n",
      "6.265767335891724\n",
      "current at batch: 182 tensor(7.1038, dtype=torch.float64)\n",
      "7.2346320152282715\n",
      "current at batch: 183 tensor(7.0406, dtype=torch.float64)\n",
      "7.1451802253723145\n",
      "current at batch: 184 tensor(7.3114, dtype=torch.float64)\n",
      "7.949846982955933\n",
      "current at batch: 185 tensor(7.2321, dtype=torch.float64)\n",
      "8.000165462493896\n",
      "current at batch: 186 tensor(7.4623, dtype=torch.float64)\n",
      "7.3034327030181885\n",
      "current at batch: 187 tensor(7.1284, dtype=torch.float64)\n",
      "9.526813745498657\n",
      "current at batch: 188 tensor(6.8636, dtype=torch.float64)\n",
      "10.363451957702637\n",
      "current at batch: 189 tensor(7.1116, dtype=torch.float64)\n",
      "10.665844678878784\n",
      "current at batch: 190 tensor(6.7328, dtype=torch.float64)\n",
      "9.108994483947754\n",
      "current at batch: 191 tensor(7.9832, dtype=torch.float64)\n",
      "10.27163052558899\n",
      "current at batch: 192 tensor(7.1720, dtype=torch.float64)\n",
      "9.402276754379272\n",
      "current at batch: 193 tensor(7.3455, dtype=torch.float64)\n",
      "9.136352777481079\n",
      "current at batch: 194 tensor(6.7908, dtype=torch.float64)\n",
      "8.701504945755005\n",
      "current at batch: 195 tensor(7.3010, dtype=torch.float64)\n",
      "9.75165057182312\n",
      "current at batch: 196 tensor(7.6120, dtype=torch.float64)\n",
      "8.380923748016357\n",
      "current at batch: 197 tensor(7.0671, dtype=torch.float64)\n",
      "8.730259895324707\n",
      "current at batch: 198 tensor(7.6080, dtype=torch.float64)\n",
      "9.231403350830078\n",
      "current at batch: 199 tensor(7.1131, dtype=torch.float64)\n",
      "9.317263841629028\n",
      "current at batch: 200 tensor(7.1142, dtype=torch.float64)\n",
      "8.768382787704468\n",
      "current at batch: 201 tensor(7.0544, dtype=torch.float64)\n",
      "9.701841592788696\n",
      "current at batch: 202 tensor(7.6544, dtype=torch.float64)\n",
      "10.15910816192627\n",
      "current at batch: 203 tensor(7.0605, dtype=torch.float64)\n",
      "7.492104530334473\n",
      "current at batch: 204 tensor(7.1661, dtype=torch.float64)\n",
      "6.79049015045166\n",
      "current at batch: 205 tensor(7.6027, dtype=torch.float64)\n",
      "7.399281024932861\n",
      "current at batch: 206 tensor(7.8278, dtype=torch.float64)\n",
      "7.822082996368408\n",
      "current at batch: 207 tensor(6.8187, dtype=torch.float64)\n",
      "7.580743789672852\n",
      "current at batch: 208 tensor(7.2930, dtype=torch.float64)\n",
      "8.636228799819946\n",
      "current at batch: 209 tensor(7.4069, dtype=torch.float64)\n",
      "8.55078935623169\n",
      "current at batch: 210 tensor(7.1387, dtype=torch.float64)\n",
      "9.756985664367676\n",
      "current at batch: 211 tensor(7.0759, dtype=torch.float64)\n",
      "9.864767789840698\n",
      "current at batch: 212 tensor(7.7059, dtype=torch.float64)\n",
      "9.776200532913208\n",
      "current at batch: 213 tensor(7.0649, dtype=torch.float64)\n",
      "9.848693132400513\n",
      "current at batch: 214 tensor(6.6178, dtype=torch.float64)\n",
      "10.496760606765747\n",
      "current at batch: 215 tensor(7.4107, dtype=torch.float64)\n",
      "9.545129537582397\n",
      "current at batch: 216 tensor(7.1352, dtype=torch.float64)\n",
      "9.17677903175354\n",
      "current at batch: 217 tensor(7.6015, dtype=torch.float64)\n",
      "9.173335552215576\n",
      "current at batch: 218 tensor(6.7215, dtype=torch.float64)\n",
      "9.390644788742065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 219 tensor(7.4931, dtype=torch.float64)\n",
      "9.304765462875366\n",
      "current at batch: 220 tensor(7.0710, dtype=torch.float64)\n",
      "8.85907793045044\n",
      "current at batch: 221 tensor(7.8482, dtype=torch.float64)\n",
      "9.04118013381958\n",
      "current at batch: 222 tensor(7.4810, dtype=torch.float64)\n",
      "9.840965270996094\n",
      "current at batch: 223 tensor(7.0042, dtype=torch.float64)\n",
      "9.875472784042358\n",
      "current at batch: 224 tensor(7.1096, dtype=torch.float64)\n",
      "8.950500726699829\n",
      "current at batch: 225 tensor(7.3543, dtype=torch.float64)\n",
      "9.451038599014282\n",
      "current at batch: 226 tensor(7.3286, dtype=torch.float64)\n",
      "10.628004312515259\n",
      "current at batch: 227 tensor(7.1947, dtype=torch.float64)\n",
      "10.987698554992676\n",
      "current at batch: 228 tensor(6.8015, dtype=torch.float64)\n",
      "9.252475500106812\n",
      "current at batch: 229 tensor(7.1332, dtype=torch.float64)\n",
      "9.765216827392578\n",
      "current at batch: 230 tensor(7.3635, dtype=torch.float64)\n",
      "10.64740777015686\n",
      "current at batch: 231 tensor(7.3280, dtype=torch.float64)\n",
      "10.661463737487793\n",
      "current at batch: 232 tensor(6.7300, dtype=torch.float64)\n",
      "10.330895185470581\n",
      "current at batch: 233 tensor(7.3185, dtype=torch.float64)\n",
      "10.495518445968628\n",
      "current at batch: 234 tensor(6.7980, dtype=torch.float64)\n",
      "10.661061525344849\n",
      "current at batch: 235 tensor(6.6752, dtype=torch.float64)\n",
      "9.174836158752441\n",
      "current at batch: 236 tensor(7.3844, dtype=torch.float64)\n",
      "7.58096718788147\n",
      "current at batch: 237 tensor(7.2426, dtype=torch.float64)\n",
      "9.393613815307617\n",
      "current at batch: 238 tensor(7.3247, dtype=torch.float64)\n",
      "9.64160966873169\n",
      "current at batch: 239 tensor(6.7755, dtype=torch.float64)\n",
      "9.27849555015564\n",
      "current at batch: 240 tensor(6.9101, dtype=torch.float64)\n",
      "9.839755773544312\n",
      "current at batch: 241 tensor(6.9969, dtype=torch.float64)\n",
      "9.763866662979126\n",
      "current at batch: 242 tensor(6.8834, dtype=torch.float64)\n",
      "10.229544639587402\n",
      "current at batch: 243 tensor(6.5813, dtype=torch.float64)\n",
      "9.986117124557495\n",
      "current at batch: 244 tensor(6.8890, dtype=torch.float64)\n",
      "9.73169231414795\n",
      "current at batch: 245 tensor(7.1868, dtype=torch.float64)\n",
      "10.467218160629272\n",
      "current at batch: 246 tensor(6.6783, dtype=torch.float64)\n",
      "10.4803147315979\n",
      "current at batch: 247 tensor(6.8721, dtype=torch.float64)\n",
      "8.593933820724487\n",
      "current at batch: 248 tensor(6.8831, dtype=torch.float64)\n",
      "9.92951226234436\n",
      "current at batch: 249 tensor(6.8319, dtype=torch.float64)\n",
      "10.147920608520508\n",
      "current at batch: 250 tensor(6.7487, dtype=torch.float64)\n",
      "9.710984945297241\n",
      "current at batch: 251 tensor(7.1218, dtype=torch.float64)\n",
      "10.606914043426514\n",
      "current at batch: 252 tensor(7.5440, dtype=torch.float64)\n",
      "9.484903335571289\n",
      "current at batch: 253 tensor(6.7406, dtype=torch.float64)\n",
      "9.973876953125\n",
      "current at batch: 254 tensor(7.1532, dtype=torch.float64)\n",
      "10.26021933555603\n",
      "current at batch: 255 tensor(6.7934, dtype=torch.float64)\n",
      "9.14101505279541\n",
      "current at batch: 256 tensor(6.8102, dtype=torch.float64)\n",
      "8.4414541721344\n",
      "current at batch: 257 tensor(7.1249, dtype=torch.float64)\n",
      "9.993712663650513\n",
      "current at batch: 258 tensor(6.5920, dtype=torch.float64)\n",
      "10.107877492904663\n",
      "current at batch: 259 tensor(6.9904, dtype=torch.float64)\n",
      "9.939164876937866\n",
      "current at batch: 260 tensor(7.1343, dtype=torch.float64)\n",
      "9.484992027282715\n",
      "current at batch: 261 tensor(7.1551, dtype=torch.float64)\n",
      "10.094285726547241\n",
      "current at batch: 262 tensor(6.8561, dtype=torch.float64)\n",
      "10.644037961959839\n",
      "current at batch: 263 tensor(7.4121, dtype=torch.float64)\n",
      "8.615559577941895\n",
      "current at batch: 264 tensor(7.6132, dtype=torch.float64)\n",
      "10.08774185180664\n",
      "current at batch: 265 tensor(7.1405, dtype=torch.float64)\n",
      "10.460843801498413\n",
      "current at batch: 266 tensor(7.3175, dtype=torch.float64)\n",
      "10.183412551879883\n",
      "current at batch: 267 tensor(7.0662, dtype=torch.float64)\n",
      "9.613095998764038\n",
      "current at batch: 268 tensor(7.4471, dtype=torch.float64)\n",
      "9.60976266860962\n",
      "current at batch: 269 tensor(7.5364, dtype=torch.float64)\n",
      "8.989711999893188\n",
      "current at batch: 270 tensor(6.9161, dtype=torch.float64)\n",
      "8.034737586975098\n",
      "current at batch: 271 tensor(6.9525, dtype=torch.float64)\n",
      "9.783966064453125\n",
      "current at batch: 272 tensor(7.2297, dtype=torch.float64)\n",
      "9.226316928863525\n",
      "current at batch: 273 tensor(7.1390, dtype=torch.float64)\n",
      "8.487575054168701\n",
      "current at batch: 274 tensor(7.6940, dtype=torch.float64)\n",
      "9.209248065948486\n",
      "current at batch: 275 tensor(7.2420, dtype=torch.float64)\n",
      "9.555185079574585\n",
      "current at batch: 276 tensor(7.2602, dtype=torch.float64)\n",
      "10.063030481338501\n",
      "current at batch: 277 tensor(7.6655, dtype=torch.float64)\n",
      "10.069736957550049\n",
      "current at batch: 278 tensor(7.0606, dtype=torch.float64)\n",
      "8.70136284828186\n",
      "current at batch: 279 tensor(7.3466, dtype=torch.float64)\n",
      "8.326314687728882\n",
      "current at batch: 280 tensor(7.8329, dtype=torch.float64)\n",
      "10.140586853027344\n",
      "current at batch: 281 tensor(6.9435, dtype=torch.float64)\n",
      "10.385933876037598\n",
      "current at batch: 282 tensor(6.9291, dtype=torch.float64)\n",
      "10.050650358200073\n",
      "current at batch: 283 tensor(7.7197, dtype=torch.float64)\n",
      "9.224372148513794\n",
      "current at batch: 284 tensor(6.7228, dtype=torch.float64)\n",
      "9.425375938415527\n",
      "current at batch: 285 tensor(7.2869, dtype=torch.float64)\n",
      "9.669296979904175\n",
      "current at batch: 286 tensor(7.3453, dtype=torch.float64)\n",
      "9.939167499542236\n",
      "current at batch: 287 tensor(7.4407, dtype=torch.float64)\n",
      "8.817365407943726\n",
      "current at batch: 288 tensor(7.7745, dtype=torch.float64)\n",
      "8.903295278549194\n",
      "current at batch: 289 tensor(7.3489, dtype=torch.float64)\n",
      "10.128981590270996\n",
      "current at batch: 290 tensor(7.3462, dtype=torch.float64)\n",
      "9.666147232055664\n",
      "current at batch: 291 tensor(7.6880, dtype=torch.float64)\n",
      "9.731273174285889\n",
      "current at batch: 292 tensor(7.6394, dtype=torch.float64)\n",
      "9.455278635025024\n",
      "current at batch: 293 tensor(7.2936, dtype=torch.float64)\n",
      "8.990230321884155\n",
      "current at batch: 294 tensor(7.1500, dtype=torch.float64)\n",
      "9.7391037940979\n",
      "current at batch: 295 tensor(7.3842, dtype=torch.float64)\n",
      "11.011780977249146\n",
      "current at batch: 296 tensor(7.1205, dtype=torch.float64)\n",
      "9.933863401412964\n",
      "current at batch: 297 tensor(6.8830, dtype=torch.float64)\n",
      "8.67870831489563\n",
      "current at batch: 298 tensor(7.8826, dtype=torch.float64)\n",
      "11.172099828720093\n",
      "current at batch: 299 tensor(7.2604, dtype=torch.float64)\n",
      "9.812825918197632\n",
      "current at batch: 300 tensor(7.2411, dtype=torch.float64)\n",
      "10.983844995498657\n",
      "current at batch: 301 tensor(6.8680, dtype=torch.float64)\n",
      "8.765799760818481\n",
      "current at batch: 302 tensor(7.3747, dtype=torch.float64)\n",
      "10.0073082447052\n",
      "current at batch: 303 tensor(6.9180, dtype=torch.float64)\n",
      "10.267480373382568\n",
      "current at batch: 304 tensor(7.0780, dtype=torch.float64)\n",
      "10.651008605957031\n",
      "current at batch: 305 tensor(6.7367, dtype=torch.float64)\n",
      "9.829572439193726\n",
      "current at batch: 306 tensor(6.7272, dtype=torch.float64)\n",
      "9.07830810546875\n",
      "current at batch: 307 tensor(6.2942, dtype=torch.float64)\n",
      "10.558655023574829\n",
      "current at batch: 308 tensor(7.0960, dtype=torch.float64)\n",
      "11.192368268966675\n",
      "current at batch: 309 tensor(7.0199, dtype=torch.float64)\n",
      "10.764058589935303\n",
      "current at batch: 310 tensor(7.0659, dtype=torch.float64)\n",
      "9.380456447601318\n",
      "current at batch: 311 tensor(6.9883, dtype=torch.float64)\n",
      "8.682001829147339\n",
      "current at batch: 312 tensor(6.7103, dtype=torch.float64)\n",
      "8.718938827514648\n",
      "current at batch: 313 tensor(6.9462, dtype=torch.float64)\n",
      "11.516375541687012\n",
      "current at batch: 314 tensor(6.7941, dtype=torch.float64)\n",
      "8.843930006027222\n",
      "current at batch: 315 tensor(6.8624, dtype=torch.float64)\n",
      "10.102076292037964\n",
      "current at batch: 316 tensor(6.8593, dtype=torch.float64)\n",
      "10.8640878200531\n",
      "current at batch: 317 tensor(7.4507, dtype=torch.float64)\n",
      "10.225618124008179\n",
      "current at batch: 318 tensor(6.5399, dtype=torch.float64)\n",
      "8.758093118667603\n",
      "current at batch: 319 tensor(7.4765, dtype=torch.float64)\n",
      "9.023555755615234\n",
      "current at batch: 320 tensor(7.1864, dtype=torch.float64)\n",
      "10.744924545288086\n",
      "current at batch: 321 tensor(7.1034, dtype=torch.float64)\n",
      "10.993564128875732\n",
      "current at batch: 322 tensor(7.1167, dtype=torch.float64)\n",
      "10.077262878417969\n",
      "current at batch: 323 tensor(6.9726, dtype=torch.float64)\n",
      "9.380531311035156\n",
      "current at batch: 324 tensor(6.8036, dtype=torch.float64)\n",
      "9.37649130821228\n",
      "current at batch: 325 tensor(6.4208, dtype=torch.float64)\n",
      "10.103431463241577\n",
      "current at batch: 326 tensor(6.5146, dtype=torch.float64)\n",
      "8.164923667907715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 327 tensor(6.7491, dtype=torch.float64)\n",
      "11.031472444534302\n",
      "current at batch: 328 tensor(6.3213, dtype=torch.float64)\n",
      "8.871115446090698\n",
      "current at batch: 329 tensor(6.9525, dtype=torch.float64)\n",
      "9.732177495956421\n",
      "current at batch: 330 tensor(7.5666, dtype=torch.float64)\n",
      "10.685222387313843\n",
      "current at batch: 331 tensor(7.3824, dtype=torch.float64)\n",
      "7.481573581695557\n",
      "current at batch: 332 tensor(7.5520, dtype=torch.float64)\n",
      "7.085756778717041\n",
      "current at batch: 333 tensor(7.1497, dtype=torch.float64)\n",
      "6.441037893295288\n",
      "current at batch: 334 tensor(7.0092, dtype=torch.float64)\n",
      "7.192878723144531\n",
      "current at batch: 335 tensor(7.2646, dtype=torch.float64)\n",
      "8.547110080718994\n",
      "current at batch: 336 tensor(6.5268, dtype=torch.float64)\n",
      "10.594608068466187\n",
      "current at batch: 337 tensor(6.8664, dtype=torch.float64)\n",
      "8.507190942764282\n",
      "current at batch: 338 tensor(7.2930, dtype=torch.float64)\n",
      "9.724013805389404\n",
      "current at batch: 339 tensor(6.9934, dtype=torch.float64)\n",
      "10.20996904373169\n",
      "current at batch: 340 tensor(7.4181, dtype=torch.float64)\n",
      "10.10551142692566\n",
      "current at batch: 341 tensor(6.9875, dtype=torch.float64)\n",
      "8.43795132637024\n",
      "current at batch: 342 tensor(7.2710, dtype=torch.float64)\n",
      "10.263302087783813\n",
      "current at batch: 343 tensor(7.3578, dtype=torch.float64)\n",
      "9.804615259170532\n",
      "current at batch: 344 tensor(6.9750, dtype=torch.float64)\n",
      "9.663166284561157\n",
      "current at batch: 345 tensor(6.8297, dtype=torch.float64)\n",
      "9.63248896598816\n",
      "current at batch: 346 tensor(7.1143, dtype=torch.float64)\n",
      "10.556357145309448\n",
      "current at batch: 347 tensor(7.5394, dtype=torch.float64)\n",
      "10.551911115646362\n",
      "current at batch: 348 tensor(7.3373, dtype=torch.float64)\n",
      "10.383293151855469\n",
      "current at batch: 349 tensor(6.6942, dtype=torch.float64)\n",
      "8.468976259231567\n",
      "current at batch: 350 tensor(6.7719, dtype=torch.float64)\n",
      "12.129226922988892\n",
      "current at batch: 351 tensor(7.4139, dtype=torch.float64)\n",
      "9.562754392623901\n",
      "current at batch: 352 tensor(6.6883, dtype=torch.float64)\n",
      "10.100672721862793\n",
      "current at batch: 353 tensor(7.3361, dtype=torch.float64)\n",
      "10.76576852798462\n",
      "current at batch: 354 tensor(6.5987, dtype=torch.float64)\n",
      "9.599825620651245\n",
      "current at batch: 355 tensor(7.0135, dtype=torch.float64)\n",
      "8.753928661346436\n",
      "current at batch: 356 tensor(7.1204, dtype=torch.float64)\n",
      "10.91708254814148\n",
      "current at batch: 357 tensor(7.0922, dtype=torch.float64)\n",
      "10.659908294677734\n",
      "current at batch: 358 tensor(7.2023, dtype=torch.float64)\n",
      "9.769948482513428\n",
      "current at batch: 359 tensor(7.5082, dtype=torch.float64)\n",
      "10.260120868682861\n",
      "current at batch: 360 tensor(7.1962, dtype=torch.float64)\n",
      "9.37508487701416\n",
      "current at batch: 361 tensor(6.8342, dtype=torch.float64)\n",
      "8.853880405426025\n",
      "current at batch: 362 tensor(6.7100, dtype=torch.float64)\n",
      "8.184794664382935\n",
      "current at batch: 363 tensor(6.9579, dtype=torch.float64)\n",
      "10.91707444190979\n",
      "current at batch: 364 tensor(7.4504, dtype=torch.float64)\n",
      "10.001767873764038\n",
      "current at batch: 365 tensor(7.1430, dtype=torch.float64)\n",
      "9.543148040771484\n",
      "current at batch: 366 tensor(6.5176, dtype=torch.float64)\n",
      "9.088250160217285\n",
      "current at batch: 367 tensor(7.0605, dtype=torch.float64)\n",
      "9.8120276927948\n",
      "current at batch: 368 tensor(6.8597, dtype=torch.float64)\n",
      "8.983155488967896\n",
      "current at batch: 369 tensor(7.1822, dtype=torch.float64)\n",
      "10.325124502182007\n",
      "current at batch: 370 tensor(6.6301, dtype=torch.float64)\n",
      "9.730152606964111\n",
      "current at batch: 371 tensor(6.6989, dtype=torch.float64)\n",
      "9.234560489654541\n",
      "current at batch: 372 tensor(6.4650, dtype=torch.float64)\n",
      "10.23429250717163\n",
      "current at batch: 373 tensor(6.8471, dtype=torch.float64)\n",
      "11.265071153640747\n",
      "current at batch: 374 tensor(7.0223, dtype=torch.float64)\n",
      "10.06036376953125\n",
      "current at batch: 375 tensor(6.1082, dtype=torch.float64)\n",
      "10.231276035308838\n",
      "current at batch: 376 tensor(6.7307, dtype=torch.float64)\n",
      "10.354230403900146\n",
      "current at batch: 377 tensor(6.9335, dtype=torch.float64)\n",
      "9.52149486541748\n",
      "current at batch: 378 tensor(7.1593, dtype=torch.float64)\n",
      "9.808701276779175\n",
      "current at batch: 379 tensor(6.3839, dtype=torch.float64)\n",
      "9.899986267089844\n",
      "current at batch: 380 tensor(6.7321, dtype=torch.float64)\n",
      "9.43584656715393\n",
      "current at batch: 381 tensor(7.0577, dtype=torch.float64)\n",
      "9.852955102920532\n",
      "current at batch: 382 tensor(7.1520, dtype=torch.float64)\n",
      "10.796755075454712\n",
      "current at batch: 383 tensor(6.7110, dtype=torch.float64)\n",
      "11.077430486679077\n",
      "current at batch: 384 tensor(7.0490, dtype=torch.float64)\n",
      "9.984946012496948\n",
      "current at batch: 385 tensor(6.9046, dtype=torch.float64)\n",
      "10.834477424621582\n",
      "current at batch: 386 tensor(7.2180, dtype=torch.float64)\n",
      "11.084356784820557\n",
      "current at batch: 387 tensor(7.2079, dtype=torch.float64)\n",
      "10.038949489593506\n",
      "current at batch: 388 tensor(6.9769, dtype=torch.float64)\n",
      "9.14740777015686\n",
      "current at batch: 389 tensor(6.7798, dtype=torch.float64)\n",
      "9.890829801559448\n",
      "current at batch: 390 tensor(7.0635, dtype=torch.float64)\n",
      "9.961371660232544\n",
      "current at batch: 391 tensor(7.2679, dtype=torch.float64)\n",
      "9.773062467575073\n",
      "current at batch: 392 tensor(7.2795, dtype=torch.float64)\n",
      "10.323091506958008\n",
      "current at batch: 393 tensor(7.7573, dtype=torch.float64)\n",
      "10.328538179397583\n",
      "current at batch: 394 tensor(6.3524, dtype=torch.float64)\n",
      "9.563624858856201\n",
      "current at batch: 395 tensor(6.2897, dtype=torch.float64)\n",
      "10.551609516143799\n",
      "current at batch: 396 tensor(6.1955, dtype=torch.float64)\n",
      "9.011864423751831\n",
      "current at batch: 397 tensor(6.7139, dtype=torch.float64)\n",
      "12.600077152252197\n",
      "current at batch: 398 tensor(6.4132, dtype=torch.float64)\n",
      "10.5108163356781\n",
      "current at batch: 399 tensor(7.1495, dtype=torch.float64)\n",
      "10.502769470214844\n",
      "current at batch: 400 tensor(6.7680, dtype=torch.float64)\n",
      "9.934873342514038\n",
      "current at batch: 401 tensor(7.1747, dtype=torch.float64)\n",
      "8.184613704681396\n",
      "current at batch: 402 tensor(6.4320, dtype=torch.float64)\n",
      "9.52009916305542\n",
      "current at batch: 403 tensor(6.4141, dtype=torch.float64)\n",
      "11.381218194961548\n",
      "current at batch: 404 tensor(6.2109, dtype=torch.float64)\n",
      "11.996648073196411\n",
      "current at batch: 405 tensor(7.4778, dtype=torch.float64)\n",
      "9.979947090148926\n",
      "current at batch: 406 tensor(6.2796, dtype=torch.float64)\n",
      "10.483331441879272\n",
      "current at batch: 407 tensor(7.0046, dtype=torch.float64)\n",
      "11.556984901428223\n",
      "current at batch: 408 tensor(6.6065, dtype=torch.float64)\n",
      "9.514323472976685\n",
      "current at batch: 409 tensor(6.9048, dtype=torch.float64)\n",
      "10.394331216812134\n",
      "current at batch: 410 tensor(7.3058, dtype=torch.float64)\n",
      "12.247976064682007\n",
      "current at batch: 411 tensor(6.7376, dtype=torch.float64)\n",
      "10.45013976097107\n",
      "current at batch: 412 tensor(6.8739, dtype=torch.float64)\n",
      "9.265813112258911\n",
      "current at batch: 413 tensor(6.7707, dtype=torch.float64)\n",
      "11.227954864501953\n",
      "current at batch: 414 tensor(7.0953, dtype=torch.float64)\n",
      "11.781744956970215\n",
      "current at batch: 415 tensor(6.2040, dtype=torch.float64)\n",
      "9.09071135520935\n",
      "current at batch: 416 tensor(6.7283, dtype=torch.float64)\n",
      "10.8112633228302\n",
      "current at batch: 417 tensor(6.9473, dtype=torch.float64)\n",
      "11.359966039657593\n",
      "current at batch: 418 tensor(6.7792, dtype=torch.float64)\n",
      "9.940691232681274\n",
      "current at batch: 419 tensor(6.7968, dtype=torch.float64)\n",
      "10.529112339019775\n",
      "current at batch: 420 tensor(6.7980, dtype=torch.float64)\n",
      "11.3108811378479\n",
      "current at batch: 421 tensor(6.6157, dtype=torch.float64)\n",
      "10.172912120819092\n",
      "current at batch: 422 tensor(6.8714, dtype=torch.float64)\n",
      "10.194891452789307\n",
      "current at batch: 423 tensor(7.1563, dtype=torch.float64)\n",
      "11.563903331756592\n",
      "current at batch: 424 tensor(6.7621, dtype=torch.float64)\n",
      "9.994303703308105\n",
      "current at batch: 425 tensor(6.6283, dtype=torch.float64)\n",
      "11.080284833908081\n",
      "current at batch: 426 tensor(6.5051, dtype=torch.float64)\n",
      "11.440872192382812\n",
      "current at batch: 427 tensor(6.9936, dtype=torch.float64)\n",
      "11.206896543502808\n",
      "current at batch: 428 tensor(6.9828, dtype=torch.float64)\n",
      "9.853090763092041\n",
      "current at batch: 429 tensor(6.9648, dtype=torch.float64)\n",
      "11.30387830734253\n",
      "current at batch: 430 tensor(7.1126, dtype=torch.float64)\n",
      "11.814149856567383\n",
      "current at batch: 431 tensor(6.4537, dtype=torch.float64)\n",
      "9.765334844589233\n",
      "current at batch: 432 tensor(6.6334, dtype=torch.float64)\n",
      "10.775648355484009\n",
      "current at batch: 433 tensor(6.9311, dtype=torch.float64)\n",
      "11.548654079437256\n",
      "current at batch: 434 tensor(6.8651, dtype=torch.float64)\n",
      "10.091309070587158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 435 tensor(6.9688, dtype=torch.float64)\n",
      "11.154439210891724\n",
      "current at batch: 436 tensor(6.1532, dtype=torch.float64)\n",
      "11.719000577926636\n",
      "current at batch: 437 tensor(7.0349, dtype=torch.float64)\n",
      "11.78791356086731\n",
      "current at batch: 438 tensor(7.0449, dtype=torch.float64)\n",
      "11.288037538528442\n",
      "current at batch: 439 tensor(6.3346, dtype=torch.float64)\n",
      "11.898021459579468\n",
      "current at batch: 440 tensor(6.8903, dtype=torch.float64)\n",
      "9.981716871261597\n",
      "current at batch: 441 tensor(6.5846, dtype=torch.float64)\n",
      "9.893383264541626\n",
      "current at batch: 442 tensor(6.9933, dtype=torch.float64)\n",
      "11.718990802764893\n",
      "current at batch: 443 tensor(6.9326, dtype=torch.float64)\n",
      "9.940128087997437\n",
      "current at batch: 444 tensor(6.4346, dtype=torch.float64)\n",
      "10.615341424942017\n",
      "current at batch: 445 tensor(6.5269, dtype=torch.float64)\n",
      "11.026273965835571\n",
      "current at batch: 446 tensor(6.6206, dtype=torch.float64)\n",
      "9.71097445487976\n",
      "current at batch: 447 tensor(6.5374, dtype=torch.float64)\n",
      "11.798644781112671\n",
      "current at batch: 448 tensor(6.7249, dtype=torch.float64)\n",
      "10.749642848968506\n",
      "current at batch: 449 tensor(7.2299, dtype=torch.float64)\n",
      "10.691091060638428\n",
      "current at batch: 450 tensor(6.6079, dtype=torch.float64)\n",
      "11.63565993309021\n",
      "current at batch: 451 tensor(6.8716, dtype=torch.float64)\n",
      "11.287013053894043\n",
      "current at batch: 452 tensor(6.6351, dtype=torch.float64)\n",
      "10.437785625457764\n",
      "current at batch: 453 tensor(6.9212, dtype=torch.float64)\n",
      "12.090168714523315\n",
      "current at batch: 454 tensor(6.9835, dtype=torch.float64)\n",
      "10.691648483276367\n",
      "current at batch: 455 tensor(6.5432, dtype=torch.float64)\n",
      "10.263764142990112\n",
      "current at batch: 456 tensor(6.6464, dtype=torch.float64)\n",
      "12.192022562026978\n",
      "current at batch: 457 tensor(6.6269, dtype=torch.float64)\n",
      "10.562022686004639\n",
      "current at batch: 458 tensor(7.0618, dtype=torch.float64)\n",
      "11.113200426101685\n",
      "current at batch: 459 tensor(6.2785, dtype=torch.float64)\n",
      "11.819445610046387\n",
      "current at batch: 460 tensor(6.6462, dtype=torch.float64)\n",
      "9.620405197143555\n",
      "current at batch: 461 tensor(6.6311, dtype=torch.float64)\n",
      "12.848900556564331\n",
      "current at batch: 462 tensor(6.6532, dtype=torch.float64)\n",
      "10.376140117645264\n",
      "current at batch: 463 tensor(6.5787, dtype=torch.float64)\n",
      "11.581260204315186\n",
      "current at batch: 464 tensor(7.0418, dtype=torch.float64)\n",
      "11.953370094299316\n",
      "current at batch: 465 tensor(6.9021, dtype=torch.float64)\n",
      "10.197045803070068\n",
      "current at batch: 466 tensor(6.8394, dtype=torch.float64)\n",
      "10.978558778762817\n",
      "current at batch: 467 tensor(6.6590, dtype=torch.float64)\n",
      "11.000927448272705\n",
      "current at batch: 468 tensor(7.0808, dtype=torch.float64)\n",
      "10.485764741897583\n",
      "current at batch: 469 tensor(7.2742, dtype=torch.float64)\n",
      "11.906560182571411\n",
      "current at batch: 470 tensor(6.8527, dtype=torch.float64)\n",
      "10.813061714172363\n",
      "current at batch: 471 tensor(6.4495, dtype=torch.float64)\n",
      "10.904456615447998\n",
      "current at batch: 472 tensor(5.0470, dtype=torch.float64)\n",
      "1.9292819499969482\n",
      "epoch =  0 \n",
      " tensor(3473.9214, dtype=torch.float64)\n",
      "current at batch: 1 tensor(6.6650, dtype=torch.float64)\n",
      "12.143943071365356\n",
      "current at batch: 2 tensor(6.7970, dtype=torch.float64)\n",
      "10.570401906967163\n",
      "current at batch: 3 tensor(6.8241, dtype=torch.float64)\n",
      "10.753997087478638\n",
      "current at batch: 4 tensor(6.8116, dtype=torch.float64)\n",
      "11.875240087509155\n",
      "current at batch: 5 tensor(6.8811, dtype=torch.float64)\n",
      "9.775992631912231\n",
      "current at batch: 6 tensor(7.0767, dtype=torch.float64)\n",
      "11.022148609161377\n",
      "current at batch: 7 tensor(6.5017, dtype=torch.float64)\n",
      "10.442816972732544\n",
      "current at batch: 8 tensor(6.4860, dtype=torch.float64)\n",
      "9.687322854995728\n",
      "current at batch: 9 tensor(6.9578, dtype=torch.float64)\n",
      "12.664330005645752\n",
      "current at batch: 10 tensor(6.9006, dtype=torch.float64)\n",
      "9.575224161148071\n",
      "current at batch: 11 tensor(6.7925, dtype=torch.float64)\n",
      "11.853619575500488\n",
      "current at batch: 12 tensor(7.1982, dtype=torch.float64)\n",
      "8.959148645401001\n",
      "current at batch: 13 tensor(6.8961, dtype=torch.float64)\n",
      "9.816168785095215\n",
      "current at batch: 14 tensor(7.0557, dtype=torch.float64)\n",
      "10.036691188812256\n",
      "current at batch: 15 tensor(6.6060, dtype=torch.float64)\n",
      "10.19288945198059\n",
      "current at batch: 16 tensor(7.1853, dtype=torch.float64)\n",
      "10.445482730865479\n",
      "current at batch: 17 tensor(7.1170, dtype=torch.float64)\n",
      "11.265968322753906\n",
      "current at batch: 18 tensor(7.0156, dtype=torch.float64)\n",
      "11.585673093795776\n",
      "current at batch: 19 tensor(6.3813, dtype=torch.float64)\n",
      "12.041314363479614\n",
      "current at batch: 20 tensor(7.3727, dtype=torch.float64)\n",
      "11.652097225189209\n",
      "current at batch: 21 tensor(6.9419, dtype=torch.float64)\n",
      "10.868420600891113\n",
      "current at batch: 22 tensor(6.6874, dtype=torch.float64)\n",
      "10.790745735168457\n",
      "current at batch: 23 tensor(6.8698, dtype=torch.float64)\n",
      "10.460392236709595\n",
      "current at batch: 24 tensor(6.6965, dtype=torch.float64)\n",
      "11.152101516723633\n",
      "current at batch: 25 tensor(6.8781, dtype=torch.float64)\n",
      "10.591495513916016\n",
      "current at batch: 26 tensor(6.9236, dtype=torch.float64)\n",
      "9.967249155044556\n",
      "current at batch: 27 tensor(6.5970, dtype=torch.float64)\n",
      "10.513748407363892\n",
      "current at batch: 28 tensor(6.5020, dtype=torch.float64)\n",
      "10.859594583511353\n",
      "current at batch: 29 tensor(6.9596, dtype=torch.float64)\n",
      "10.15621542930603\n",
      "current at batch: 30 tensor(6.8093, dtype=torch.float64)\n",
      "9.81960415840149\n",
      "current at batch: 31 tensor(6.8221, dtype=torch.float64)\n",
      "10.422096967697144\n",
      "current at batch: 32 tensor(6.5550, dtype=torch.float64)\n",
      "10.09397006034851\n",
      "current at batch: 33 tensor(6.4786, dtype=torch.float64)\n",
      "10.657160997390747\n",
      "current at batch: 34 tensor(6.6252, dtype=torch.float64)\n",
      "10.040374040603638\n",
      "current at batch: 35 tensor(6.9925, dtype=torch.float64)\n",
      "12.375251054763794\n",
      "current at batch: 36 tensor(6.4725, dtype=torch.float64)\n",
      "10.471300601959229\n",
      "current at batch: 37 tensor(6.7330, dtype=torch.float64)\n",
      "10.379275798797607\n",
      "current at batch: 38 tensor(7.1320, dtype=torch.float64)\n",
      "9.682974100112915\n",
      "current at batch: 39 tensor(6.4339, dtype=torch.float64)\n",
      "7.76578426361084\n",
      "current at batch: 40 tensor(6.6961, dtype=torch.float64)\n",
      "7.657372713088989\n",
      "current at batch: 41 tensor(6.2537, dtype=torch.float64)\n",
      "7.484536647796631\n",
      "current at batch: 42 tensor(6.7066, dtype=torch.float64)\n",
      "8.352274179458618\n",
      "current at batch: 43 tensor(6.5499, dtype=torch.float64)\n",
      "7.146705389022827\n",
      "current at batch: 44 tensor(6.8243, dtype=torch.float64)\n",
      "7.239592552185059\n",
      "current at batch: 45 tensor(6.8141, dtype=torch.float64)\n",
      "7.539447069168091\n",
      "current at batch: 46 tensor(6.5464, dtype=torch.float64)\n",
      "9.315032243728638\n",
      "current at batch: 47 tensor(6.9427, dtype=torch.float64)\n",
      "8.619290828704834\n",
      "current at batch: 48 tensor(7.3158, dtype=torch.float64)\n",
      "7.890789270401001\n",
      "current at batch: 49 tensor(6.7140, dtype=torch.float64)\n",
      "6.953272581100464\n",
      "current at batch: 50 tensor(6.8389, dtype=torch.float64)\n",
      "7.948269605636597\n",
      "current at batch: 51 tensor(6.2315, dtype=torch.float64)\n",
      "7.355789661407471\n",
      "current at batch: 52 tensor(6.9853, dtype=torch.float64)\n",
      "8.279387474060059\n",
      "current at batch: 53 tensor(6.4890, dtype=torch.float64)\n",
      "7.984541177749634\n",
      "current at batch: 54 tensor(6.8515, dtype=torch.float64)\n",
      "8.036001682281494\n",
      "current at batch: 55 tensor(7.2513, dtype=torch.float64)\n",
      "7.962474584579468\n",
      "current at batch: 56 tensor(6.7919, dtype=torch.float64)\n",
      "7.73403787612915\n",
      "current at batch: 57 tensor(6.6995, dtype=torch.float64)\n",
      "7.257413864135742\n",
      "current at batch: 58 tensor(6.4730, dtype=torch.float64)\n",
      "7.61920952796936\n",
      "current at batch: 59 tensor(6.8492, dtype=torch.float64)\n",
      "8.332967042922974\n",
      "current at batch: 60 tensor(7.0003, dtype=torch.float64)\n",
      "8.551496028900146\n",
      "current at batch: 61 tensor(6.4336, dtype=torch.float64)\n",
      "10.15140175819397\n",
      "current at batch: 62 tensor(7.1662, dtype=torch.float64)\n",
      "10.112772703170776\n",
      "current at batch: 63 tensor(6.5363, dtype=torch.float64)\n",
      "10.256387948989868\n",
      "current at batch: 64 tensor(7.0090, dtype=torch.float64)\n",
      "10.221948146820068\n",
      "current at batch: 65 tensor(6.7408, dtype=torch.float64)\n",
      "8.575580358505249\n",
      "current at batch: 66 tensor(6.8603, dtype=torch.float64)\n",
      "8.303420543670654\n",
      "current at batch: 67 tensor(7.1314, dtype=torch.float64)\n",
      "9.591437339782715\n",
      "current at batch: 68 tensor(6.9358, dtype=torch.float64)\n",
      "9.258131504058838\n",
      "current at batch: 69 tensor(6.9192, dtype=torch.float64)\n",
      "9.429959297180176\n",
      "current at batch: 70 tensor(6.9099, dtype=torch.float64)\n",
      "9.470671653747559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 71 tensor(6.3355, dtype=torch.float64)\n",
      "9.867936611175537\n",
      "current at batch: 72 tensor(6.7538, dtype=torch.float64)\n",
      "9.923271179199219\n",
      "current at batch: 73 tensor(6.6218, dtype=torch.float64)\n",
      "9.356145858764648\n",
      "current at batch: 74 tensor(7.2585, dtype=torch.float64)\n",
      "9.859304428100586\n",
      "current at batch: 75 tensor(6.8544, dtype=torch.float64)\n",
      "10.181373596191406\n",
      "current at batch: 76 tensor(7.1437, dtype=torch.float64)\n",
      "9.531902551651001\n",
      "current at batch: 77 tensor(7.0130, dtype=torch.float64)\n",
      "9.21696138381958\n",
      "current at batch: 78 tensor(6.8864, dtype=torch.float64)\n",
      "10.224200010299683\n",
      "current at batch: 79 tensor(6.7354, dtype=torch.float64)\n",
      "9.744292736053467\n",
      "current at batch: 80 tensor(6.9047, dtype=torch.float64)\n",
      "9.761232614517212\n",
      "current at batch: 81 tensor(6.7076, dtype=torch.float64)\n",
      "8.986642122268677\n",
      "current at batch: 82 tensor(6.9527, dtype=torch.float64)\n",
      "8.761463403701782\n",
      "current at batch: 83 tensor(7.1194, dtype=torch.float64)\n",
      "8.684394121170044\n",
      "current at batch: 84 tensor(6.6143, dtype=torch.float64)\n",
      "8.1976637840271\n",
      "current at batch: 85 tensor(7.3324, dtype=torch.float64)\n",
      "8.614661931991577\n",
      "current at batch: 86 tensor(6.6387, dtype=torch.float64)\n",
      "7.99124813079834\n",
      "current at batch: 87 tensor(6.8326, dtype=torch.float64)\n",
      "8.313782930374146\n",
      "current at batch: 88 tensor(7.1327, dtype=torch.float64)\n",
      "8.655716180801392\n",
      "current at batch: 89 tensor(6.9203, dtype=torch.float64)\n",
      "8.243884563446045\n",
      "current at batch: 90 tensor(6.7946, dtype=torch.float64)\n",
      "8.797116041183472\n",
      "current at batch: 91 tensor(6.6455, dtype=torch.float64)\n",
      "8.448161363601685\n",
      "current at batch: 92 tensor(6.8589, dtype=torch.float64)\n",
      "7.903202533721924\n",
      "current at batch: 93 tensor(7.3758, dtype=torch.float64)\n",
      "8.654364109039307\n",
      "current at batch: 94 tensor(7.1811, dtype=torch.float64)\n",
      "8.141337156295776\n",
      "current at batch: 95 tensor(6.6831, dtype=torch.float64)\n",
      "8.296679735183716\n",
      "current at batch: 96 tensor(6.6912, dtype=torch.float64)\n",
      "8.103062629699707\n",
      "current at batch: 97 tensor(6.7314, dtype=torch.float64)\n",
      "7.922037363052368\n",
      "current at batch: 98 tensor(6.6324, dtype=torch.float64)\n",
      "8.109545230865479\n",
      "current at batch: 99 tensor(7.2176, dtype=torch.float64)\n",
      "8.047054290771484\n",
      "current at batch: 100 tensor(6.9027, dtype=torch.float64)\n",
      "7.968722820281982\n",
      "current at batch: 101 tensor(6.4176, dtype=torch.float64)\n",
      "8.19437575340271\n",
      "current at batch: 102 tensor(6.8668, dtype=torch.float64)\n",
      "8.200913429260254\n",
      "current at batch: 103 tensor(6.2792, dtype=torch.float64)\n",
      "8.605069637298584\n",
      "current at batch: 104 tensor(6.8821, dtype=torch.float64)\n",
      "8.540981531143188\n",
      "current at batch: 105 tensor(5.9649, dtype=torch.float64)\n",
      "7.615354061126709\n",
      "current at batch: 106 tensor(6.6911, dtype=torch.float64)\n",
      "7.797034025192261\n",
      "current at batch: 107 tensor(6.6897, dtype=torch.float64)\n",
      "8.875179529190063\n",
      "current at batch: 108 tensor(6.2381, dtype=torch.float64)\n",
      "8.36574912071228\n",
      "current at batch: 109 tensor(6.7235, dtype=torch.float64)\n",
      "8.312370538711548\n",
      "current at batch: 110 tensor(6.7646, dtype=torch.float64)\n",
      "8.679100036621094\n",
      "current at batch: 111 tensor(6.7694, dtype=torch.float64)\n",
      "8.971384525299072\n",
      "current at batch: 112 tensor(6.4752, dtype=torch.float64)\n",
      "9.109559059143066\n",
      "current at batch: 113 tensor(6.6363, dtype=torch.float64)\n",
      "8.383909225463867\n",
      "current at batch: 114 tensor(6.5770, dtype=torch.float64)\n",
      "8.174793004989624\n",
      "current at batch: 115 tensor(6.7345, dtype=torch.float64)\n",
      "8.090656995773315\n",
      "current at batch: 116 tensor(6.7262, dtype=torch.float64)\n",
      "7.5939037799835205\n",
      "current at batch: 117 tensor(6.4884, dtype=torch.float64)\n",
      "7.859535455703735\n",
      "current at batch: 118 tensor(6.4913, dtype=torch.float64)\n",
      "7.8974339962005615\n",
      "current at batch: 119 tensor(6.7041, dtype=torch.float64)\n",
      "8.07176685333252\n",
      "current at batch: 120 tensor(6.4496, dtype=torch.float64)\n",
      "7.76578426361084\n",
      "current at batch: 121 tensor(6.9352, dtype=torch.float64)\n",
      "8.343927383422852\n",
      "current at batch: 122 tensor(6.9540, dtype=torch.float64)\n",
      "8.256733417510986\n",
      "current at batch: 123 tensor(6.7364, dtype=torch.float64)\n",
      "8.110628128051758\n",
      "current at batch: 124 tensor(6.7880, dtype=torch.float64)\n",
      "7.859533071517944\n",
      "current at batch: 125 tensor(7.4776, dtype=torch.float64)\n",
      "8.922055721282959\n",
      "current at batch: 126 tensor(6.2417, dtype=torch.float64)\n",
      "7.9845335483551025\n",
      "current at batch: 127 tensor(6.7735, dtype=torch.float64)\n",
      "7.99367618560791\n",
      "current at batch: 128 tensor(6.2311, dtype=torch.float64)\n",
      "7.850797176361084\n",
      "current at batch: 129 tensor(6.6290, dtype=torch.float64)\n",
      "7.547031402587891\n",
      "current at batch: 130 tensor(6.5158, dtype=torch.float64)\n",
      "8.520519733428955\n",
      "current at batch: 131 tensor(6.6882, dtype=torch.float64)\n",
      "8.398499011993408\n",
      "current at batch: 132 tensor(6.2884, dtype=torch.float64)\n",
      "8.27923035621643\n",
      "current at batch: 133 tensor(6.6575, dtype=torch.float64)\n",
      "8.281418323516846\n",
      "current at batch: 134 tensor(6.5670, dtype=torch.float64)\n",
      "7.872154474258423\n",
      "current at batch: 135 tensor(6.2779, dtype=torch.float64)\n",
      "8.343917608261108\n",
      "current at batch: 136 tensor(7.0463, dtype=torch.float64)\n",
      "8.612331867218018\n",
      "current at batch: 137 tensor(6.5453, dtype=torch.float64)\n",
      "7.911238431930542\n",
      "current at batch: 138 tensor(6.2356, dtype=torch.float64)\n",
      "7.840948581695557\n",
      "current at batch: 139 tensor(6.3868, dtype=torch.float64)\n",
      "8.000167608261108\n",
      "current at batch: 140 tensor(6.8911, dtype=torch.float64)\n",
      "8.567435503005981\n",
      "current at batch: 141 tensor(6.7269, dtype=torch.float64)\n",
      "7.87515926361084\n",
      "current at batch: 142 tensor(6.5911, dtype=torch.float64)\n",
      "8.187673568725586\n",
      "current at batch: 143 tensor(6.4961, dtype=torch.float64)\n",
      "7.922033071517944\n",
      "current at batch: 144 tensor(6.6308, dtype=torch.float64)\n",
      "8.015808820724487\n",
      "current at batch: 145 tensor(6.6286, dtype=torch.float64)\n",
      "7.442409038543701\n",
      "current at batch: 146 tensor(6.2375, dtype=torch.float64)\n",
      "7.939462423324585\n",
      "current at batch: 147 tensor(6.7264, dtype=torch.float64)\n",
      "8.28141713142395\n",
      "current at batch: 148 tensor(6.6710, dtype=torch.float64)\n",
      "7.656404733657837\n",
      "current at batch: 149 tensor(6.6132, dtype=torch.float64)\n",
      "7.828288316726685\n",
      "current at batch: 150 tensor(6.8070, dtype=torch.float64)\n",
      "8.419780254364014\n",
      "current at batch: 151 tensor(6.9931, dtype=torch.float64)\n",
      "8.097630023956299\n",
      "current at batch: 152 tensor(6.3565, dtype=torch.float64)\n",
      "7.406400203704834\n",
      "current at batch: 153 tensor(6.6343, dtype=torch.float64)\n",
      "7.5964131355285645\n",
      "current at batch: 154 tensor(6.0827, dtype=torch.float64)\n",
      "7.6251540184021\n",
      "current at batch: 155 tensor(6.3722, dtype=torch.float64)\n",
      "7.680654287338257\n",
      "current at batch: 156 tensor(6.4422, dtype=torch.float64)\n",
      "8.046806573867798\n",
      "current at batch: 157 tensor(6.3318, dtype=torch.float64)\n",
      "8.37517499923706\n",
      "current at batch: 158 tensor(6.7880, dtype=torch.float64)\n",
      "7.9064106941223145\n",
      "current at batch: 159 tensor(6.9915, dtype=torch.float64)\n",
      "7.466958522796631\n",
      "current at batch: 160 tensor(6.7089, dtype=torch.float64)\n",
      "7.959556341171265\n",
      "current at batch: 161 tensor(6.1797, dtype=torch.float64)\n",
      "7.835769176483154\n",
      "current at batch: 162 tensor(6.9863, dtype=torch.float64)\n",
      "8.406420469284058\n",
      "current at batch: 163 tensor(6.7512, dtype=torch.float64)\n",
      "8.328293561935425\n",
      "current at batch: 164 tensor(6.4919, dtype=torch.float64)\n",
      "8.242696046829224\n",
      "current at batch: 165 tensor(6.6968, dtype=torch.float64)\n",
      "8.200212001800537\n",
      "current at batch: 166 tensor(6.4611, dtype=torch.float64)\n",
      "8.218915224075317\n",
      "current at batch: 167 tensor(6.5312, dtype=torch.float64)\n",
      "7.252435684204102\n",
      "current at batch: 168 tensor(6.7028, dtype=torch.float64)\n",
      "8.29792594909668\n",
      "current at batch: 169 tensor(6.4925, dtype=torch.float64)\n",
      "7.609528303146362\n",
      "current at batch: 170 tensor(6.9533, dtype=torch.float64)\n",
      "8.190695524215698\n",
      "current at batch: 171 tensor(6.0360, dtype=torch.float64)\n",
      "7.468902111053467\n",
      "current at batch: 172 tensor(6.7415, dtype=torch.float64)\n",
      "7.953289270401001\n",
      "current at batch: 173 tensor(6.6140, dtype=torch.float64)\n",
      "7.553740739822388\n",
      "current at batch: 174 tensor(6.3290, dtype=torch.float64)\n",
      "7.49335789680481\n",
      "current at batch: 175 tensor(6.4476, dtype=torch.float64)\n",
      "8.088648557662964\n",
      "current at batch: 176 tensor(6.4268, dtype=torch.float64)\n",
      "7.375243902206421\n",
      "current at batch: 177 tensor(6.6428, dtype=torch.float64)\n",
      "7.812658309936523\n",
      "current at batch: 178 tensor(6.4270, dtype=torch.float64)\n",
      "7.063324928283691\n",
      "current at batch: 179 tensor(6.7306, dtype=torch.float64)\n",
      "7.795841932296753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 180 tensor(6.8783, dtype=torch.float64)\n",
      "8.078287839889526\n",
      "current at batch: 181 tensor(6.9075, dtype=torch.float64)\n",
      "7.781985521316528\n",
      "current at batch: 182 tensor(6.2791, dtype=torch.float64)\n",
      "7.797043085098267\n",
      "current at batch: 183 tensor(6.3773, dtype=torch.float64)\n",
      "7.620650768280029\n",
      "current at batch: 184 tensor(6.5287, dtype=torch.float64)\n",
      "8.0233736038208\n",
      "current at batch: 185 tensor(5.9981, dtype=torch.float64)\n",
      "8.113088846206665\n",
      "current at batch: 186 tensor(6.3080, dtype=torch.float64)\n",
      "8.017477035522461\n",
      "current at batch: 187 tensor(6.3300, dtype=torch.float64)\n",
      "7.593899488449097\n",
      "current at batch: 188 tensor(7.4133, dtype=torch.float64)\n",
      "7.792729139328003\n",
      "current at batch: 189 tensor(6.7291, dtype=torch.float64)\n",
      "8.168924331665039\n",
      "current at batch: 190 tensor(7.0127, dtype=torch.float64)\n",
      "8.640803813934326\n",
      "current at batch: 191 tensor(6.7876, dtype=torch.float64)\n",
      "8.552472829818726\n",
      "current at batch: 192 tensor(6.8514, dtype=torch.float64)\n",
      "7.825916290283203\n",
      "current at batch: 193 tensor(6.8463, dtype=torch.float64)\n",
      "7.800779104232788\n",
      "current at batch: 194 tensor(6.2496, dtype=torch.float64)\n",
      "8.343922853469849\n",
      "current at batch: 195 tensor(6.9709, dtype=torch.float64)\n",
      "8.140789270401001\n",
      "current at batch: 196 tensor(6.4009, dtype=torch.float64)\n",
      "8.468918085098267\n",
      "current at batch: 197 tensor(6.4907, dtype=torch.float64)\n",
      "8.303781032562256\n",
      "current at batch: 198 tensor(6.8797, dtype=torch.float64)\n",
      "7.979002237319946\n",
      "current at batch: 199 tensor(6.7092, dtype=torch.float64)\n",
      "8.22541356086731\n",
      "current at batch: 200 tensor(6.2003, dtype=torch.float64)\n",
      "7.443187952041626\n",
      "current at batch: 201 tensor(6.3914, dtype=torch.float64)\n",
      "8.198998928070068\n",
      "current at batch: 202 tensor(6.8625, dtype=torch.float64)\n",
      "8.017729997634888\n",
      "current at batch: 203 tensor(7.0189, dtype=torch.float64)\n",
      "8.078291416168213\n",
      "current at batch: 204 tensor(6.6818, dtype=torch.float64)\n",
      "7.890798330307007\n",
      "current at batch: 205 tensor(6.3234, dtype=torch.float64)\n",
      "7.45332407951355\n",
      "current at batch: 206 tensor(6.7729, dtype=torch.float64)\n",
      "8.38492202758789\n",
      "current at batch: 207 tensor(6.2150, dtype=torch.float64)\n",
      "7.449274301528931\n",
      "current at batch: 208 tensor(6.4384, dtype=torch.float64)\n",
      "7.609584093093872\n",
      "current at batch: 209 tensor(6.3134, dtype=torch.float64)\n",
      "7.625203847885132\n",
      "current at batch: 210 tensor(6.9148, dtype=torch.float64)\n",
      "8.047093152999878\n",
      "current at batch: 211 tensor(6.4052, dtype=torch.float64)\n",
      "7.649838209152222\n",
      "current at batch: 212 tensor(6.4398, dtype=torch.float64)\n",
      "7.859495401382446\n",
      "current at batch: 213 tensor(6.7934, dtype=torch.float64)\n",
      "8.015838384628296\n",
      "current at batch: 214 tensor(6.5611, dtype=torch.float64)\n",
      "7.750210523605347\n",
      "current at batch: 215 tensor(6.5396, dtype=torch.float64)\n",
      "8.119609117507935\n",
      "current at batch: 216 tensor(6.8328, dtype=torch.float64)\n",
      "8.017721176147461\n",
      "current at batch: 217 tensor(6.5178, dtype=torch.float64)\n",
      "7.678895711898804\n",
      "current at batch: 218 tensor(6.7788, dtype=torch.float64)\n",
      "7.890852451324463\n",
      "current at batch: 219 tensor(6.7388, dtype=torch.float64)\n",
      "7.937711477279663\n",
      "current at batch: 220 tensor(6.6992, dtype=torch.float64)\n",
      "7.843962907791138\n",
      "current at batch: 221 tensor(6.9699, dtype=torch.float64)\n",
      "7.81050705909729\n",
      "current at batch: 222 tensor(6.8356, dtype=torch.float64)\n",
      "7.280298471450806\n",
      "current at batch: 223 tensor(6.6755, dtype=torch.float64)\n",
      "7.583854913711548\n",
      "current at batch: 224 tensor(6.6476, dtype=torch.float64)\n",
      "7.7741289138793945\n",
      "current at batch: 225 tensor(7.2023, dtype=torch.float64)\n",
      "8.454005718231201\n",
      "current at batch: 226 tensor(6.6757, dtype=torch.float64)\n",
      "8.209386825561523\n",
      "current at batch: 227 tensor(6.6329, dtype=torch.float64)\n",
      "7.218949794769287\n",
      "current at batch: 228 tensor(6.7377, dtype=torch.float64)\n",
      "7.547079086303711\n",
      "current at batch: 229 tensor(6.1586, dtype=torch.float64)\n",
      "7.859582185745239\n",
      "current at batch: 230 tensor(5.8677, dtype=torch.float64)\n",
      "7.656263113021851\n",
      "current at batch: 231 tensor(6.1884, dtype=torch.float64)\n",
      "7.763240814208984\n",
      "current at batch: 232 tensor(7.1603, dtype=torch.float64)\n",
      "8.437588214874268\n",
      "current at batch: 233 tensor(6.2144, dtype=torch.float64)\n",
      "8.026516437530518\n",
      "current at batch: 234 tensor(6.9280, dtype=torch.float64)\n",
      "7.640828371047974\n",
      "current at batch: 235 tensor(6.9591, dtype=torch.float64)\n",
      "8.085015296936035\n",
      "current at batch: 236 tensor(6.6358, dtype=torch.float64)\n",
      "8.270237445831299\n",
      "current at batch: 237 tensor(6.7022, dtype=torch.float64)\n",
      "8.43772029876709\n",
      "current at batch: 238 tensor(6.5674, dtype=torch.float64)\n",
      "8.062713861465454\n",
      "current at batch: 239 tensor(6.2981, dtype=torch.float64)\n",
      "8.228726625442505\n",
      "current at batch: 240 tensor(6.6656, dtype=torch.float64)\n",
      "7.954023838043213\n",
      "current at batch: 241 tensor(6.7562, dtype=torch.float64)\n",
      "7.957564353942871\n",
      "current at batch: 242 tensor(6.5357, dtype=torch.float64)\n",
      "7.906422853469849\n",
      "current at batch: 243 tensor(6.6703, dtype=torch.float64)\n",
      "7.6251537799835205\n",
      "current at batch: 244 tensor(6.5329, dtype=torch.float64)\n",
      "7.76987361907959\n",
      "current at batch: 245 tensor(6.7855, dtype=torch.float64)\n",
      "7.909284591674805\n",
      "current at batch: 246 tensor(6.2936, dtype=torch.float64)\n",
      "7.812654733657837\n",
      "current at batch: 247 tensor(6.8954, dtype=torch.float64)\n",
      "7.593904495239258\n",
      "current at batch: 248 tensor(6.6415, dtype=torch.float64)\n",
      "8.020341634750366\n",
      "current at batch: 249 tensor(6.5952, dtype=torch.float64)\n",
      "7.658190488815308\n",
      "current at batch: 250 tensor(6.9622, dtype=torch.float64)\n",
      "7.791807651519775\n",
      "current at batch: 251 tensor(6.6535, dtype=torch.float64)\n",
      "7.750156402587891\n",
      "current at batch: 252 tensor(6.4948, dtype=torch.float64)\n",
      "8.218915939331055\n",
      "current at batch: 253 tensor(6.7191, dtype=torch.float64)\n",
      "8.062666177749634\n",
      "current at batch: 254 tensor(6.3353, dtype=torch.float64)\n",
      "8.13650918006897\n",
      "current at batch: 255 tensor(6.0907, dtype=torch.float64)\n",
      "8.231330633163452\n",
      "current at batch: 256 tensor(6.4047, dtype=torch.float64)\n",
      "7.618191242218018\n",
      "current at batch: 257 tensor(6.1887, dtype=torch.float64)\n",
      "8.437670946121216\n",
      "current at batch: 258 tensor(6.7583, dtype=torch.float64)\n",
      "8.655340194702148\n",
      "current at batch: 259 tensor(5.9241, dtype=torch.float64)\n",
      "8.118860006332397\n",
      "current at batch: 260 tensor(6.2442, dtype=torch.float64)\n",
      "8.250166416168213\n",
      "current at batch: 261 tensor(6.5748, dtype=torch.float64)\n",
      "7.76578426361084\n",
      "current at batch: 262 tensor(6.0525, dtype=torch.float64)\n",
      "7.935804128646851\n",
      "current at batch: 263 tensor(6.1515, dtype=torch.float64)\n",
      "8.807344675064087\n",
      "current at batch: 264 tensor(7.1116, dtype=torch.float64)\n",
      "8.282245635986328\n",
      "current at batch: 265 tensor(6.6016, dtype=torch.float64)\n",
      "7.828285455703735\n",
      "current at batch: 266 tensor(7.0607, dtype=torch.float64)\n",
      "8.093915939331055\n",
      "current at batch: 267 tensor(6.7482, dtype=torch.float64)\n",
      "8.453295469284058\n",
      "current at batch: 268 tensor(6.5238, dtype=torch.float64)\n",
      "7.994143009185791\n",
      "current at batch: 269 tensor(6.5480, dtype=torch.float64)\n",
      "8.274700403213501\n",
      "current at batch: 270 tensor(6.3302, dtype=torch.float64)\n",
      "7.809417247772217\n",
      "current at batch: 271 tensor(6.7184, dtype=torch.float64)\n",
      "7.687657594680786\n",
      "current at batch: 272 tensor(6.5533, dtype=torch.float64)\n",
      "7.809619903564453\n",
      "current at batch: 273 tensor(6.6422, dtype=torch.float64)\n",
      "8.14170217514038\n",
      "current at batch: 274 tensor(6.3912, dtype=torch.float64)\n",
      "8.750176668167114\n",
      "current at batch: 275 tensor(6.5355, dtype=torch.float64)\n",
      "7.515787601470947\n",
      "current at batch: 276 tensor(6.4487, dtype=torch.float64)\n",
      "8.359543323516846\n",
      "current at batch: 277 tensor(5.7749, dtype=torch.float64)\n",
      "7.7478187084198\n",
      "current at batch: 278 tensor(6.4630, dtype=torch.float64)\n",
      "7.287431478500366\n",
      "current at batch: 279 tensor(6.3150, dtype=torch.float64)\n",
      "7.875161170959473\n",
      "current at batch: 280 tensor(6.4624, dtype=torch.float64)\n",
      "8.012609958648682\n",
      "current at batch: 281 tensor(6.3280, dtype=torch.float64)\n",
      "7.984537124633789\n",
      "current at batch: 282 tensor(6.6304, dtype=torch.float64)\n",
      "7.952289819717407\n",
      "current at batch: 283 tensor(6.7930, dtype=torch.float64)\n",
      "8.453436613082886\n",
      "current at batch: 284 tensor(6.3109, dtype=torch.float64)\n",
      "8.922059535980225\n",
      "current at batch: 285 tensor(6.6937, dtype=torch.float64)\n",
      "7.790059804916382\n",
      "current at batch: 286 tensor(6.1793, dtype=torch.float64)\n",
      "8.20331358909607\n",
      "current at batch: 287 tensor(6.5159, dtype=torch.float64)\n",
      "8.288660049438477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 288 tensor(6.6309, dtype=torch.float64)\n",
      "8.253637313842773\n",
      "current at batch: 289 tensor(6.8472, dtype=torch.float64)\n",
      "8.531424760818481\n",
      "current at batch: 290 tensor(6.5931, dtype=torch.float64)\n",
      "8.250166177749634\n",
      "current at batch: 291 tensor(6.2857, dtype=torch.float64)\n",
      "7.854451656341553\n",
      "current at batch: 292 tensor(6.3028, dtype=torch.float64)\n",
      "7.687385082244873\n",
      "current at batch: 293 tensor(6.9238, dtype=torch.float64)\n",
      "7.970120191574097\n",
      "current at batch: 294 tensor(6.5535, dtype=torch.float64)\n",
      "8.203290462493896\n",
      "current at batch: 295 tensor(6.5374, dtype=torch.float64)\n",
      "8.828312158584595\n",
      "current at batch: 296 tensor(6.4908, dtype=torch.float64)\n",
      "7.556117057800293\n",
      "current at batch: 297 tensor(6.4445, dtype=torch.float64)\n",
      "7.808705806732178\n",
      "current at batch: 298 tensor(6.1295, dtype=torch.float64)\n",
      "7.656423807144165\n",
      "current at batch: 299 tensor(6.3977, dtype=torch.float64)\n",
      "8.672051906585693\n",
      "current at batch: 300 tensor(6.8998, dtype=torch.float64)\n",
      "8.34461259841919\n",
      "current at batch: 301 tensor(6.4404, dtype=torch.float64)\n",
      "8.295236349105835\n",
      "current at batch: 302 tensor(6.5988, dtype=torch.float64)\n",
      "8.218916177749634\n",
      "current at batch: 303 tensor(6.7556, dtype=torch.float64)\n",
      "7.843908786773682\n",
      "current at batch: 304 tensor(6.7896, dtype=torch.float64)\n",
      "7.83764386177063\n",
      "current at batch: 305 tensor(6.6458, dtype=torch.float64)\n",
      "8.78832197189331\n",
      "current at batch: 306 tensor(6.2857, dtype=torch.float64)\n",
      "8.052883625030518\n",
      "current at batch: 307 tensor(6.7181, dtype=torch.float64)\n",
      "8.484554052352905\n",
      "current at batch: 308 tensor(6.0196, dtype=torch.float64)\n",
      "7.881593227386475\n",
      "current at batch: 309 tensor(6.5994, dtype=torch.float64)\n",
      "8.468920707702637\n",
      "current at batch: 310 tensor(6.9417, dtype=torch.float64)\n",
      "8.416942834854126\n",
      "current at batch: 311 tensor(7.0323, dtype=torch.float64)\n",
      "7.9364659786224365\n",
      "current at batch: 312 tensor(6.4527, dtype=torch.float64)\n",
      "7.457733392715454\n",
      "current at batch: 313 tensor(6.2712, dtype=torch.float64)\n",
      "7.968912124633789\n",
      "current at batch: 314 tensor(6.3987, dtype=torch.float64)\n",
      "8.309647798538208\n",
      "current at batch: 315 tensor(6.1520, dtype=torch.float64)\n",
      "8.177882671356201\n",
      "current at batch: 316 tensor(6.1980, dtype=torch.float64)\n",
      "8.116144180297852\n",
      "current at batch: 317 tensor(6.4456, dtype=torch.float64)\n",
      "8.04704213142395\n",
      "current at batch: 318 tensor(6.9252, dtype=torch.float64)\n",
      "8.203291177749634\n",
      "current at batch: 319 tensor(6.3418, dtype=torch.float64)\n",
      "8.32498574256897\n",
      "current at batch: 320 tensor(6.4408, dtype=torch.float64)\n",
      "8.028127193450928\n",
      "current at batch: 321 tensor(6.4507, dtype=torch.float64)\n",
      "8.062658071517944\n",
      "current at batch: 322 tensor(6.7007, dtype=torch.float64)\n",
      "7.937661647796631\n",
      "current at batch: 323 tensor(6.6708, dtype=torch.float64)\n",
      "7.825229167938232\n",
      "current at batch: 324 tensor(7.1464, dtype=torch.float64)\n",
      "8.773538827896118\n",
      "current at batch: 325 tensor(7.0158, dtype=torch.float64)\n",
      "8.33210301399231\n",
      "current at batch: 326 tensor(6.3613, dtype=torch.float64)\n",
      "8.82831335067749\n",
      "current at batch: 327 tensor(6.6549, dtype=torch.float64)\n",
      "8.237176656723022\n",
      "current at batch: 328 tensor(6.3428, dtype=torch.float64)\n",
      "8.113310813903809\n",
      "current at batch: 329 tensor(6.3965, dtype=torch.float64)\n",
      "8.301257610321045\n",
      "current at batch: 330 tensor(6.4123, dtype=torch.float64)\n",
      "8.218915939331055\n",
      "current at batch: 331 tensor(6.8049, dtype=torch.float64)\n",
      "8.186537027359009\n",
      "current at batch: 332 tensor(6.5106, dtype=torch.float64)\n",
      "7.875162839889526\n",
      "current at batch: 333 tensor(6.3344, dtype=torch.float64)\n",
      "8.718703269958496\n",
      "current at batch: 334 tensor(6.5452, dtype=torch.float64)\n",
      "8.062596797943115\n",
      "current at batch: 335 tensor(6.3632, dtype=torch.float64)\n",
      "8.240143537521362\n",
      "current at batch: 336 tensor(5.7656, dtype=torch.float64)\n",
      "7.98453426361084\n",
      "current at batch: 337 tensor(6.5304, dtype=torch.float64)\n",
      "8.031422138214111\n",
      "current at batch: 338 tensor(6.9189, dtype=torch.float64)\n",
      "8.172203302383423\n",
      "current at batch: 339 tensor(6.5742, dtype=torch.float64)\n",
      "8.188138246536255\n",
      "current at batch: 340 tensor(6.0238, dtype=torch.float64)\n",
      "8.062676429748535\n",
      "current at batch: 341 tensor(6.8776, dtype=torch.float64)\n",
      "8.828311204910278\n",
      "current at batch: 342 tensor(6.3057, dtype=torch.float64)\n",
      "8.509387969970703\n",
      "current at batch: 343 tensor(6.7044, dtype=torch.float64)\n",
      "8.704091787338257\n",
      "current at batch: 344 tensor(6.5969, dtype=torch.float64)\n",
      "8.59392523765564\n",
      "current at batch: 345 tensor(6.3190, dtype=torch.float64)\n",
      "7.750156402587891\n",
      "current at batch: 346 tensor(6.2411, dtype=torch.float64)\n",
      "7.9784722328186035\n",
      "current at batch: 347 tensor(6.7910, dtype=torch.float64)\n",
      "9.190599918365479\n",
      "current at batch: 348 tensor(6.2851, dtype=torch.float64)\n",
      "7.7425315380096436\n",
      "current at batch: 349 tensor(6.2102, dtype=torch.float64)\n",
      "8.734554052352905\n",
      "current at batch: 350 tensor(6.2444, dtype=torch.float64)\n",
      "8.203293085098267\n",
      "current at batch: 351 tensor(6.2020, dtype=torch.float64)\n",
      "7.8721277713775635\n",
      "current at batch: 352 tensor(6.6610, dtype=torch.float64)\n",
      "8.625022411346436\n",
      "current at batch: 353 tensor(6.9107, dtype=torch.float64)\n",
      "7.980950832366943\n",
      "current at batch: 354 tensor(6.7216, dtype=torch.float64)\n",
      "8.5002281665802\n",
      "current at batch: 355 tensor(5.8899, dtype=torch.float64)\n",
      "7.437692165374756\n",
      "current at batch: 356 tensor(6.4391, dtype=torch.float64)\n",
      "8.251425981521606\n",
      "current at batch: 357 tensor(6.3507, dtype=torch.float64)\n",
      "8.226195096969604\n",
      "current at batch: 358 tensor(6.5811, dtype=torch.float64)\n",
      "8.218971490859985\n",
      "current at batch: 359 tensor(6.2931, dtype=torch.float64)\n",
      "8.667460680007935\n",
      "current at batch: 360 tensor(6.0670, dtype=torch.float64)\n",
      "8.047088146209717\n",
      "current at batch: 361 tensor(6.4062, dtype=torch.float64)\n",
      "7.473531007766724\n",
      "current at batch: 362 tensor(6.7257, dtype=torch.float64)\n",
      "7.84297251701355\n",
      "current at batch: 363 tensor(7.0021, dtype=torch.float64)\n",
      "8.156472206115723\n",
      "current at batch: 364 tensor(6.7378, dtype=torch.float64)\n",
      "8.187715530395508\n",
      "current at batch: 365 tensor(6.5649, dtype=torch.float64)\n",
      "8.000213861465454\n",
      "current at batch: 366 tensor(6.2081, dtype=torch.float64)\n",
      "7.624621868133545\n",
      "current at batch: 367 tensor(6.6336, dtype=torch.float64)\n",
      "7.685462713241577\n",
      "current at batch: 368 tensor(6.6639, dtype=torch.float64)\n",
      "8.125216484069824\n",
      "current at batch: 369 tensor(6.1155, dtype=torch.float64)\n",
      "8.136187076568604\n",
      "current at batch: 370 tensor(6.0730, dtype=torch.float64)\n",
      "7.507483959197998\n",
      "current at batch: 371 tensor(6.6876, dtype=torch.float64)\n",
      "8.217036008834839\n",
      "current at batch: 372 tensor(6.3882, dtype=torch.float64)\n",
      "7.968968152999878\n",
      "current at batch: 373 tensor(6.4322, dtype=torch.float64)\n",
      "8.140856504440308\n",
      "current at batch: 374 tensor(6.7184, dtype=torch.float64)\n",
      "8.359598636627197\n",
      "current at batch: 375 tensor(6.2270, dtype=torch.float64)\n",
      "8.096662998199463\n",
      "current at batch: 376 tensor(6.5649, dtype=torch.float64)\n",
      "7.8388237953186035\n",
      "current at batch: 377 tensor(7.0286, dtype=torch.float64)\n",
      "8.031468868255615\n",
      "current at batch: 378 tensor(6.7161, dtype=torch.float64)\n",
      "7.828328847885132\n",
      "current at batch: 379 tensor(5.8339, dtype=torch.float64)\n",
      "7.312695264816284\n",
      "current at batch: 380 tensor(6.4838, dtype=torch.float64)\n",
      "7.810210704803467\n",
      "current at batch: 381 tensor(6.3551, dtype=torch.float64)\n",
      "7.669432878494263\n",
      "current at batch: 382 tensor(5.9755, dtype=torch.float64)\n",
      "8.10959529876709\n",
      "current at batch: 383 tensor(6.3179, dtype=torch.float64)\n",
      "7.326413631439209\n",
      "current at batch: 384 tensor(6.2897, dtype=torch.float64)\n",
      "7.822477579116821\n",
      "current at batch: 385 tensor(6.6867, dtype=torch.float64)\n",
      "7.323636770248413\n",
      "current at batch: 386 tensor(6.2496, dtype=torch.float64)\n",
      "7.5207483768463135\n",
      "current at batch: 387 tensor(6.5908, dtype=torch.float64)\n",
      "7.797086000442505\n",
      "current at batch: 388 tensor(6.4896, dtype=torch.float64)\n",
      "7.468914985656738\n",
      "current at batch: 389 tensor(6.2663, dtype=torch.float64)\n",
      "8.03141450881958\n",
      "current at batch: 390 tensor(6.4836, dtype=torch.float64)\n",
      "8.42688250541687\n",
      "current at batch: 391 tensor(6.2430, dtype=torch.float64)\n",
      "7.606679439544678\n",
      "current at batch: 392 tensor(6.6324, dtype=torch.float64)\n",
      "8.43649411201477\n",
      "current at batch: 393 tensor(6.8937, dtype=torch.float64)\n",
      "7.87516450881958\n",
      "current at batch: 394 tensor(6.3436, dtype=torch.float64)\n",
      "7.703280687332153\n",
      "current at batch: 395 tensor(6.2396, dtype=torch.float64)\n",
      "7.78304648399353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 396 tensor(6.4047, dtype=torch.float64)\n",
      "7.821781635284424\n",
      "current at batch: 397 tensor(6.4069, dtype=torch.float64)\n",
      "7.422024726867676\n",
      "current at batch: 398 tensor(7.0603, dtype=torch.float64)\n",
      "8.562674045562744\n",
      "current at batch: 399 tensor(6.7221, dtype=torch.float64)\n",
      "7.797046661376953\n",
      "current at batch: 400 tensor(6.7844, dtype=torch.float64)\n",
      "7.974440813064575\n",
      "current at batch: 401 tensor(7.0844, dtype=torch.float64)\n",
      "8.184546709060669\n",
      "current at batch: 402 tensor(6.1939, dtype=torch.float64)\n",
      "8.031411409378052\n",
      "current at batch: 403 tensor(6.1471, dtype=torch.float64)\n",
      "7.651712894439697\n",
      "current at batch: 404 tensor(6.3547, dtype=torch.float64)\n",
      "8.043872117996216\n",
      "current at batch: 405 tensor(6.7453, dtype=torch.float64)\n",
      "8.768602848052979\n",
      "current at batch: 406 tensor(6.5800, dtype=torch.float64)\n",
      "8.203311443328857\n",
      "current at batch: 407 tensor(6.1819, dtype=torch.float64)\n",
      "8.297042608261108\n",
      "current at batch: 408 tensor(6.6556, dtype=torch.float64)\n",
      "8.367629289627075\n",
      "current at batch: 409 tensor(6.2977, dtype=torch.float64)\n",
      "8.125975847244263\n",
      "current at batch: 410 tensor(7.2303, dtype=torch.float64)\n",
      "8.10446834564209\n",
      "current at batch: 411 tensor(6.2914, dtype=torch.float64)\n",
      "8.109560489654541\n",
      "current at batch: 412 tensor(6.3440, dtype=torch.float64)\n",
      "7.765799045562744\n",
      "current at batch: 413 tensor(7.2131, dtype=torch.float64)\n",
      "8.218912839889526\n",
      "current at batch: 414 tensor(6.0605, dtype=torch.float64)\n",
      "7.650167465209961\n",
      "current at batch: 415 tensor(6.0653, dtype=torch.float64)\n",
      "8.368642330169678\n",
      "current at batch: 416 tensor(6.4626, dtype=torch.float64)\n",
      "8.282646417617798\n",
      "current at batch: 417 tensor(6.1060, dtype=torch.float64)\n",
      "7.953293085098267\n",
      "current at batch: 418 tensor(6.2567, dtype=torch.float64)\n",
      "7.922034502029419\n",
      "current at batch: 419 tensor(6.2007, dtype=torch.float64)\n",
      "7.799771547317505\n",
      "current at batch: 420 tensor(5.5844, dtype=torch.float64)\n",
      "8.009092092514038\n",
      "current at batch: 421 tensor(6.3543, dtype=torch.float64)\n",
      "7.828283786773682\n",
      "current at batch: 422 tensor(6.6495, dtype=torch.float64)\n",
      "8.797064781188965\n",
      "current at batch: 423 tensor(6.6482, dtype=torch.float64)\n",
      "7.308955430984497\n",
      "current at batch: 424 tensor(6.9681, dtype=torch.float64)\n",
      "8.454082727432251\n",
      "current at batch: 425 tensor(6.1238, dtype=torch.float64)\n",
      "7.797033071517944\n",
      "current at batch: 426 tensor(5.6070, dtype=torch.float64)\n",
      "7.5782859325408936\n",
      "current at batch: 427 tensor(6.1525, dtype=torch.float64)\n",
      "7.781409502029419\n",
      "current at batch: 428 tensor(6.5874, dtype=torch.float64)\n",
      "8.43639850616455\n",
      "current at batch: 429 tensor(6.5682, dtype=torch.float64)\n",
      "7.772392511367798\n",
      "current at batch: 430 tensor(5.9066, dtype=torch.float64)\n",
      "8.000158786773682\n",
      "current at batch: 431 tensor(6.0963, dtype=torch.float64)\n",
      "7.496258735656738\n",
      "current at batch: 432 tensor(6.0716, dtype=torch.float64)\n",
      "8.16471266746521\n",
      "current at batch: 433 tensor(6.6288, dtype=torch.float64)\n",
      "8.152254104614258\n",
      "current at batch: 434 tensor(6.3361, dtype=torch.float64)\n",
      "8.076272964477539\n",
      "current at batch: 435 tensor(6.2949, dtype=torch.float64)\n",
      "8.203292608261108\n",
      "current at batch: 436 tensor(6.4263, dtype=torch.float64)\n",
      "7.703289985656738\n",
      "current at batch: 437 tensor(6.6599, dtype=torch.float64)\n",
      "7.781407117843628\n",
      "current at batch: 438 tensor(6.0373, dtype=torch.float64)\n",
      "7.174380540847778\n",
      "current at batch: 439 tensor(6.1746, dtype=torch.float64)\n",
      "8.082967281341553\n",
      "current at batch: 440 tensor(6.4586, dtype=torch.float64)\n",
      "7.491057395935059\n",
      "current at batch: 441 tensor(6.5301, dtype=torch.float64)\n",
      "7.531402349472046\n",
      "current at batch: 442 tensor(6.4182, dtype=torch.float64)\n",
      "8.156419038772583\n",
      "current at batch: 443 tensor(6.4997, dtype=torch.float64)\n",
      "8.043735265731812\n",
      "current at batch: 444 tensor(6.5967, dtype=torch.float64)\n",
      "8.05963134765625\n",
      "current at batch: 445 tensor(6.3632, dtype=torch.float64)\n",
      "7.437650203704834\n",
      "current at batch: 446 tensor(6.7428, dtype=torch.float64)\n",
      "7.32827353477478\n",
      "current at batch: 447 tensor(6.5753, dtype=torch.float64)\n",
      "6.892361164093018\n",
      "current at batch: 448 tensor(5.9222, dtype=torch.float64)\n",
      "7.173848390579224\n",
      "current at batch: 449 tensor(6.6022, dtype=torch.float64)\n",
      "6.957773685455322\n",
      "current at batch: 450 tensor(6.4659, dtype=torch.float64)\n",
      "7.8907904624938965\n",
      "current at batch: 451 tensor(6.9287, dtype=torch.float64)\n",
      "7.562664747238159\n",
      "current at batch: 452 tensor(6.9428, dtype=torch.float64)\n",
      "8.468921184539795\n",
      "current at batch: 453 tensor(6.8418, dtype=torch.float64)\n",
      "7.848598003387451\n",
      "current at batch: 454 tensor(6.9173, dtype=torch.float64)\n",
      "7.542904853820801\n",
      "current at batch: 455 tensor(6.5005, dtype=torch.float64)\n",
      "7.4891862869262695\n",
      "current at batch: 456 tensor(6.1758, dtype=torch.float64)\n",
      "7.3751442432403564\n",
      "current at batch: 457 tensor(6.5448, dtype=torch.float64)\n",
      "7.65976357460022\n",
      "current at batch: 458 tensor(6.0330, dtype=torch.float64)\n",
      "7.200428009033203\n",
      "current at batch: 459 tensor(5.6683, dtype=torch.float64)\n",
      "7.519517660140991\n",
      "current at batch: 460 tensor(6.0879, dtype=torch.float64)\n",
      "8.187665462493896\n",
      "current at batch: 461 tensor(5.7836, dtype=torch.float64)\n",
      "7.687669038772583\n",
      "current at batch: 462 tensor(7.1519, dtype=torch.float64)\n",
      "7.8907997608184814\n",
      "current at batch: 463 tensor(6.1254, dtype=torch.float64)\n",
      "7.414167881011963\n",
      "current at batch: 464 tensor(7.0404, dtype=torch.float64)\n",
      "7.946771860122681\n",
      "current at batch: 465 tensor(6.4137, dtype=torch.float64)\n",
      "8.390859842300415\n",
      "current at batch: 466 tensor(6.0520, dtype=torch.float64)\n",
      "7.781466245651245\n",
      "current at batch: 467 tensor(6.7600, dtype=torch.float64)\n",
      "7.875215530395508\n",
      "current at batch: 468 tensor(6.9312, dtype=torch.float64)\n",
      "7.776286602020264\n",
      "current at batch: 469 tensor(5.7971, dtype=torch.float64)\n",
      "7.8586931228637695\n",
      "current at batch: 470 tensor(6.6743, dtype=torch.float64)\n",
      "7.718954086303711\n",
      "current at batch: 471 tensor(6.6290, dtype=torch.float64)\n",
      "8.009215593338013\n",
      "current at batch: 472 tensor(3.9479, dtype=torch.float64)\n",
      "1.359415054321289\n",
      "epoch =  1 \n",
      " tensor(3107.3513, dtype=torch.float64)\n",
      "current at batch: 1 tensor(6.3102, dtype=torch.float64)\n",
      "8.031468868255615\n",
      "current at batch: 2 tensor(6.3085, dtype=torch.float64)\n",
      "7.456046104431152\n",
      "current at batch: 3 tensor(6.4075, dtype=torch.float64)\n",
      "7.569094181060791\n",
      "current at batch: 4 tensor(5.7854, dtype=torch.float64)\n",
      "7.797084093093872\n",
      "current at batch: 5 tensor(6.5230, dtype=torch.float64)\n",
      "8.156472206115723\n",
      "current at batch: 6 tensor(6.3028, dtype=torch.float64)\n",
      "7.672079086303711\n",
      "current at batch: 7 tensor(6.3377, dtype=torch.float64)\n",
      "7.700358152389526\n",
      "current at batch: 8 tensor(6.2414, dtype=torch.float64)\n",
      "8.003961324691772\n",
      "current at batch: 9 tensor(6.2790, dtype=torch.float64)\n",
      "7.640832185745239\n",
      "current at batch: 10 tensor(6.3215, dtype=torch.float64)\n",
      "8.125211238861084\n",
      "current at batch: 11 tensor(6.3858, dtype=torch.float64)\n",
      "7.971286773681641\n",
      "current at batch: 12 tensor(6.1165, dtype=torch.float64)\n",
      "7.677953243255615\n",
      "current at batch: 13 tensor(6.8507, dtype=torch.float64)\n",
      "7.71111536026001\n",
      "current at batch: 14 tensor(6.2886, dtype=torch.float64)\n",
      "7.109567880630493\n",
      "current at batch: 15 tensor(6.6363, dtype=torch.float64)\n",
      "7.297077178955078\n",
      "current at batch: 16 tensor(5.3038, dtype=torch.float64)\n",
      "7.384242057800293\n",
      "current at batch: 17 tensor(6.3386, dtype=torch.float64)\n",
      "7.39631724357605\n",
      "current at batch: 18 tensor(6.0005, dtype=torch.float64)\n",
      "7.0146214962005615\n",
      "current at batch: 19 tensor(5.4810, dtype=torch.float64)\n",
      "7.51582407951355\n",
      "current at batch: 20 tensor(6.3719, dtype=torch.float64)\n",
      "7.562713623046875\n",
      "current at batch: 21 tensor(6.8126, dtype=torch.float64)\n",
      "7.547070503234863\n",
      "current at batch: 22 tensor(6.4496, dtype=torch.float64)\n",
      "7.014991044998169\n",
      "current at batch: 23 tensor(6.1511, dtype=torch.float64)\n",
      "7.443542718887329\n",
      "current at batch: 24 tensor(6.0879, dtype=torch.float64)\n",
      "7.703348398208618\n",
      "current at batch: 25 tensor(6.8659, dtype=torch.float64)\n",
      "8.092880249023438\n",
      "current at batch: 26 tensor(6.1264, dtype=torch.float64)\n",
      "7.297066926956177\n",
      "current at batch: 27 tensor(6.0385, dtype=torch.float64)\n",
      "6.875183343887329\n",
      "current at batch: 28 tensor(6.4789, dtype=torch.float64)\n",
      "7.0396552085876465\n",
      "current at batch: 29 tensor(6.5063, dtype=torch.float64)\n",
      "8.100062131881714\n",
      "current at batch: 30 tensor(5.9179, dtype=torch.float64)\n",
      "6.9845287799835205\n",
      "current at batch: 31 tensor(6.6038, dtype=torch.float64)\n",
      "7.656404972076416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 32 tensor(6.4116, dtype=torch.float64)\n",
      "7.3439109325408936\n",
      "current at batch: 33 tensor(6.3464, dtype=torch.float64)\n",
      "7.306866407394409\n",
      "current at batch: 34 tensor(6.7929, dtype=torch.float64)\n",
      "8.277787208557129\n",
      "current at batch: 35 tensor(6.4739, dtype=torch.float64)\n",
      "7.43764591217041\n",
      "current at batch: 36 tensor(6.3566, dtype=torch.float64)\n",
      "7.562655687332153\n",
      "current at batch: 37 tensor(6.8560, dtype=torch.float64)\n",
      "7.701962947845459\n",
      "current at batch: 38 tensor(6.2793, dtype=torch.float64)\n",
      "7.4563188552856445\n",
      "current at batch: 39 tensor(6.5153, dtype=torch.float64)\n",
      "7.747666835784912\n",
      "current at batch: 40 tensor(6.3795, dtype=torch.float64)\n",
      "7.406407117843628\n",
      "current at batch: 41 tensor(6.6542, dtype=torch.float64)\n",
      "7.934751749038696\n",
      "current at batch: 42 tensor(6.7069, dtype=torch.float64)\n",
      "7.578277587890625\n",
      "current at batch: 43 tensor(6.3416, dtype=torch.float64)\n",
      "7.377512454986572\n",
      "current at batch: 44 tensor(6.6030, dtype=torch.float64)\n",
      "7.195460557937622\n",
      "current at batch: 45 tensor(6.7225, dtype=torch.float64)\n",
      "7.359523773193359\n",
      "current at batch: 46 tensor(6.7315, dtype=torch.float64)\n",
      "8.328289270401001\n",
      "current at batch: 47 tensor(6.2008, dtype=torch.float64)\n",
      "7.3907835483551025\n",
      "current at batch: 48 tensor(6.7952, dtype=torch.float64)\n",
      "7.613234519958496\n",
      "current at batch: 49 tensor(6.3133, dtype=torch.float64)\n",
      "7.633527040481567\n",
      "current at batch: 50 tensor(6.5609, dtype=torch.float64)\n",
      "7.343900442123413\n",
      "current at batch: 51 tensor(6.3199, dtype=torch.float64)\n",
      "7.50015115737915\n",
      "current at batch: 52 tensor(6.2473, dtype=torch.float64)\n",
      "7.656404733657837\n",
      "current at batch: 53 tensor(5.8120, dtype=torch.float64)\n",
      "7.274435997009277\n",
      "current at batch: 54 tensor(6.7579, dtype=torch.float64)\n",
      "8.050660133361816\n",
      "current at batch: 55 tensor(6.4033, dtype=torch.float64)\n",
      "7.515782117843628\n",
      "current at batch: 56 tensor(6.6539, dtype=torch.float64)\n",
      "7.2657763957977295\n",
      "current at batch: 57 tensor(6.1128, dtype=torch.float64)\n",
      "7.484525918960571\n",
      "current at batch: 58 tensor(6.6462, dtype=torch.float64)\n",
      "7.802354097366333\n",
      "current at batch: 59 tensor(6.1339, dtype=torch.float64)\n",
      "7.9347052574157715\n",
      "current at batch: 60 tensor(6.3459, dtype=torch.float64)\n",
      "7.718906879425049\n",
      "current at batch: 61 tensor(6.3268, dtype=torch.float64)\n",
      "7.922043800354004\n",
      "current at batch: 62 tensor(6.7554, dtype=torch.float64)\n",
      "7.750161409378052\n",
      "current at batch: 63 tensor(6.6231, dtype=torch.float64)\n",
      "7.879220485687256\n",
      "current at batch: 64 tensor(6.8831, dtype=torch.float64)\n",
      "7.380841016769409\n",
      "current at batch: 65 tensor(6.5079, dtype=torch.float64)\n",
      "7.812657833099365\n",
      "current at batch: 66 tensor(6.3573, dtype=torch.float64)\n",
      "7.486999750137329\n",
      "current at batch: 67 tensor(6.4131, dtype=torch.float64)\n",
      "7.453274965286255\n",
      "current at batch: 68 tensor(6.8118, dtype=torch.float64)\n",
      "7.484527826309204\n",
      "current at batch: 69 tensor(6.7045, dtype=torch.float64)\n",
      "6.908179759979248\n",
      "current at batch: 70 tensor(5.9701, dtype=torch.float64)\n",
      "7.059370279312134\n",
      "current at batch: 71 tensor(7.2987, dtype=torch.float64)\n",
      "8.055630922317505\n",
      "current at batch: 72 tensor(6.7565, dtype=torch.float64)\n",
      "7.625153303146362\n",
      "current at batch: 73 tensor(6.3245, dtype=torch.float64)\n",
      "7.422025918960571\n",
      "current at batch: 74 tensor(6.1580, dtype=torch.float64)\n",
      "7.028775930404663\n",
      "current at batch: 75 tensor(6.5075, dtype=torch.float64)\n",
      "7.534241676330566\n",
      "current at batch: 76 tensor(6.4324, dtype=torch.float64)\n",
      "7.422025442123413\n",
      "current at batch: 77 tensor(6.5417, dtype=torch.float64)\n",
      "7.562652587890625\n",
      "current at batch: 78 tensor(6.3326, dtype=torch.float64)\n",
      "7.140770673751831\n",
      "current at batch: 79 tensor(5.9517, dtype=torch.float64)\n",
      "7.642956972122192\n",
      "current at batch: 80 tensor(6.1422, dtype=torch.float64)\n",
      "7.248122930526733\n",
      "current at batch: 81 tensor(6.4006, dtype=torch.float64)\n",
      "7.359525442123413\n",
      "current at batch: 82 tensor(6.6452, dtype=torch.float64)\n",
      "7.453289031982422\n",
      "current at batch: 83 tensor(6.8532, dtype=torch.float64)\n",
      "8.09391713142395\n",
      "current at batch: 84 tensor(6.0741, dtype=torch.float64)\n",
      "7.736316204071045\n",
      "current at batch: 85 tensor(5.7901, dtype=torch.float64)\n",
      "7.28758430480957\n",
      "current at batch: 86 tensor(5.9526, dtype=torch.float64)\n",
      "7.562654972076416\n",
      "current at batch: 87 tensor(6.6135, dtype=torch.float64)\n",
      "7.390783786773682\n",
      "current at batch: 88 tensor(6.1223, dtype=torch.float64)\n",
      "8.024073362350464\n",
      "current at batch: 89 tensor(6.3846, dtype=torch.float64)\n",
      "8.16413927078247\n",
      "current at batch: 90 tensor(6.3635, dtype=torch.float64)\n",
      "8.046181678771973\n",
      "current at batch: 91 tensor(6.2149, dtype=torch.float64)\n",
      "7.828282833099365\n",
      "current at batch: 92 tensor(6.5907, dtype=torch.float64)\n",
      "7.843915224075317\n",
      "current at batch: 93 tensor(6.3668, dtype=torch.float64)\n",
      "7.656404495239258\n",
      "current at batch: 94 tensor(6.1569, dtype=torch.float64)\n",
      "7.187648296356201\n",
      "current at batch: 95 tensor(6.4548, dtype=torch.float64)\n",
      "7.931732892990112\n",
      "current at batch: 96 tensor(6.1307, dtype=torch.float64)\n",
      "7.57829475402832\n",
      "current at batch: 97 tensor(6.0126, dtype=torch.float64)\n",
      "7.609526634216309\n",
      "current at batch: 98 tensor(6.1578, dtype=torch.float64)\n",
      "7.672043800354004\n",
      "current at batch: 99 tensor(6.4530, dtype=torch.float64)\n",
      "7.5721964836120605\n",
      "current at batch: 100 tensor(6.5355, dtype=torch.float64)\n",
      "8.301651239395142\n",
      "current at batch: 101 tensor(6.7566, dtype=torch.float64)\n",
      "7.6564202308654785\n",
      "current at batch: 102 tensor(6.1865, dtype=torch.float64)\n",
      "8.343920946121216\n",
      "current at batch: 103 tensor(6.6878, dtype=torch.float64)\n",
      "7.797034502029419\n",
      "current at batch: 104 tensor(6.3281, dtype=torch.float64)\n",
      "7.828289985656738\n",
      "current at batch: 105 tensor(6.1745, dtype=torch.float64)\n",
      "7.755857229232788\n",
      "current at batch: 106 tensor(6.2110, dtype=torch.float64)\n",
      "7.812658309936523\n",
      "current at batch: 107 tensor(5.8553, dtype=torch.float64)\n",
      "7.290074586868286\n",
      "current at batch: 108 tensor(6.5419, dtype=torch.float64)\n",
      "7.312648296356201\n",
      "current at batch: 109 tensor(6.2756, dtype=torch.float64)\n",
      "7.187641620635986\n",
      "current at batch: 110 tensor(6.0413, dtype=torch.float64)\n",
      "7.58307957649231\n",
      "current at batch: 111 tensor(6.1797, dtype=torch.float64)\n",
      "7.734467267990112\n",
      "current at batch: 112 tensor(6.2521, dtype=torch.float64)\n",
      "7.547030448913574\n",
      "current at batch: 113 tensor(6.3325, dtype=torch.float64)\n",
      "7.849427223205566\n",
      "current at batch: 114 tensor(6.0218, dtype=torch.float64)\n",
      "7.281397104263306\n",
      "current at batch: 115 tensor(6.5847, dtype=torch.float64)\n",
      "7.52303147315979\n",
      "current at batch: 116 tensor(6.1493, dtype=torch.float64)\n",
      "7.6487462520599365\n",
      "current at batch: 117 tensor(6.2799, dtype=torch.float64)\n",
      "7.812666654586792\n",
      "current at batch: 118 tensor(6.3558, dtype=torch.float64)\n",
      "7.250147104263306\n",
      "current at batch: 119 tensor(6.4127, dtype=torch.float64)\n",
      "7.672029972076416\n",
      "current at batch: 120 tensor(5.9196, dtype=torch.float64)\n",
      "7.55836820602417\n",
      "current at batch: 121 tensor(6.0339, dtype=torch.float64)\n",
      "7.813823461532593\n",
      "current at batch: 122 tensor(5.7647, dtype=torch.float64)\n",
      "7.669351577758789\n",
      "current at batch: 123 tensor(6.0520, dtype=torch.float64)\n",
      "7.983385801315308\n",
      "current at batch: 124 tensor(6.1208, dtype=torch.float64)\n",
      "7.640798330307007\n",
      "current at batch: 125 tensor(5.6592, dtype=torch.float64)\n",
      "7.514441728591919\n",
      "current at batch: 126 tensor(6.0437, dtype=torch.float64)\n",
      "7.682508945465088\n",
      "current at batch: 127 tensor(6.5860, dtype=torch.float64)\n",
      "7.7189061641693115\n",
      "current at batch: 128 tensor(6.3027, dtype=torch.float64)\n",
      "7.54702615737915\n",
      "current at batch: 129 tensor(6.8373, dtype=torch.float64)\n",
      "8.04705810546875\n",
      "current at batch: 130 tensor(6.3182, dtype=torch.float64)\n",
      "7.53037166595459\n",
      "current at batch: 131 tensor(6.0564, dtype=torch.float64)\n",
      "8.132530212402344\n",
      "current at batch: 132 tensor(6.4432, dtype=torch.float64)\n",
      "7.797032594680786\n",
      "current at batch: 133 tensor(6.2641, dtype=torch.float64)\n",
      "7.390776634216309\n",
      "current at batch: 134 tensor(6.3477, dtype=torch.float64)\n",
      "7.906414270401001\n",
      "current at batch: 135 tensor(6.5406, dtype=torch.float64)\n",
      "7.356558799743652\n",
      "current at batch: 136 tensor(6.6777, dtype=torch.float64)\n",
      "8.370478391647339\n",
      "current at batch: 137 tensor(6.4710, dtype=torch.float64)\n",
      "8.015794277191162\n",
      "current at batch: 138 tensor(5.9214, dtype=torch.float64)\n",
      "7.703276634216309\n",
      "current at batch: 139 tensor(6.1258, dtype=torch.float64)\n",
      "7.710377931594849\n",
      "current at batch: 140 tensor(6.4124, dtype=torch.float64)\n",
      "7.313327312469482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 141 tensor(6.9223, dtype=torch.float64)\n",
      "7.6433491706848145\n",
      "current at batch: 142 tensor(6.5438, dtype=torch.float64)\n",
      "7.1563990116119385\n",
      "current at batch: 143 tensor(6.2578, dtype=torch.float64)\n",
      "7.547030210494995\n",
      "current at batch: 144 tensor(6.3249, dtype=torch.float64)\n",
      "7.953295469284058\n",
      "current at batch: 145 tensor(7.0784, dtype=torch.float64)\n",
      "8.156418085098267\n",
      "current at batch: 146 tensor(6.5120, dtype=torch.float64)\n",
      "7.4712207317352295\n",
      "current at batch: 147 tensor(6.2916, dtype=torch.float64)\n",
      "7.416017770767212\n",
      "current at batch: 148 tensor(6.8012, dtype=torch.float64)\n",
      "7.84397029876709\n",
      "current at batch: 149 tensor(6.4819, dtype=torch.float64)\n",
      "7.656453609466553\n",
      "current at batch: 150 tensor(6.2579, dtype=torch.float64)\n",
      "7.765835762023926\n",
      "current at batch: 151 tensor(6.7955, dtype=torch.float64)\n",
      "7.921887636184692\n",
      "current at batch: 152 tensor(5.9530, dtype=torch.float64)\n",
      "7.343945264816284\n",
      "current at batch: 153 tensor(6.2740, dtype=torch.float64)\n",
      "7.437696695327759\n",
      "current at batch: 154 tensor(6.4116, dtype=torch.float64)\n",
      "7.272304534912109\n",
      "current at batch: 155 tensor(6.9886, dtype=torch.float64)\n",
      "8.406477689743042\n",
      "current at batch: 156 tensor(6.0801, dtype=torch.float64)\n",
      "7.851261377334595\n",
      "current at batch: 157 tensor(5.6352, dtype=torch.float64)\n",
      "7.169049263000488\n",
      "current at batch: 158 tensor(6.1267, dtype=torch.float64)\n",
      "7.672090530395508\n",
      "current at batch: 159 tensor(6.0420, dtype=torch.float64)\n",
      "7.692694902420044\n",
      "current at batch: 160 tensor(6.9547, dtype=torch.float64)\n",
      "8.427302122116089\n",
      "current at batch: 161 tensor(6.7812, dtype=torch.float64)\n",
      "8.400300025939941\n",
      "current at batch: 162 tensor(6.5416, dtype=torch.float64)\n",
      "9.256174802780151\n",
      "current at batch: 163 tensor(5.9612, dtype=torch.float64)\n",
      "7.999276161193848\n",
      "current at batch: 164 tensor(5.8833, dtype=torch.float64)\n",
      "7.493712425231934\n",
      "current at batch: 165 tensor(6.7314, dtype=torch.float64)\n",
      "7.748354434967041\n",
      "current at batch: 166 tensor(5.8785, dtype=torch.float64)\n",
      "7.589581727981567\n",
      "current at batch: 167 tensor(6.1470, dtype=torch.float64)\n",
      "7.856865406036377\n",
      "current at batch: 168 tensor(6.6058, dtype=torch.float64)\n",
      "7.8564064502716064\n",
      "current at batch: 169 tensor(6.7276, dtype=torch.float64)\n",
      "7.383530378341675\n",
      "current at batch: 170 tensor(6.1181, dtype=torch.float64)\n",
      "7.399672985076904\n",
      "current at batch: 171 tensor(6.3023, dtype=torch.float64)\n",
      "7.748554468154907\n",
      "current at batch: 172 tensor(6.4948, dtype=torch.float64)\n",
      "8.01621127128601\n",
      "current at batch: 173 tensor(6.1783, dtype=torch.float64)\n",
      "8.1750009059906\n",
      "current at batch: 174 tensor(6.2559, dtype=torch.float64)\n",
      "8.062487602233887\n",
      "current at batch: 175 tensor(5.9910, dtype=torch.float64)\n",
      "7.569690942764282\n",
      "current at batch: 176 tensor(6.4959, dtype=torch.float64)\n",
      "8.113357543945312\n",
      "current at batch: 177 tensor(6.2277, dtype=torch.float64)\n",
      "7.79636549949646\n",
      "current at batch: 178 tensor(5.6656, dtype=torch.float64)\n",
      "7.666945219039917\n",
      "current at batch: 179 tensor(6.6023, dtype=torch.float64)\n",
      "5.64804744720459\n",
      "current at batch: 180 tensor(6.6277, dtype=torch.float64)\n",
      "5.569070816040039\n",
      "current at batch: 181 tensor(6.5241, dtype=torch.float64)\n",
      "5.640885829925537\n",
      "current at batch: 182 tensor(6.0156, dtype=torch.float64)\n",
      "5.359080791473389\n",
      "current at batch: 183 tensor(6.2374, dtype=torch.float64)\n",
      "5.209867238998413\n",
      "current at batch: 184 tensor(6.2521, dtype=torch.float64)\n",
      "6.120893478393555\n",
      "current at batch: 185 tensor(5.9211, dtype=torch.float64)\n",
      "7.587546110153198\n",
      "current at batch: 186 tensor(6.4272, dtype=torch.float64)\n",
      "7.714956998825073\n",
      "current at batch: 187 tensor(5.8517, dtype=torch.float64)\n",
      "7.1501991748809814\n",
      "current at batch: 188 tensor(6.5240, dtype=torch.float64)\n",
      "7.582995891571045\n",
      "current at batch: 189 tensor(6.5008, dtype=torch.float64)\n",
      "7.864226341247559\n",
      "current at batch: 190 tensor(6.6825, dtype=torch.float64)\n",
      "7.547029256820679\n",
      "current at batch: 191 tensor(5.9019, dtype=torch.float64)\n",
      "7.73600172996521\n",
      "current at batch: 192 tensor(6.6161, dtype=torch.float64)\n",
      "7.656416177749634\n",
      "current at batch: 193 tensor(6.5310, dtype=torch.float64)\n",
      "8.040125131607056\n",
      "current at batch: 194 tensor(6.0712, dtype=torch.float64)\n",
      "7.850970983505249\n",
      "current at batch: 195 tensor(6.8553, dtype=torch.float64)\n",
      "7.687654495239258\n",
      "current at batch: 196 tensor(6.3019, dtype=torch.float64)\n",
      "7.8595359325408936\n",
      "current at batch: 197 tensor(6.2103, dtype=torch.float64)\n",
      "7.821302890777588\n",
      "current at batch: 198 tensor(5.7020, dtype=torch.float64)\n",
      "7.3653175830841064\n",
      "current at batch: 199 tensor(6.6766, dtype=torch.float64)\n",
      "7.823774337768555\n",
      "current at batch: 200 tensor(6.9045, dtype=torch.float64)\n",
      "8.00015926361084\n",
      "current at batch: 201 tensor(6.7047, dtype=torch.float64)\n",
      "7.81266975402832\n",
      "current at batch: 202 tensor(6.4862, dtype=torch.float64)\n",
      "8.297047138214111\n",
      "current at batch: 203 tensor(6.1506, dtype=torch.float64)\n",
      "7.314293146133423\n",
      "current at batch: 204 tensor(6.4408, dtype=torch.float64)\n",
      "8.257035493850708\n",
      "current at batch: 205 tensor(5.6798, dtype=torch.float64)\n",
      "7.750161170959473\n",
      "current at batch: 206 tensor(6.2997, dtype=torch.float64)\n",
      "7.4376513957977295\n",
      "current at batch: 207 tensor(6.0129, dtype=torch.float64)\n",
      "7.703280210494995\n",
      "current at batch: 208 tensor(6.7286, dtype=torch.float64)\n",
      "7.88962721824646\n",
      "current at batch: 209 tensor(6.3058, dtype=torch.float64)\n",
      "7.591970205307007\n",
      "current at batch: 210 tensor(6.4257, dtype=torch.float64)\n",
      "8.265790462493896\n",
      "current at batch: 211 tensor(6.4406, dtype=torch.float64)\n",
      "8.453296661376953\n",
      "current at batch: 212 tensor(6.5077, dtype=torch.float64)\n",
      "7.984546899795532\n",
      "current at batch: 213 tensor(6.5173, dtype=torch.float64)\n",
      "8.013611555099487\n",
      "current at batch: 214 tensor(6.4014, dtype=torch.float64)\n",
      "7.820475816726685\n",
      "current at batch: 215 tensor(6.0728, dtype=torch.float64)\n",
      "7.093897104263306\n",
      "current at batch: 216 tensor(6.1908, dtype=torch.float64)\n",
      "7.145207166671753\n",
      "current at batch: 217 tensor(6.4385, dtype=torch.float64)\n",
      "8.203291416168213\n",
      "current at batch: 218 tensor(6.6794, dtype=torch.float64)\n",
      "8.211168050765991\n",
      "current at batch: 219 tensor(6.2294, dtype=torch.float64)\n",
      "7.390681982040405\n",
      "current at batch: 220 tensor(6.2301, dtype=torch.float64)\n",
      "8.187685012817383\n",
      "current at batch: 221 tensor(6.3812, dtype=torch.float64)\n",
      "7.7389984130859375\n",
      "current at batch: 222 tensor(6.4414, dtype=torch.float64)\n",
      "7.562656879425049\n",
      "current at batch: 223 tensor(5.3998, dtype=torch.float64)\n",
      "7.288331031799316\n",
      "current at batch: 224 tensor(6.2036, dtype=torch.float64)\n",
      "7.836193799972534\n",
      "current at batch: 225 tensor(6.6739, dtype=torch.float64)\n",
      "8.109538555145264\n",
      "current at batch: 226 tensor(6.4328, dtype=torch.float64)\n",
      "8.03141975402832\n",
      "current at batch: 227 tensor(5.8589, dtype=torch.float64)\n",
      "7.6514317989349365\n",
      "current at batch: 228 tensor(6.2414, dtype=torch.float64)\n",
      "8.149359464645386\n",
      "current at batch: 229 tensor(6.3544, dtype=torch.float64)\n",
      "7.994898080825806\n",
      "current at batch: 230 tensor(6.5415, dtype=torch.float64)\n",
      "7.547028064727783\n",
      "current at batch: 231 tensor(6.0042, dtype=torch.float64)\n",
      "7.4220428466796875\n",
      "current at batch: 232 tensor(6.2202, dtype=torch.float64)\n",
      "7.489521026611328\n",
      "current at batch: 233 tensor(6.0683, dtype=torch.float64)\n",
      "7.7657811641693115\n",
      "current at batch: 234 tensor(6.4100, dtype=torch.float64)\n",
      "7.546554327011108\n",
      "current at batch: 235 tensor(6.3315, dtype=torch.float64)\n",
      "7.859533071517944\n",
      "current at batch: 236 tensor(6.5879, dtype=torch.float64)\n",
      "7.875168323516846\n",
      "current at batch: 237 tensor(6.1861, dtype=torch.float64)\n",
      "7.566135883331299\n",
      "current at batch: 238 tensor(6.5339, dtype=torch.float64)\n",
      "7.484527587890625\n",
      "current at batch: 239 tensor(6.6208, dtype=torch.float64)\n",
      "9.163012981414795\n",
      "current at batch: 240 tensor(6.6459, dtype=torch.float64)\n",
      "8.889516830444336\n",
      "current at batch: 241 tensor(6.1423, dtype=torch.float64)\n",
      "8.238149166107178\n",
      "current at batch: 242 tensor(6.1972, dtype=torch.float64)\n",
      "8.809510469436646\n",
      "current at batch: 243 tensor(6.5123, dtype=torch.float64)\n",
      "8.632091760635376\n",
      "current at batch: 244 tensor(6.3665, dtype=torch.float64)\n",
      "8.431183815002441\n",
      "current at batch: 245 tensor(6.4167, dtype=torch.float64)\n",
      "10.1555757522583\n",
      "current at batch: 246 tensor(6.2733, dtype=torch.float64)\n",
      "8.803188562393188\n",
      "current at batch: 247 tensor(5.9969, dtype=torch.float64)\n",
      "7.954458951950073\n",
      "current at batch: 248 tensor(5.6555, dtype=torch.float64)\n",
      "8.029879808425903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 249 tensor(6.1804, dtype=torch.float64)\n",
      "7.584090232849121\n",
      "current at batch: 250 tensor(6.4592, dtype=torch.float64)\n",
      "9.144497632980347\n",
      "current at batch: 251 tensor(6.2435, dtype=torch.float64)\n",
      "8.43339729309082\n",
      "current at batch: 252 tensor(6.6691, dtype=torch.float64)\n",
      "7.840100288391113\n",
      "current at batch: 253 tensor(6.7742, dtype=torch.float64)\n",
      "8.38043212890625\n",
      "current at batch: 254 tensor(6.5617, dtype=torch.float64)\n",
      "7.7814037799835205\n",
      "current at batch: 255 tensor(5.9455, dtype=torch.float64)\n",
      "7.984541177749634\n",
      "current at batch: 256 tensor(6.2320, dtype=torch.float64)\n",
      "8.070345163345337\n",
      "current at batch: 257 tensor(5.9753, dtype=torch.float64)\n",
      "7.828283786773682\n",
      "current at batch: 258 tensor(5.9706, dtype=torch.float64)\n",
      "8.189793109893799\n",
      "current at batch: 259 tensor(6.0581, dtype=torch.float64)\n",
      "7.672037839889526\n",
      "current at batch: 260 tensor(5.9532, dtype=torch.float64)\n",
      "8.225680112838745\n",
      "current at batch: 261 tensor(6.6988, dtype=torch.float64)\n",
      "8.093984603881836\n",
      "current at batch: 262 tensor(5.5694, dtype=torch.float64)\n",
      "7.4830543994903564\n",
      "current at batch: 263 tensor(6.2235, dtype=torch.float64)\n",
      "8.073047399520874\n",
      "current at batch: 264 tensor(6.0361, dtype=torch.float64)\n",
      "8.573560953140259\n",
      "current at batch: 265 tensor(6.5899, dtype=torch.float64)\n",
      "8.639248609542847\n",
      "current at batch: 266 tensor(5.9776, dtype=torch.float64)\n",
      "8.00341510772705\n",
      "current at batch: 267 tensor(6.1878, dtype=torch.float64)\n",
      "8.19669771194458\n",
      "current at batch: 268 tensor(6.7954, dtype=torch.float64)\n",
      "8.302913904190063\n",
      "current at batch: 269 tensor(5.6995, dtype=torch.float64)\n",
      "8.375225305557251\n",
      "current at batch: 270 tensor(6.4197, dtype=torch.float64)\n",
      "8.044788360595703\n",
      "current at batch: 271 tensor(5.9068, dtype=torch.float64)\n",
      "8.015838623046875\n",
      "current at batch: 272 tensor(5.6742, dtype=torch.float64)\n",
      "7.488118886947632\n",
      "current at batch: 273 tensor(6.7140, dtype=torch.float64)\n",
      "7.994147539138794\n",
      "current at batch: 274 tensor(6.0428, dtype=torch.float64)\n",
      "8.000213623046875\n",
      "current at batch: 275 tensor(6.2967, dtype=torch.float64)\n",
      "8.072278022766113\n",
      "current at batch: 276 tensor(6.3213, dtype=torch.float64)\n",
      "8.187718868255615\n",
      "current at batch: 277 tensor(6.5544, dtype=torch.float64)\n",
      "7.776174068450928\n",
      "current at batch: 278 tensor(6.5662, dtype=torch.float64)\n",
      "8.143743753433228\n",
      "current at batch: 279 tensor(6.6240, dtype=torch.float64)\n",
      "7.913254976272583\n",
      "current at batch: 280 tensor(6.2795, dtype=torch.float64)\n",
      "7.588303327560425\n",
      "current at batch: 281 tensor(6.2139, dtype=torch.float64)\n",
      "7.843961238861084\n",
      "current at batch: 282 tensor(6.3004, dtype=torch.float64)\n",
      "8.11258316040039\n",
      "current at batch: 283 tensor(6.1758, dtype=torch.float64)\n",
      "8.174082279205322\n",
      "current at batch: 284 tensor(6.6803, dtype=torch.float64)\n",
      "7.531450033187866\n",
      "current at batch: 285 tensor(6.4611, dtype=torch.float64)\n",
      "7.562700510025024\n",
      "current at batch: 286 tensor(6.2654, dtype=torch.float64)\n",
      "7.406454086303711\n",
      "current at batch: 287 tensor(6.4611, dtype=torch.float64)\n",
      "7.625213861465454\n",
      "current at batch: 288 tensor(6.3231, dtype=torch.float64)\n",
      "8.34862732887268\n",
      "current at batch: 289 tensor(6.2989, dtype=torch.float64)\n",
      "7.779139757156372\n",
      "current at batch: 290 tensor(6.2871, dtype=torch.float64)\n",
      "8.47512674331665\n",
      "current at batch: 291 tensor(5.7426, dtype=torch.float64)\n",
      "7.869857549667358\n",
      "current at batch: 292 tensor(6.1901, dtype=torch.float64)\n",
      "8.15646743774414\n",
      "current at batch: 293 tensor(6.0620, dtype=torch.float64)\n",
      "8.140355825424194\n",
      "current at batch: 294 tensor(6.5054, dtype=torch.float64)\n",
      "8.73192572593689\n",
      "current at batch: 295 tensor(6.3798, dtype=torch.float64)\n",
      "7.828333854675293\n",
      "current at batch: 296 tensor(6.4723, dtype=torch.float64)\n",
      "7.875185966491699\n",
      "current at batch: 297 tensor(6.3069, dtype=torch.float64)\n",
      "7.659765720367432\n",
      "current at batch: 298 tensor(6.5227, dtype=torch.float64)\n",
      "8.123762130737305\n",
      "current at batch: 299 tensor(6.3057, dtype=torch.float64)\n",
      "7.529321193695068\n",
      "current at batch: 300 tensor(6.7142, dtype=torch.float64)\n",
      "7.838212251663208\n",
      "current at batch: 301 tensor(5.8384, dtype=torch.float64)\n",
      "7.7814106941223145\n",
      "current at batch: 302 tensor(6.5714, dtype=torch.float64)\n",
      "7.797032833099365\n",
      "current at batch: 303 tensor(6.3113, dtype=torch.float64)\n",
      "8.490118980407715\n",
      "current at batch: 304 tensor(6.0731, dtype=torch.float64)\n",
      "8.000173568725586\n",
      "current at batch: 305 tensor(6.5302, dtype=torch.float64)\n",
      "8.539706945419312\n",
      "current at batch: 306 tensor(6.1934, dtype=torch.float64)\n",
      "8.578298091888428\n",
      "current at batch: 307 tensor(6.4495, dtype=torch.float64)\n",
      "8.437436819076538\n",
      "current at batch: 308 tensor(6.3596, dtype=torch.float64)\n",
      "9.044169902801514\n",
      "current at batch: 309 tensor(6.4570, dtype=torch.float64)\n",
      "8.904796838760376\n",
      "current at batch: 310 tensor(6.6925, dtype=torch.float64)\n",
      "9.00238299369812\n",
      "current at batch: 311 tensor(6.7123, dtype=torch.float64)\n",
      "8.50017261505127\n",
      "current at batch: 312 tensor(6.6741, dtype=torch.float64)\n",
      "8.927095890045166\n",
      "current at batch: 313 tensor(6.5877, dtype=torch.float64)\n",
      "9.148995637893677\n",
      "current at batch: 314 tensor(6.8505, dtype=torch.float64)\n",
      "8.861024379730225\n",
      "current at batch: 315 tensor(6.3652, dtype=torch.float64)\n",
      "7.3907976150512695\n",
      "current at batch: 316 tensor(5.9206, dtype=torch.float64)\n",
      "7.812669992446899\n",
      "current at batch: 317 tensor(6.3177, dtype=torch.float64)\n",
      "7.71969747543335\n",
      "current at batch: 318 tensor(6.1620, dtype=torch.float64)\n",
      "7.451765060424805\n",
      "current at batch: 319 tensor(6.3370, dtype=torch.float64)\n",
      "8.203289031982422\n",
      "current at batch: 320 tensor(6.5142, dtype=torch.float64)\n",
      "8.773876667022705\n",
      "current at batch: 321 tensor(6.1837, dtype=torch.float64)\n",
      "7.640779733657837\n",
      "current at batch: 322 tensor(5.8336, dtype=torch.float64)\n",
      "7.896568059921265\n",
      "current at batch: 323 tensor(6.4796, dtype=torch.float64)\n",
      "8.070229530334473\n",
      "current at batch: 324 tensor(5.8458, dtype=torch.float64)\n",
      "8.312678575515747\n",
      "current at batch: 325 tensor(6.7440, dtype=torch.float64)\n",
      "8.500173091888428\n",
      "current at batch: 326 tensor(6.1066, dtype=torch.float64)\n",
      "7.906405687332153\n",
      "current at batch: 327 tensor(6.7043, dtype=torch.float64)\n",
      "8.894933700561523\n",
      "current at batch: 328 tensor(6.4226, dtype=torch.float64)\n",
      "8.777761697769165\n",
      "current at batch: 329 tensor(6.1394, dtype=torch.float64)\n",
      "7.823848485946655\n",
      "current at batch: 330 tensor(6.5034, dtype=torch.float64)\n",
      "7.953285217285156\n",
      "current at batch: 331 tensor(5.4633, dtype=torch.float64)\n",
      "8.14078974723816\n",
      "current at batch: 332 tensor(6.4196, dtype=torch.float64)\n",
      "8.020269632339478\n",
      "current at batch: 333 tensor(6.0747, dtype=torch.float64)\n",
      "8.328293085098267\n",
      "current at batch: 334 tensor(6.7871, dtype=torch.float64)\n",
      "8.109545230865479\n",
      "current at batch: 335 tensor(6.0057, dtype=torch.float64)\n",
      "7.828285455703735\n",
      "current at batch: 336 tensor(6.0895, dtype=torch.float64)\n",
      "8.12517261505127\n",
      "current at batch: 337 tensor(6.4282, dtype=torch.float64)\n",
      "8.53756856918335\n",
      "current at batch: 338 tensor(6.4683, dtype=torch.float64)\n",
      "7.814593076705933\n",
      "current at batch: 339 tensor(5.8689, dtype=torch.float64)\n",
      "7.875169038772583\n",
      "current at batch: 340 tensor(6.2932, dtype=torch.float64)\n",
      "8.130339622497559\n",
      "current at batch: 341 tensor(6.2593, dtype=torch.float64)\n",
      "8.14078950881958\n",
      "current at batch: 342 tensor(6.0270, dtype=torch.float64)\n",
      "7.889172315597534\n",
      "current at batch: 343 tensor(6.4592, dtype=torch.float64)\n",
      "8.07829475402832\n",
      "current at batch: 344 tensor(6.3640, dtype=torch.float64)\n",
      "8.103312730789185\n",
      "current at batch: 345 tensor(6.1989, dtype=torch.float64)\n",
      "8.13916826248169\n",
      "current at batch: 346 tensor(6.6532, dtype=torch.float64)\n",
      "7.593900442123413\n",
      "current at batch: 347 tensor(5.9514, dtype=torch.float64)\n",
      "7.578893661499023\n",
      "current at batch: 348 tensor(5.9444, dtype=torch.float64)\n",
      "7.656404733657837\n",
      "current at batch: 349 tensor(6.1936, dtype=torch.float64)\n",
      "8.547043800354004\n",
      "current at batch: 350 tensor(5.6658, dtype=torch.float64)\n",
      "7.656405687332153\n",
      "current at batch: 351 tensor(5.8094, dtype=torch.float64)\n",
      "8.17203950881958\n",
      "current at batch: 352 tensor(6.0658, dtype=torch.float64)\n",
      "8.044550895690918\n",
      "current at batch: 353 tensor(6.4410, dtype=torch.float64)\n",
      "7.766261577606201\n",
      "current at batch: 354 tensor(6.0851, dtype=torch.float64)\n",
      "7.906410455703735\n",
      "current at batch: 355 tensor(6.1877, dtype=torch.float64)\n",
      "8.14078950881958\n",
      "current at batch: 356 tensor(6.1989, dtype=torch.float64)\n",
      "7.781408786773682\n",
      "current at batch: 357 tensor(6.4634, dtype=torch.float64)\n",
      "8.135334730148315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 358 tensor(6.4913, dtype=torch.float64)\n",
      "8.015786170959473\n",
      "current at batch: 359 tensor(6.3530, dtype=torch.float64)\n",
      "7.640779495239258\n",
      "current at batch: 360 tensor(6.6187, dtype=torch.float64)\n",
      "8.03141474723816\n",
      "current at batch: 361 tensor(6.2319, dtype=torch.float64)\n",
      "8.139447689056396\n",
      "current at batch: 362 tensor(6.0937, dtype=torch.float64)\n",
      "7.8745152950286865\n",
      "current at batch: 363 tensor(6.4328, dtype=torch.float64)\n",
      "7.587134122848511\n",
      "current at batch: 364 tensor(6.5545, dtype=torch.float64)\n",
      "8.204322576522827\n",
      "current at batch: 365 tensor(6.5045, dtype=torch.float64)\n",
      "7.9948859214782715\n",
      "current at batch: 366 tensor(6.0991, dtype=torch.float64)\n",
      "7.95329475402832\n",
      "current at batch: 367 tensor(5.8994, dtype=torch.float64)\n",
      "7.857948541641235\n",
      "current at batch: 368 tensor(6.3275, dtype=torch.float64)\n",
      "7.906355619430542\n",
      "current at batch: 369 tensor(5.9486, dtype=torch.float64)\n",
      "8.127097606658936\n",
      "current at batch: 370 tensor(5.7934, dtype=torch.float64)\n",
      "8.280229091644287\n",
      "current at batch: 371 tensor(5.9317, dtype=torch.float64)\n",
      "8.625176191329956\n",
      "current at batch: 372 tensor(6.2074, dtype=torch.float64)\n",
      "8.821772336959839\n",
      "current at batch: 373 tensor(6.2413, dtype=torch.float64)\n",
      "7.968878269195557\n",
      "current at batch: 374 tensor(5.7444, dtype=torch.float64)\n",
      "7.692315340042114\n",
      "current at batch: 375 tensor(5.9798, dtype=torch.float64)\n",
      "9.406440734863281\n",
      "current at batch: 376 tensor(5.7151, dtype=torch.float64)\n",
      "11.017592668533325\n",
      "current at batch: 377 tensor(6.0660, dtype=torch.float64)\n",
      "7.940238952636719\n",
      "current at batch: 378 tensor(6.2839, dtype=torch.float64)\n",
      "7.734544515609741\n",
      "current at batch: 379 tensor(6.5590, dtype=torch.float64)\n",
      "8.328292846679688\n",
      "current at batch: 380 tensor(5.8855, dtype=torch.float64)\n",
      "7.687659502029419\n",
      "current at batch: 381 tensor(6.1388, dtype=torch.float64)\n",
      "7.728790044784546\n",
      "current at batch: 382 tensor(6.0247, dtype=torch.float64)\n",
      "8.06336236000061\n",
      "current at batch: 383 tensor(6.5623, dtype=torch.float64)\n",
      "8.265792846679688\n",
      "current at batch: 384 tensor(5.3900, dtype=torch.float64)\n",
      "7.70671820640564\n",
      "current at batch: 385 tensor(6.0085, dtype=torch.float64)\n",
      "7.832819700241089\n",
      "current at batch: 386 tensor(6.3607, dtype=torch.float64)\n",
      "8.031419515609741\n",
      "current at batch: 387 tensor(6.2406, dtype=torch.float64)\n",
      "8.22383713722229\n",
      "current at batch: 388 tensor(5.8966, dtype=torch.float64)\n",
      "8.703304052352905\n",
      "current at batch: 389 tensor(5.8024, dtype=torch.float64)\n",
      "9.672071695327759\n",
      "current at batch: 390 tensor(5.8843, dtype=torch.float64)\n",
      "10.465153455734253\n",
      "current at batch: 391 tensor(6.0198, dtype=torch.float64)\n",
      "7.89607310295105\n",
      "current at batch: 392 tensor(6.5158, dtype=torch.float64)\n",
      "9.48226022720337\n",
      "current at batch: 393 tensor(6.2019, dtype=torch.float64)\n",
      "11.95664381980896\n",
      "current at batch: 394 tensor(6.5925, dtype=torch.float64)\n",
      "11.645954132080078\n",
      "current at batch: 395 tensor(6.0382, dtype=torch.float64)\n",
      "10.604028224945068\n",
      "current at batch: 396 tensor(5.6700, dtype=torch.float64)\n",
      "12.171602249145508\n",
      "current at batch: 397 tensor(6.5161, dtype=torch.float64)\n",
      "8.7447030544281\n",
      "current at batch: 398 tensor(6.0481, dtype=torch.float64)\n",
      "8.661886215209961\n",
      "current at batch: 399 tensor(6.1292, dtype=torch.float64)\n",
      "8.041173696517944\n",
      "current at batch: 400 tensor(6.3408, dtype=torch.float64)\n",
      "8.152037858963013\n",
      "current at batch: 401 tensor(5.7517, dtype=torch.float64)\n",
      "9.06269121170044\n",
      "current at batch: 402 tensor(6.7544, dtype=torch.float64)\n",
      "11.98703384399414\n",
      "current at batch: 403 tensor(6.1312, dtype=torch.float64)\n",
      "10.32547116279602\n",
      "current at batch: 404 tensor(6.5769, dtype=torch.float64)\n",
      "11.3715660572052\n",
      "current at batch: 405 tensor(6.2491, dtype=torch.float64)\n",
      "10.106699466705322\n",
      "current at batch: 406 tensor(6.2423, dtype=torch.float64)\n",
      "10.56116008758545\n",
      "current at batch: 407 tensor(6.3035, dtype=torch.float64)\n",
      "10.510386943817139\n",
      "current at batch: 408 tensor(6.8106, dtype=torch.float64)\n",
      "11.226921319961548\n",
      "current at batch: 409 tensor(5.8310, dtype=torch.float64)\n",
      "10.845424890518188\n",
      "current at batch: 410 tensor(6.5443, dtype=torch.float64)\n",
      "11.078601121902466\n",
      "current at batch: 411 tensor(5.9261, dtype=torch.float64)\n",
      "10.207547903060913\n",
      "current at batch: 412 tensor(6.3125, dtype=torch.float64)\n",
      "10.709890127182007\n",
      "current at batch: 413 tensor(6.4547, dtype=torch.float64)\n",
      "11.127882480621338\n",
      "current at batch: 414 tensor(6.0351, dtype=torch.float64)\n",
      "10.418037414550781\n",
      "current at batch: 415 tensor(6.2002, dtype=torch.float64)\n",
      "10.099591732025146\n",
      "current at batch: 416 tensor(6.3703, dtype=torch.float64)\n",
      "9.357434272766113\n",
      "current at batch: 417 tensor(6.0253, dtype=torch.float64)\n",
      "10.380279064178467\n",
      "current at batch: 418 tensor(6.2506, dtype=torch.float64)\n",
      "10.026395559310913\n",
      "current at batch: 419 tensor(5.9332, dtype=torch.float64)\n",
      "9.715566396713257\n",
      "current at batch: 420 tensor(6.4701, dtype=torch.float64)\n",
      "8.17646837234497\n",
      "current at batch: 421 tensor(5.6284, dtype=torch.float64)\n",
      "10.86521863937378\n",
      "current at batch: 422 tensor(6.3576, dtype=torch.float64)\n",
      "10.271460771560669\n",
      "current at batch: 423 tensor(6.1321, dtype=torch.float64)\n",
      "9.965807914733887\n",
      "current at batch: 424 tensor(5.9422, dtype=torch.float64)\n",
      "10.012605905532837\n",
      "current at batch: 425 tensor(6.0544, dtype=torch.float64)\n",
      "11.135330438613892\n",
      "current at batch: 426 tensor(6.3645, dtype=torch.float64)\n",
      "10.529748678207397\n",
      "current at batch: 427 tensor(6.4808, dtype=torch.float64)\n",
      "9.705767393112183\n",
      "current at batch: 428 tensor(6.6518, dtype=torch.float64)\n",
      "11.135194063186646\n",
      "current at batch: 429 tensor(6.1095, dtype=torch.float64)\n",
      "10.798409461975098\n",
      "current at batch: 430 tensor(6.2172, dtype=torch.float64)\n",
      "10.659476280212402\n",
      "current at batch: 431 tensor(6.2386, dtype=torch.float64)\n",
      "11.035003900527954\n",
      "current at batch: 432 tensor(6.3200, dtype=torch.float64)\n",
      "10.038703680038452\n",
      "current at batch: 433 tensor(6.7043, dtype=torch.float64)\n",
      "10.968663215637207\n",
      "current at batch: 434 tensor(6.2380, dtype=torch.float64)\n",
      "11.364323139190674\n",
      "current at batch: 435 tensor(6.2146, dtype=torch.float64)\n",
      "11.15979552268982\n",
      "current at batch: 436 tensor(6.4389, dtype=torch.float64)\n",
      "10.312393426895142\n",
      "current at batch: 437 tensor(6.3133, dtype=torch.float64)\n",
      "11.365528345108032\n",
      "current at batch: 438 tensor(5.8970, dtype=torch.float64)\n",
      "10.610424995422363\n",
      "current at batch: 439 tensor(6.0089, dtype=torch.float64)\n",
      "8.406327962875366\n",
      "current at batch: 440 tensor(6.0137, dtype=torch.float64)\n",
      "10.510663747787476\n",
      "current at batch: 441 tensor(6.3493, dtype=torch.float64)\n",
      "10.476719617843628\n",
      "current at batch: 442 tensor(5.8576, dtype=torch.float64)\n",
      "10.137278079986572\n",
      "current at batch: 443 tensor(6.4239, dtype=torch.float64)\n",
      "10.702411413192749\n",
      "current at batch: 444 tensor(6.1706, dtype=torch.float64)\n",
      "10.218956232070923\n",
      "current at batch: 445 tensor(6.2405, dtype=torch.float64)\n",
      "10.418679237365723\n",
      "current at batch: 446 tensor(5.8590, dtype=torch.float64)\n",
      "10.370561599731445\n",
      "current at batch: 447 tensor(6.1459, dtype=torch.float64)\n",
      "9.961555004119873\n",
      "current at batch: 448 tensor(5.7972, dtype=torch.float64)\n",
      "10.328334093093872\n",
      "current at batch: 449 tensor(5.8421, dtype=torch.float64)\n",
      "10.256105899810791\n",
      "current at batch: 450 tensor(7.0433, dtype=torch.float64)\n",
      "10.80634617805481\n",
      "current at batch: 451 tensor(6.6151, dtype=torch.float64)\n",
      "10.413047313690186\n",
      "current at batch: 452 tensor(6.4630, dtype=torch.float64)\n",
      "11.023321866989136\n",
      "current at batch: 453 tensor(6.3532, dtype=torch.float64)\n",
      "9.59884786605835\n",
      "current at batch: 454 tensor(6.3236, dtype=torch.float64)\n",
      "9.2186918258667\n",
      "current at batch: 455 tensor(6.1443, dtype=torch.float64)\n",
      "8.717532396316528\n",
      "current at batch: 456 tensor(6.2198, dtype=torch.float64)\n",
      "8.478425979614258\n",
      "current at batch: 457 tensor(5.9632, dtype=torch.float64)\n",
      "8.039937257766724\n",
      "current at batch: 458 tensor(6.3521, dtype=torch.float64)\n",
      "8.167648553848267\n",
      "current at batch: 459 tensor(6.7607, dtype=torch.float64)\n",
      "8.048289775848389\n",
      "current at batch: 460 tensor(6.2449, dtype=torch.float64)\n",
      "8.063674449920654\n",
      "current at batch: 461 tensor(6.2773, dtype=torch.float64)\n",
      "8.421782970428467\n",
      "current at batch: 462 tensor(6.0480, dtype=torch.float64)\n",
      "8.425875663757324\n",
      "current at batch: 463 tensor(6.1829, dtype=torch.float64)\n",
      "8.644395351409912\n",
      "current at batch: 464 tensor(5.7686, dtype=torch.float64)\n",
      "7.783328056335449\n",
      "current at batch: 465 tensor(6.6276, dtype=torch.float64)\n",
      "8.371368646621704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 466 tensor(6.2043, dtype=torch.float64)\n",
      "8.471266746520996\n",
      "current at batch: 467 tensor(5.4008, dtype=torch.float64)\n",
      "9.964880228042603\n",
      "current at batch: 468 tensor(6.4595, dtype=torch.float64)\n",
      "12.515844106674194\n",
      "current at batch: 469 tensor(6.1042, dtype=torch.float64)\n",
      "11.019016981124878\n",
      "current at batch: 470 tensor(5.7977, dtype=torch.float64)\n",
      "10.858993530273438\n",
      "current at batch: 471 tensor(5.9395, dtype=torch.float64)\n",
      "10.831700563430786\n",
      "current at batch: 472 tensor(4.5400, dtype=torch.float64)\n",
      "1.4531543254852295\n",
      "epoch =  2 \n",
      " tensor(2967.9790, dtype=torch.float64)\n",
      "current at batch: 1 tensor(6.1798, dtype=torch.float64)\n",
      "10.39538025856018\n",
      "current at batch: 2 tensor(5.4640, dtype=torch.float64)\n",
      "9.531263589859009\n",
      "current at batch: 3 tensor(6.0657, dtype=torch.float64)\n",
      "10.434920072555542\n",
      "current at batch: 4 tensor(5.5381, dtype=torch.float64)\n",
      "10.49474048614502\n",
      "current at batch: 5 tensor(6.0117, dtype=torch.float64)\n",
      "10.063828229904175\n",
      "current at batch: 6 tensor(6.4568, dtype=torch.float64)\n",
      "10.413555383682251\n",
      "current at batch: 7 tensor(5.7501, dtype=torch.float64)\n",
      "9.593825578689575\n",
      "current at batch: 8 tensor(6.2723, dtype=torch.float64)\n",
      "10.083323955535889\n",
      "current at batch: 9 tensor(6.2297, dtype=torch.float64)\n",
      "10.411349773406982\n",
      "current at batch: 10 tensor(5.6540, dtype=torch.float64)\n",
      "9.722211599349976\n",
      "current at batch: 11 tensor(6.3188, dtype=torch.float64)\n",
      "11.060740232467651\n",
      "current at batch: 12 tensor(6.4305, dtype=torch.float64)\n",
      "10.406166076660156\n",
      "current at batch: 13 tensor(5.4803, dtype=torch.float64)\n",
      "10.492451429367065\n",
      "current at batch: 14 tensor(6.0536, dtype=torch.float64)\n",
      "9.80631709098816\n",
      "current at batch: 15 tensor(6.1975, dtype=torch.float64)\n",
      "10.424482822418213\n",
      "current at batch: 16 tensor(5.9659, dtype=torch.float64)\n",
      "10.114741563796997\n",
      "current at batch: 17 tensor(6.3580, dtype=torch.float64)\n",
      "11.079447269439697\n",
      "current at batch: 18 tensor(6.5044, dtype=torch.float64)\n",
      "9.309844970703125\n",
      "current at batch: 19 tensor(5.9979, dtype=torch.float64)\n",
      "9.738349437713623\n",
      "current at batch: 20 tensor(6.1442, dtype=torch.float64)\n",
      "10.157348394393921\n",
      "current at batch: 21 tensor(6.3006, dtype=torch.float64)\n",
      "11.0826096534729\n",
      "current at batch: 22 tensor(6.3879, dtype=torch.float64)\n",
      "11.54371428489685\n",
      "current at batch: 23 tensor(6.3301, dtype=torch.float64)\n",
      "11.225440263748169\n",
      "current at batch: 24 tensor(5.7885, dtype=torch.float64)\n",
      "11.01943302154541\n",
      "current at batch: 25 tensor(6.3167, dtype=torch.float64)\n",
      "10.928479194641113\n",
      "current at batch: 26 tensor(6.0865, dtype=torch.float64)\n",
      "10.280357122421265\n",
      "current at batch: 27 tensor(6.0088, dtype=torch.float64)\n",
      "10.162074327468872\n",
      "current at batch: 28 tensor(6.3243, dtype=torch.float64)\n",
      "11.015730381011963\n",
      "current at batch: 29 tensor(5.8304, dtype=torch.float64)\n",
      "11.12389063835144\n",
      "current at batch: 30 tensor(6.2797, dtype=torch.float64)\n",
      "11.604955911636353\n",
      "current at batch: 31 tensor(6.2941, dtype=torch.float64)\n",
      "10.433375835418701\n",
      "current at batch: 32 tensor(6.7214, dtype=torch.float64)\n",
      "11.05131721496582\n",
      "current at batch: 33 tensor(5.7198, dtype=torch.float64)\n",
      "10.10958218574524\n",
      "current at batch: 34 tensor(6.1935, dtype=torch.float64)\n",
      "10.944051027297974\n",
      "current at batch: 35 tensor(5.6527, dtype=torch.float64)\n",
      "11.203421831130981\n",
      "current at batch: 36 tensor(6.0704, dtype=torch.float64)\n",
      "11.343847751617432\n",
      "current at batch: 37 tensor(6.5180, dtype=torch.float64)\n",
      "11.325409650802612\n",
      "current at batch: 38 tensor(6.1253, dtype=torch.float64)\n",
      "11.343978881835938\n",
      "current at batch: 39 tensor(6.4290, dtype=torch.float64)\n",
      "10.650178670883179\n",
      "current at batch: 40 tensor(6.5136, dtype=torch.float64)\n",
      "10.731829643249512\n",
      "current at batch: 41 tensor(6.2944, dtype=torch.float64)\n",
      "10.768653392791748\n",
      "current at batch: 42 tensor(6.1050, dtype=torch.float64)\n",
      "10.853922843933105\n",
      "current at batch: 43 tensor(6.2837, dtype=torch.float64)\n",
      "11.092280149459839\n",
      "current at batch: 44 tensor(6.5071, dtype=torch.float64)\n",
      "11.287771224975586\n",
      "current at batch: 45 tensor(5.7980, dtype=torch.float64)\n",
      "10.339020490646362\n",
      "current at batch: 46 tensor(6.2163, dtype=torch.float64)\n",
      "11.036238193511963\n",
      "current at batch: 47 tensor(6.6475, dtype=torch.float64)\n",
      "11.581571340560913\n",
      "current at batch: 48 tensor(6.3661, dtype=torch.float64)\n",
      "11.994845390319824\n",
      "current at batch: 49 tensor(6.2032, dtype=torch.float64)\n",
      "11.81960940361023\n",
      "current at batch: 50 tensor(6.2204, dtype=torch.float64)\n",
      "11.540007829666138\n",
      "current at batch: 51 tensor(6.1988, dtype=torch.float64)\n",
      "11.157968759536743\n",
      "current at batch: 52 tensor(6.2235, dtype=torch.float64)\n",
      "11.395323991775513\n",
      "current at batch: 53 tensor(6.4776, dtype=torch.float64)\n",
      "11.564269781112671\n",
      "current at batch: 54 tensor(6.0746, dtype=torch.float64)\n",
      "11.447159051895142\n",
      "current at batch: 55 tensor(6.8763, dtype=torch.float64)\n",
      "8.318095684051514\n",
      "current at batch: 56 tensor(6.3598, dtype=torch.float64)\n",
      "7.765799283981323\n",
      "current at batch: 57 tensor(6.0744, dtype=torch.float64)\n",
      "7.358916759490967\n",
      "current at batch: 58 tensor(5.9054, dtype=torch.float64)\n",
      "8.186148166656494\n",
      "current at batch: 59 tensor(6.3603, dtype=torch.float64)\n",
      "7.9229044914245605\n",
      "current at batch: 60 tensor(6.0590, dtype=torch.float64)\n",
      "7.435390949249268\n",
      "current at batch: 61 tensor(6.7833, dtype=torch.float64)\n",
      "8.282087802886963\n",
      "current at batch: 62 tensor(6.1733, dtype=torch.float64)\n",
      "7.755687475204468\n",
      "current at batch: 63 tensor(5.9575, dtype=torch.float64)\n",
      "7.650870323181152\n",
      "current at batch: 64 tensor(6.1900, dtype=torch.float64)\n",
      "7.829135894775391\n",
      "current at batch: 65 tensor(6.5491, dtype=torch.float64)\n",
      "7.985360145568848\n",
      "current at batch: 66 tensor(5.9067, dtype=torch.float64)\n",
      "7.800933122634888\n",
      "current at batch: 67 tensor(5.8689, dtype=torch.float64)\n",
      "7.157186985015869\n",
      "current at batch: 68 tensor(5.9157, dtype=torch.float64)\n",
      "8.875888347625732\n",
      "current at batch: 69 tensor(6.1444, dtype=torch.float64)\n",
      "9.095325946807861\n",
      "current at batch: 70 tensor(6.1462, dtype=torch.float64)\n",
      "11.281925201416016\n",
      "current at batch: 71 tensor(6.1214, dtype=torch.float64)\n",
      "10.063807725906372\n",
      "current at batch: 72 tensor(6.5893, dtype=torch.float64)\n",
      "10.289866924285889\n",
      "current at batch: 73 tensor(6.1084, dtype=torch.float64)\n",
      "10.576990127563477\n",
      "current at batch: 74 tensor(5.7960, dtype=torch.float64)\n",
      "9.93471074104309\n",
      "current at batch: 75 tensor(6.4117, dtype=torch.float64)\n",
      "10.557438850402832\n",
      "current at batch: 76 tensor(6.0869, dtype=torch.float64)\n",
      "8.282325029373169\n",
      "current at batch: 77 tensor(5.9105, dtype=torch.float64)\n",
      "7.579565763473511\n",
      "current at batch: 78 tensor(6.1818, dtype=torch.float64)\n",
      "7.897442579269409\n",
      "current at batch: 79 tensor(6.4575, dtype=torch.float64)\n",
      "8.156328678131104\n",
      "current at batch: 80 tensor(6.3540, dtype=torch.float64)\n",
      "8.918696165084839\n",
      "current at batch: 81 tensor(6.2235, dtype=torch.float64)\n",
      "7.375953435897827\n",
      "current at batch: 82 tensor(6.1172, dtype=torch.float64)\n",
      "8.170586824417114\n",
      "current at batch: 83 tensor(6.7770, dtype=torch.float64)\n",
      "8.536613464355469\n",
      "current at batch: 84 tensor(6.3254, dtype=torch.float64)\n",
      "7.4876580238342285\n",
      "current at batch: 85 tensor(6.1926, dtype=torch.float64)\n",
      "7.6017279624938965\n",
      "current at batch: 86 tensor(6.3468, dtype=torch.float64)\n",
      "10.79881739616394\n",
      "current at batch: 87 tensor(6.0522, dtype=torch.float64)\n",
      "9.385074853897095\n",
      "current at batch: 88 tensor(5.9833, dtype=torch.float64)\n",
      "12.002212285995483\n",
      "current at batch: 89 tensor(6.2401, dtype=torch.float64)\n",
      "11.329130172729492\n",
      "current at batch: 90 tensor(5.5666, dtype=torch.float64)\n",
      "10.115684509277344\n",
      "current at batch: 91 tensor(6.8444, dtype=torch.float64)\n",
      "11.382599830627441\n",
      "current at batch: 92 tensor(6.6264, dtype=torch.float64)\n",
      "10.492516279220581\n",
      "current at batch: 93 tensor(6.3409, dtype=torch.float64)\n",
      "9.10349726676941\n",
      "current at batch: 94 tensor(6.2517, dtype=torch.float64)\n",
      "9.69178819656372\n",
      "current at batch: 95 tensor(6.2946, dtype=torch.float64)\n",
      "9.37625503540039\n",
      "current at batch: 96 tensor(6.0242, dtype=torch.float64)\n",
      "8.559266090393066\n",
      "current at batch: 97 tensor(6.3653, dtype=torch.float64)\n",
      "8.289147853851318\n",
      "current at batch: 98 tensor(6.3661, dtype=torch.float64)\n",
      "8.14445161819458\n",
      "current at batch: 99 tensor(6.1440, dtype=torch.float64)\n",
      "8.231635332107544\n",
      "current at batch: 100 tensor(6.0937, dtype=torch.float64)\n",
      "8.156467199325562\n",
      "current at batch: 101 tensor(5.6193, dtype=torch.float64)\n",
      "7.817276477813721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 102 tensor(6.0273, dtype=torch.float64)\n",
      "7.753639221191406\n",
      "current at batch: 103 tensor(6.6197, dtype=torch.float64)\n",
      "7.611834526062012\n",
      "current at batch: 104 tensor(6.4645, dtype=torch.float64)\n",
      "8.453349828720093\n",
      "current at batch: 105 tensor(6.2418, dtype=torch.float64)\n",
      "8.076564311981201\n",
      "current at batch: 106 tensor(6.3996, dtype=torch.float64)\n",
      "8.109591722488403\n",
      "current at batch: 107 tensor(5.8811, dtype=torch.float64)\n",
      "7.710891962051392\n",
      "current at batch: 108 tensor(6.0319, dtype=torch.float64)\n",
      "7.750204801559448\n",
      "current at batch: 109 tensor(5.8696, dtype=torch.float64)\n",
      "7.890835285186768\n",
      "current at batch: 110 tensor(5.8004, dtype=torch.float64)\n",
      "7.4533281326293945\n",
      "current at batch: 111 tensor(6.2878, dtype=torch.float64)\n",
      "8.465172052383423\n",
      "current at batch: 112 tensor(6.1924, dtype=torch.float64)\n",
      "8.706313610076904\n",
      "current at batch: 113 tensor(6.2344, dtype=torch.float64)\n",
      "7.547065019607544\n",
      "current at batch: 114 tensor(6.0887, dtype=torch.float64)\n",
      "7.82833194732666\n",
      "current at batch: 115 tensor(5.9957, dtype=torch.float64)\n",
      "8.069064855575562\n",
      "current at batch: 116 tensor(6.4605, dtype=torch.float64)\n",
      "8.16464352607727\n",
      "current at batch: 117 tensor(6.2376, dtype=torch.float64)\n",
      "7.4969611167907715\n",
      "current at batch: 118 tensor(6.5952, dtype=torch.float64)\n",
      "10.065612077713013\n",
      "current at batch: 119 tensor(6.1901, dtype=torch.float64)\n",
      "10.322025775909424\n",
      "current at batch: 120 tensor(6.1378, dtype=torch.float64)\n",
      "9.226479768753052\n",
      "current at batch: 121 tensor(5.6798, dtype=torch.float64)\n",
      "9.920698165893555\n",
      "current at batch: 122 tensor(5.5582, dtype=torch.float64)\n",
      "9.366706609725952\n",
      "current at batch: 123 tensor(6.2457, dtype=torch.float64)\n",
      "10.501014471054077\n",
      "current at batch: 124 tensor(6.4032, dtype=torch.float64)\n",
      "9.794692039489746\n",
      "current at batch: 125 tensor(6.1738, dtype=torch.float64)\n",
      "10.59599757194519\n",
      "current at batch: 126 tensor(6.1675, dtype=torch.float64)\n",
      "10.381484270095825\n",
      "current at batch: 127 tensor(6.4201, dtype=torch.float64)\n",
      "9.884702920913696\n",
      "current at batch: 128 tensor(6.3017, dtype=torch.float64)\n",
      "10.678406476974487\n",
      "current at batch: 129 tensor(5.6627, dtype=torch.float64)\n",
      "9.743247032165527\n",
      "current at batch: 130 tensor(5.9865, dtype=torch.float64)\n",
      "10.568414688110352\n",
      "current at batch: 131 tensor(6.4364, dtype=torch.float64)\n",
      "10.037763833999634\n",
      "current at batch: 132 tensor(6.4131, dtype=torch.float64)\n",
      "10.638720035552979\n",
      "current at batch: 133 tensor(5.8954, dtype=torch.float64)\n",
      "9.67912220954895\n",
      "current at batch: 134 tensor(6.1676, dtype=torch.float64)\n",
      "10.960550308227539\n",
      "current at batch: 135 tensor(6.1267, dtype=torch.float64)\n",
      "10.957732677459717\n",
      "current at batch: 136 tensor(6.2873, dtype=torch.float64)\n",
      "10.291784524917603\n",
      "current at batch: 137 tensor(6.0425, dtype=torch.float64)\n",
      "10.362310647964478\n",
      "current at batch: 138 tensor(6.1978, dtype=torch.float64)\n",
      "10.827798128128052\n",
      "current at batch: 139 tensor(6.2095, dtype=torch.float64)\n",
      "10.40880823135376\n",
      "current at batch: 140 tensor(5.8226, dtype=torch.float64)\n",
      "9.98862361907959\n",
      "current at batch: 141 tensor(5.7075, dtype=torch.float64)\n",
      "10.204210042953491\n",
      "current at batch: 142 tensor(6.6183, dtype=torch.float64)\n",
      "10.328307628631592\n",
      "current at batch: 143 tensor(6.0405, dtype=torch.float64)\n",
      "10.213480710983276\n",
      "current at batch: 144 tensor(6.4435, dtype=torch.float64)\n",
      "10.768766164779663\n",
      "current at batch: 145 tensor(6.5775, dtype=torch.float64)\n",
      "10.341736793518066\n",
      "current at batch: 146 tensor(6.0533, dtype=torch.float64)\n",
      "10.165759563446045\n",
      "current at batch: 147 tensor(5.9323, dtype=torch.float64)\n",
      "9.621116638183594\n",
      "current at batch: 148 tensor(6.4871, dtype=torch.float64)\n",
      "10.2451012134552\n",
      "current at batch: 149 tensor(6.2406, dtype=torch.float64)\n",
      "10.924185276031494\n",
      "current at batch: 150 tensor(5.9816, dtype=torch.float64)\n",
      "10.330216407775879\n",
      "current at batch: 151 tensor(5.9370, dtype=torch.float64)\n",
      "10.11452031135559\n",
      "current at batch: 152 tensor(5.9361, dtype=torch.float64)\n",
      "10.21666169166565\n",
      "current at batch: 153 tensor(5.8385, dtype=torch.float64)\n",
      "9.177709341049194\n",
      "current at batch: 154 tensor(6.4819, dtype=torch.float64)\n",
      "9.311416387557983\n",
      "current at batch: 155 tensor(6.3749, dtype=torch.float64)\n",
      "8.283223867416382\n",
      "current at batch: 156 tensor(5.9251, dtype=torch.float64)\n",
      "7.109520673751831\n",
      "current at batch: 157 tensor(6.2920, dtype=torch.float64)\n",
      "7.9027204513549805\n",
      "current at batch: 158 tensor(6.1662, dtype=torch.float64)\n",
      "8.060675621032715\n",
      "current at batch: 159 tensor(6.1336, dtype=torch.float64)\n",
      "7.917135238647461\n",
      "current at batch: 160 tensor(5.7099, dtype=torch.float64)\n",
      "7.381711483001709\n",
      "current at batch: 161 tensor(6.0748, dtype=torch.float64)\n",
      "8.36202597618103\n",
      "current at batch: 162 tensor(6.5298, dtype=torch.float64)\n",
      "8.21686053276062\n",
      "current at batch: 163 tensor(6.1946, dtype=torch.float64)\n",
      "7.774524688720703\n",
      "current at batch: 164 tensor(6.1130, dtype=torch.float64)\n",
      "8.253387212753296\n",
      "current at batch: 165 tensor(6.2340, dtype=torch.float64)\n",
      "8.63861083984375\n",
      "current at batch: 166 tensor(6.0385, dtype=torch.float64)\n",
      "6.937521696090698\n",
      "current at batch: 167 tensor(5.7190, dtype=torch.float64)\n",
      "8.02832579612732\n",
      "current at batch: 168 tensor(6.6367, dtype=torch.float64)\n",
      "7.906410217285156\n",
      "current at batch: 169 tensor(6.0905, dtype=torch.float64)\n",
      "7.5258729457855225\n",
      "current at batch: 170 tensor(6.1391, dtype=torch.float64)\n",
      "7.583999872207642\n",
      "current at batch: 171 tensor(6.0673, dtype=torch.float64)\n",
      "7.236804723739624\n",
      "current at batch: 172 tensor(5.9382, dtype=torch.float64)\n",
      "9.223331928253174\n",
      "current at batch: 173 tensor(5.9581, dtype=torch.float64)\n",
      "9.556174755096436\n",
      "current at batch: 174 tensor(6.2554, dtype=torch.float64)\n",
      "7.376849889755249\n",
      "current at batch: 175 tensor(5.9944, dtype=torch.float64)\n",
      "8.322319746017456\n",
      "current at batch: 176 tensor(6.1021, dtype=torch.float64)\n",
      "10.599378824234009\n",
      "current at batch: 177 tensor(5.9649, dtype=torch.float64)\n",
      "10.375211477279663\n",
      "current at batch: 178 tensor(6.1879, dtype=torch.float64)\n",
      "9.26121711730957\n",
      "current at batch: 179 tensor(6.1673, dtype=torch.float64)\n",
      "11.672497510910034\n",
      "current at batch: 180 tensor(6.4470, dtype=torch.float64)\n",
      "11.587889671325684\n",
      "current at batch: 181 tensor(5.3679, dtype=torch.float64)\n",
      "9.952269077301025\n",
      "current at batch: 182 tensor(5.6762, dtype=torch.float64)\n",
      "10.107992887496948\n",
      "current at batch: 183 tensor(5.7427, dtype=torch.float64)\n",
      "11.141684532165527\n",
      "current at batch: 184 tensor(6.4602, dtype=torch.float64)\n",
      "10.798557996749878\n",
      "current at batch: 185 tensor(5.9731, dtype=torch.float64)\n",
      "10.178648233413696\n",
      "current at batch: 186 tensor(6.1085, dtype=torch.float64)\n",
      "10.42094373703003\n",
      "current at batch: 187 tensor(6.3193, dtype=torch.float64)\n",
      "11.664499044418335\n",
      "current at batch: 188 tensor(5.9269, dtype=torch.float64)\n",
      "10.88228726387024\n",
      "current at batch: 189 tensor(5.8150, dtype=torch.float64)\n",
      "7.703283071517944\n",
      "current at batch: 190 tensor(6.1155, dtype=torch.float64)\n",
      "7.566189765930176\n",
      "current at batch: 191 tensor(5.9782, dtype=torch.float64)\n",
      "7.7581212520599365\n",
      "current at batch: 192 tensor(5.4365, dtype=torch.float64)\n",
      "7.217322111129761\n",
      "current at batch: 193 tensor(5.9821, dtype=torch.float64)\n",
      "7.265774726867676\n",
      "current at batch: 194 tensor(6.5182, dtype=torch.float64)\n",
      "8.015806436538696\n",
      "current at batch: 195 tensor(6.0274, dtype=torch.float64)\n",
      "8.34773850440979\n",
      "current at batch: 196 tensor(5.7418, dtype=torch.float64)\n",
      "7.854824781417847\n",
      "current at batch: 197 tensor(6.4151, dtype=torch.float64)\n",
      "7.895033597946167\n",
      "current at batch: 198 tensor(6.0213, dtype=torch.float64)\n",
      "7.78140926361084\n",
      "current at batch: 199 tensor(6.5368, dtype=torch.float64)\n",
      "8.562675714492798\n",
      "current at batch: 200 tensor(6.0682, dtype=torch.float64)\n",
      "8.224858045578003\n",
      "current at batch: 201 tensor(5.2391, dtype=torch.float64)\n",
      "7.328272104263306\n",
      "current at batch: 202 tensor(5.9487, dtype=torch.float64)\n",
      "7.039714813232422\n",
      "current at batch: 203 tensor(6.0446, dtype=torch.float64)\n",
      "7.667876958847046\n",
      "current at batch: 204 tensor(6.7929, dtype=torch.float64)\n",
      "8.277488231658936\n",
      "current at batch: 205 tensor(6.0959, dtype=torch.float64)\n",
      "7.9968132972717285\n",
      "current at batch: 206 tensor(5.7977, dtype=torch.float64)\n",
      "8.28132152557373\n",
      "current at batch: 207 tensor(6.0807, dtype=torch.float64)\n",
      "8.53142237663269\n",
      "current at batch: 208 tensor(6.1739, dtype=torch.float64)\n",
      "7.789525747299194\n",
      "current at batch: 209 tensor(5.9131, dtype=torch.float64)\n",
      "7.9703590869903564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 210 tensor(5.8929, dtype=torch.float64)\n",
      "7.670681476593018\n",
      "current at batch: 211 tensor(6.2139, dtype=torch.float64)\n",
      "7.905567646026611\n",
      "current at batch: 212 tensor(5.9899, dtype=torch.float64)\n",
      "7.453275680541992\n",
      "current at batch: 213 tensor(5.9834, dtype=torch.float64)\n",
      "7.628714084625244\n",
      "current at batch: 214 tensor(6.0389, dtype=torch.float64)\n",
      "7.936647415161133\n",
      "current at batch: 215 tensor(5.6010, dtype=torch.float64)\n",
      "6.953265428543091\n",
      "current at batch: 216 tensor(6.0762, dtype=torch.float64)\n",
      "7.48454737663269\n",
      "current at batch: 217 tensor(6.9638, dtype=torch.float64)\n",
      "8.177958726882935\n",
      "current at batch: 218 tensor(6.0461, dtype=torch.float64)\n",
      "7.532344341278076\n",
      "current at batch: 219 tensor(6.4004, dtype=torch.float64)\n",
      "7.795900583267212\n",
      "current at batch: 220 tensor(5.8288, dtype=torch.float64)\n",
      "7.250150442123413\n",
      "current at batch: 221 tensor(5.9404, dtype=torch.float64)\n",
      "8.16051459312439\n",
      "current at batch: 222 tensor(6.2297, dtype=torch.float64)\n",
      "10.256023645401001\n",
      "current at batch: 223 tensor(6.2864, dtype=torch.float64)\n",
      "11.462506294250488\n",
      "current at batch: 224 tensor(6.0750, dtype=torch.float64)\n",
      "10.700106143951416\n",
      "current at batch: 225 tensor(5.5026, dtype=torch.float64)\n",
      "10.664335012435913\n",
      "current at batch: 226 tensor(6.0753, dtype=torch.float64)\n",
      "10.897444009780884\n",
      "current at batch: 227 tensor(6.1413, dtype=torch.float64)\n",
      "9.680551052093506\n",
      "current at batch: 228 tensor(5.7278, dtype=torch.float64)\n",
      "11.250768423080444\n",
      "current at batch: 229 tensor(5.3528, dtype=torch.float64)\n",
      "11.820154190063477\n",
      "current at batch: 230 tensor(5.9139, dtype=torch.float64)\n",
      "10.172089576721191\n",
      "current at batch: 231 tensor(6.4989, dtype=torch.float64)\n",
      "10.952762126922607\n",
      "current at batch: 232 tensor(5.3199, dtype=torch.float64)\n",
      "11.711158752441406\n",
      "current at batch: 233 tensor(5.6408, dtype=torch.float64)\n",
      "11.740084886550903\n",
      "current at batch: 234 tensor(6.1844, dtype=torch.float64)\n",
      "11.531482458114624\n",
      "current at batch: 235 tensor(6.2010, dtype=torch.float64)\n",
      "11.033498048782349\n",
      "current at batch: 236 tensor(6.4174, dtype=torch.float64)\n",
      "12.545153379440308\n",
      "current at batch: 237 tensor(6.0857, dtype=torch.float64)\n",
      "11.188200235366821\n",
      "current at batch: 238 tensor(6.6212, dtype=torch.float64)\n",
      "11.55866813659668\n",
      "current at batch: 239 tensor(6.2990, dtype=torch.float64)\n",
      "12.097720623016357\n",
      "current at batch: 240 tensor(5.5667, dtype=torch.float64)\n",
      "11.881653547286987\n",
      "current at batch: 241 tensor(6.0496, dtype=torch.float64)\n",
      "10.609594345092773\n",
      "current at batch: 242 tensor(6.1219, dtype=torch.float64)\n",
      "9.333550930023193\n",
      "current at batch: 243 tensor(6.7292, dtype=torch.float64)\n",
      "8.569117546081543\n",
      "current at batch: 244 tensor(6.1722, dtype=torch.float64)\n",
      "8.812681674957275\n",
      "current at batch: 245 tensor(6.7227, dtype=torch.float64)\n",
      "11.218976736068726\n",
      "current at batch: 246 tensor(5.7981, dtype=torch.float64)\n",
      "9.78223180770874\n",
      "current at batch: 247 tensor(6.0476, dtype=torch.float64)\n",
      "10.661535263061523\n",
      "current at batch: 248 tensor(6.1448, dtype=torch.float64)\n",
      "12.107079267501831\n",
      "current at batch: 249 tensor(5.6584, dtype=torch.float64)\n",
      "9.862218618392944\n",
      "current at batch: 250 tensor(5.5768, dtype=torch.float64)\n",
      "10.775351762771606\n",
      "current at batch: 251 tensor(6.5798, dtype=torch.float64)\n",
      "11.320884943008423\n",
      "current at batch: 252 tensor(5.9550, dtype=torch.float64)\n",
      "10.20339822769165\n",
      "current at batch: 253 tensor(6.0831, dtype=torch.float64)\n",
      "10.243545770645142\n",
      "current at batch: 254 tensor(6.4457, dtype=torch.float64)\n",
      "11.520991086959839\n",
      "current at batch: 255 tensor(6.5418, dtype=torch.float64)\n",
      "10.595122575759888\n",
      "current at batch: 256 tensor(6.3629, dtype=torch.float64)\n",
      "9.708969354629517\n",
      "current at batch: 257 tensor(6.3823, dtype=torch.float64)\n",
      "10.775893926620483\n",
      "current at batch: 258 tensor(6.5975, dtype=torch.float64)\n",
      "11.933502435684204\n",
      "current at batch: 259 tensor(5.7199, dtype=torch.float64)\n",
      "9.316990613937378\n",
      "current at batch: 260 tensor(5.9277, dtype=torch.float64)\n",
      "11.024683475494385\n",
      "current at batch: 261 tensor(5.9157, dtype=torch.float64)\n",
      "11.236612319946289\n",
      "current at batch: 262 tensor(6.2448, dtype=torch.float64)\n",
      "10.129255294799805\n",
      "current at batch: 263 tensor(6.2089, dtype=torch.float64)\n",
      "11.101624488830566\n",
      "current at batch: 264 tensor(5.8863, dtype=torch.float64)\n",
      "11.251904249191284\n",
      "current at batch: 265 tensor(6.0214, dtype=torch.float64)\n",
      "9.933660984039307\n",
      "current at batch: 266 tensor(6.5015, dtype=torch.float64)\n",
      "11.5720694065094\n",
      "current at batch: 267 tensor(6.0696, dtype=torch.float64)\n",
      "11.71518874168396\n",
      "current at batch: 268 tensor(5.9681, dtype=torch.float64)\n",
      "12.297865629196167\n",
      "current at batch: 269 tensor(6.4164, dtype=torch.float64)\n",
      "10.21902322769165\n",
      "current at batch: 270 tensor(5.8755, dtype=torch.float64)\n",
      "10.87273645401001\n",
      "current at batch: 271 tensor(5.8049, dtype=torch.float64)\n",
      "11.869891166687012\n",
      "current at batch: 272 tensor(5.8579, dtype=torch.float64)\n",
      "11.331154823303223\n",
      "current at batch: 273 tensor(6.1715, dtype=torch.float64)\n",
      "10.016008377075195\n",
      "current at batch: 274 tensor(5.8070, dtype=torch.float64)\n",
      "11.300483703613281\n",
      "current at batch: 275 tensor(5.9852, dtype=torch.float64)\n",
      "11.532843828201294\n",
      "current at batch: 276 tensor(6.2082, dtype=torch.float64)\n",
      "10.363795757293701\n",
      "current at batch: 277 tensor(6.8031, dtype=torch.float64)\n",
      "11.824276685714722\n",
      "current at batch: 278 tensor(5.7935, dtype=torch.float64)\n",
      "10.503716707229614\n",
      "current at batch: 279 tensor(6.1440, dtype=torch.float64)\n",
      "9.766981601715088\n",
      "current at batch: 280 tensor(5.9406, dtype=torch.float64)\n",
      "11.156477451324463\n",
      "current at batch: 281 tensor(6.1203, dtype=torch.float64)\n",
      "10.703348875045776\n",
      "current at batch: 282 tensor(6.2570, dtype=torch.float64)\n",
      "9.937476396560669\n",
      "current at batch: 283 tensor(6.1195, dtype=torch.float64)\n",
      "10.899986267089844\n",
      "current at batch: 284 tensor(6.4854, dtype=torch.float64)\n",
      "10.606799364089966\n",
      "current at batch: 285 tensor(5.7991, dtype=torch.float64)\n",
      "9.609566450119019\n",
      "current at batch: 286 tensor(6.1651, dtype=torch.float64)\n",
      "11.451571702957153\n",
      "current at batch: 287 tensor(6.9803, dtype=torch.float64)\n",
      "10.919053077697754\n",
      "current at batch: 288 tensor(6.3123, dtype=torch.float64)\n",
      "10.75630235671997\n",
      "current at batch: 289 tensor(6.7366, dtype=torch.float64)\n",
      "11.492562055587769\n",
      "current at batch: 290 tensor(5.9902, dtype=torch.float64)\n",
      "10.48200511932373\n",
      "current at batch: 291 tensor(6.6064, dtype=torch.float64)\n",
      "9.886087417602539\n",
      "current at batch: 292 tensor(6.3440, dtype=torch.float64)\n",
      "13.027248620986938\n",
      "current at batch: 293 tensor(6.7796, dtype=torch.float64)\n",
      "10.348974227905273\n",
      "current at batch: 294 tensor(6.2082, dtype=torch.float64)\n",
      "10.102667093276978\n",
      "current at batch: 295 tensor(6.2509, dtype=torch.float64)\n",
      "11.83940076828003\n",
      "current at batch: 296 tensor(6.1184, dtype=torch.float64)\n",
      "10.988579273223877\n",
      "current at batch: 297 tensor(6.4065, dtype=torch.float64)\n",
      "11.493931770324707\n",
      "current at batch: 298 tensor(5.6011, dtype=torch.float64)\n",
      "11.35885214805603\n",
      "current at batch: 299 tensor(6.4110, dtype=torch.float64)\n",
      "12.299001932144165\n",
      "current at batch: 300 tensor(6.4931, dtype=torch.float64)\n",
      "10.828344821929932\n",
      "current at batch: 301 tensor(6.3738, dtype=torch.float64)\n",
      "14.539021253585815\n",
      "current at batch: 302 tensor(5.7360, dtype=torch.float64)\n",
      "13.394508361816406\n",
      "current at batch: 303 tensor(6.1026, dtype=torch.float64)\n",
      "13.548112392425537\n",
      "current at batch: 304 tensor(5.7280, dtype=torch.float64)\n",
      "13.522986888885498\n",
      "current at batch: 305 tensor(6.4536, dtype=torch.float64)\n",
      "14.032893657684326\n",
      "current at batch: 306 tensor(6.0717, dtype=torch.float64)\n",
      "13.348309993743896\n",
      "current at batch: 307 tensor(5.8926, dtype=torch.float64)\n",
      "12.561917543411255\n",
      "current at batch: 308 tensor(5.6906, dtype=torch.float64)\n",
      "14.320534944534302\n",
      "current at batch: 309 tensor(6.1358, dtype=torch.float64)\n",
      "14.583081483840942\n",
      "current at batch: 310 tensor(5.8538, dtype=torch.float64)\n",
      "12.829228639602661\n",
      "current at batch: 311 tensor(6.1739, dtype=torch.float64)\n",
      "14.440838813781738\n",
      "current at batch: 312 tensor(6.0623, dtype=torch.float64)\n",
      "13.264813661575317\n",
      "current at batch: 313 tensor(5.7111, dtype=torch.float64)\n",
      "13.003777980804443\n",
      "current at batch: 314 tensor(6.4213, dtype=torch.float64)\n",
      "13.360564231872559\n",
      "current at batch: 315 tensor(5.9483, dtype=torch.float64)\n",
      "13.655996084213257\n",
      "current at batch: 316 tensor(6.0833, dtype=torch.float64)\n",
      "13.030988931655884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 317 tensor(6.7141, dtype=torch.float64)\n",
      "13.252708673477173\n",
      "current at batch: 318 tensor(5.8737, dtype=torch.float64)\n",
      "14.534344673156738\n",
      "current at batch: 319 tensor(6.2720, dtype=torch.float64)\n",
      "11.988856077194214\n",
      "current at batch: 320 tensor(6.4944, dtype=torch.float64)\n",
      "11.637686252593994\n",
      "current at batch: 321 tensor(6.5209, dtype=torch.float64)\n",
      "15.04266619682312\n",
      "current at batch: 322 tensor(6.5857, dtype=torch.float64)\n",
      "13.788320064544678\n",
      "current at batch: 323 tensor(6.0401, dtype=torch.float64)\n",
      "13.292675971984863\n",
      "current at batch: 324 tensor(6.1279, dtype=torch.float64)\n",
      "13.912520170211792\n",
      "current at batch: 325 tensor(5.7922, dtype=torch.float64)\n",
      "12.298288106918335\n",
      "current at batch: 326 tensor(6.1639, dtype=torch.float64)\n",
      "14.088367223739624\n",
      "current at batch: 327 tensor(6.2297, dtype=torch.float64)\n",
      "13.093170642852783\n",
      "current at batch: 328 tensor(6.1520, dtype=torch.float64)\n",
      "13.852466344833374\n",
      "current at batch: 329 tensor(5.8517, dtype=torch.float64)\n",
      "13.37314224243164\n",
      "current at batch: 330 tensor(6.4405, dtype=torch.float64)\n",
      "12.086653232574463\n",
      "current at batch: 331 tensor(5.9530, dtype=torch.float64)\n",
      "13.405403137207031\n",
      "current at batch: 332 tensor(6.4308, dtype=torch.float64)\n",
      "13.61667799949646\n",
      "current at batch: 333 tensor(6.2741, dtype=torch.float64)\n",
      "13.860620975494385\n",
      "current at batch: 334 tensor(5.8038, dtype=torch.float64)\n",
      "13.594820976257324\n",
      "current at batch: 335 tensor(5.8565, dtype=torch.float64)\n",
      "12.778303623199463\n",
      "current at batch: 336 tensor(6.2556, dtype=torch.float64)\n",
      "11.768336296081543\n",
      "current at batch: 337 tensor(6.3857, dtype=torch.float64)\n",
      "13.734530448913574\n",
      "current at batch: 338 tensor(6.4367, dtype=torch.float64)\n",
      "14.630468845367432\n",
      "current at batch: 339 tensor(6.0686, dtype=torch.float64)\n",
      "12.019860744476318\n",
      "current at batch: 340 tensor(6.2398, dtype=torch.float64)\n",
      "13.97316837310791\n",
      "current at batch: 341 tensor(6.5269, dtype=torch.float64)\n",
      "14.142878770828247\n",
      "current at batch: 342 tensor(5.9890, dtype=torch.float64)\n",
      "13.113271713256836\n",
      "current at batch: 343 tensor(5.4136, dtype=torch.float64)\n",
      "12.378059148788452\n",
      "current at batch: 344 tensor(5.5824, dtype=torch.float64)\n",
      "13.615702867507935\n",
      "current at batch: 345 tensor(6.1075, dtype=torch.float64)\n",
      "13.971611976623535\n",
      "current at batch: 346 tensor(6.8771, dtype=torch.float64)\n",
      "13.643612623214722\n",
      "current at batch: 347 tensor(5.9387, dtype=torch.float64)\n",
      "12.487988233566284\n",
      "current at batch: 348 tensor(6.0075, dtype=torch.float64)\n",
      "12.79814076423645\n",
      "current at batch: 349 tensor(5.9931, dtype=torch.float64)\n",
      "13.150217771530151\n",
      "current at batch: 350 tensor(5.9428, dtype=torch.float64)\n",
      "14.439467906951904\n",
      "current at batch: 351 tensor(6.4913, dtype=torch.float64)\n",
      "14.552315711975098\n",
      "current at batch: 352 tensor(5.8410, dtype=torch.float64)\n",
      "13.19601583480835\n",
      "current at batch: 353 tensor(6.1206, dtype=torch.float64)\n",
      "12.893075704574585\n",
      "current at batch: 354 tensor(6.1092, dtype=torch.float64)\n",
      "14.347322940826416\n",
      "current at batch: 355 tensor(6.2562, dtype=torch.float64)\n",
      "13.521058559417725\n",
      "current at batch: 356 tensor(6.0430, dtype=torch.float64)\n",
      "12.068462133407593\n",
      "current at batch: 357 tensor(6.2929, dtype=torch.float64)\n",
      "14.955771446228027\n",
      "current at batch: 358 tensor(6.0545, dtype=torch.float64)\n",
      "14.334625720977783\n",
      "current at batch: 359 tensor(5.7853, dtype=torch.float64)\n",
      "12.829777240753174\n",
      "current at batch: 360 tensor(6.0812, dtype=torch.float64)\n",
      "12.567153930664062\n",
      "current at batch: 361 tensor(5.7889, dtype=torch.float64)\n",
      "14.04198408126831\n",
      "current at batch: 362 tensor(5.5832, dtype=torch.float64)\n",
      "14.852817296981812\n",
      "current at batch: 363 tensor(5.7269, dtype=torch.float64)\n",
      "11.977962255477905\n",
      "current at batch: 364 tensor(6.6915, dtype=torch.float64)\n",
      "13.67962908744812\n",
      "current at batch: 365 tensor(5.9252, dtype=torch.float64)\n",
      "12.830379009246826\n",
      "current at batch: 366 tensor(6.3169, dtype=torch.float64)\n",
      "12.25653338432312\n",
      "current at batch: 367 tensor(6.2664, dtype=torch.float64)\n",
      "14.782102346420288\n",
      "current at batch: 368 tensor(6.2830, dtype=torch.float64)\n",
      "13.764245748519897\n",
      "current at batch: 369 tensor(6.5615, dtype=torch.float64)\n",
      "13.329612255096436\n",
      "current at batch: 370 tensor(5.5911, dtype=torch.float64)\n",
      "12.944332122802734\n",
      "current at batch: 371 tensor(6.4148, dtype=torch.float64)\n",
      "14.379096508026123\n",
      "current at batch: 372 tensor(6.8739, dtype=torch.float64)\n",
      "13.632471799850464\n",
      "current at batch: 373 tensor(6.2891, dtype=torch.float64)\n",
      "13.833862781524658\n",
      "current at batch: 374 tensor(6.7896, dtype=torch.float64)\n",
      "13.754025936126709\n",
      "current at batch: 375 tensor(5.8569, dtype=torch.float64)\n",
      "13.384941339492798\n",
      "current at batch: 376 tensor(6.1351, dtype=torch.float64)\n",
      "12.443039894104004\n",
      "current at batch: 377 tensor(6.3161, dtype=torch.float64)\n",
      "12.914467811584473\n",
      "current at batch: 378 tensor(5.8979, dtype=torch.float64)\n",
      "13.94910216331482\n",
      "current at batch: 379 tensor(6.0484, dtype=torch.float64)\n",
      "13.512065649032593\n",
      "current at batch: 380 tensor(6.5063, dtype=torch.float64)\n",
      "14.893988132476807\n",
      "current at batch: 381 tensor(6.3475, dtype=torch.float64)\n",
      "14.459348440170288\n",
      "current at batch: 382 tensor(6.0572, dtype=torch.float64)\n",
      "12.546721935272217\n",
      "current at batch: 383 tensor(5.9595, dtype=torch.float64)\n",
      "13.212844610214233\n",
      "current at batch: 384 tensor(5.7126, dtype=torch.float64)\n",
      "14.584407567977905\n",
      "current at batch: 385 tensor(6.0185, dtype=torch.float64)\n",
      "14.407826662063599\n",
      "current at batch: 386 tensor(5.9328, dtype=torch.float64)\n",
      "12.542299270629883\n",
      "current at batch: 387 tensor(6.5806, dtype=torch.float64)\n",
      "13.589291334152222\n",
      "current at batch: 388 tensor(5.9223, dtype=torch.float64)\n",
      "13.265486001968384\n",
      "current at batch: 389 tensor(6.0907, dtype=torch.float64)\n",
      "12.821094989776611\n",
      "current at batch: 390 tensor(6.6966, dtype=torch.float64)\n",
      "13.933550119400024\n",
      "current at batch: 391 tensor(6.1533, dtype=torch.float64)\n",
      "14.938852548599243\n",
      "current at batch: 392 tensor(5.7657, dtype=torch.float64)\n",
      "12.473236322402954\n",
      "current at batch: 393 tensor(6.1877, dtype=torch.float64)\n",
      "12.23310136795044\n",
      "current at batch: 394 tensor(5.8724, dtype=torch.float64)\n",
      "14.154114484786987\n",
      "current at batch: 395 tensor(6.0833, dtype=torch.float64)\n",
      "13.449556112289429\n",
      "current at batch: 396 tensor(6.2571, dtype=torch.float64)\n",
      "13.204857349395752\n",
      "current at batch: 397 tensor(6.2855, dtype=torch.float64)\n",
      "13.36107873916626\n",
      "current at batch: 398 tensor(6.2162, dtype=torch.float64)\n",
      "13.940842390060425\n",
      "current at batch: 399 tensor(6.0678, dtype=torch.float64)\n",
      "12.954572677612305\n",
      "current at batch: 400 tensor(5.8484, dtype=torch.float64)\n",
      "12.556601524353027\n",
      "current at batch: 401 tensor(6.3856, dtype=torch.float64)\n",
      "13.956433057785034\n",
      "current at batch: 402 tensor(5.9856, dtype=torch.float64)\n",
      "13.750179290771484\n",
      "current at batch: 403 tensor(5.7825, dtype=torch.float64)\n",
      "14.066280364990234\n",
      "current at batch: 404 tensor(5.5712, dtype=torch.float64)\n",
      "13.469017267227173\n",
      "current at batch: 405 tensor(6.3890, dtype=torch.float64)\n",
      "14.425883054733276\n",
      "current at batch: 406 tensor(5.7990, dtype=torch.float64)\n",
      "11.890559434890747\n",
      "current at batch: 407 tensor(5.6408, dtype=torch.float64)\n",
      "12.556601524353027\n",
      "current at batch: 408 tensor(6.1588, dtype=torch.float64)\n",
      "13.531522989273071\n",
      "current at batch: 409 tensor(5.6779, dtype=torch.float64)\n",
      "13.656225204467773\n",
      "current at batch: 410 tensor(5.6464, dtype=torch.float64)\n",
      "14.435287237167358\n",
      "current at batch: 411 tensor(6.2561, dtype=torch.float64)\n",
      "14.453425168991089\n",
      "current at batch: 412 tensor(5.9978, dtype=torch.float64)\n",
      "13.927197933197021\n",
      "current at batch: 413 tensor(5.3711, dtype=torch.float64)\n",
      "12.403263807296753\n",
      "current at batch: 414 tensor(5.8447, dtype=torch.float64)\n",
      "13.79724907875061\n",
      "current at batch: 415 tensor(6.4176, dtype=torch.float64)\n",
      "15.047281742095947\n",
      "current at batch: 416 tensor(6.1863, dtype=torch.float64)\n",
      "12.839766025543213\n",
      "current at batch: 417 tensor(5.8238, dtype=torch.float64)\n",
      "14.549864053726196\n",
      "current at batch: 418 tensor(6.5866, dtype=torch.float64)\n",
      "14.797270059585571\n",
      "current at batch: 419 tensor(6.0713, dtype=torch.float64)\n",
      "13.339994192123413\n",
      "current at batch: 420 tensor(6.4987, dtype=torch.float64)\n",
      "13.437857627868652\n",
      "current at batch: 421 tensor(5.9310, dtype=torch.float64)\n",
      "14.642465114593506\n",
      "current at batch: 422 tensor(6.1436, dtype=torch.float64)\n",
      "13.27776312828064\n",
      "current at batch: 423 tensor(6.5381, dtype=torch.float64)\n",
      "13.844118356704712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 424 tensor(5.9523, dtype=torch.float64)\n",
      "13.422230005264282\n",
      "current at batch: 425 tensor(6.2020, dtype=torch.float64)\n",
      "13.893500328063965\n",
      "current at batch: 426 tensor(6.3046, dtype=torch.float64)\n",
      "13.745432376861572\n",
      "current at batch: 427 tensor(6.0044, dtype=torch.float64)\n",
      "14.562891006469727\n",
      "current at batch: 428 tensor(6.2974, dtype=torch.float64)\n",
      "13.670210123062134\n",
      "current at batch: 429 tensor(6.1544, dtype=torch.float64)\n",
      "11.953449964523315\n",
      "current at batch: 430 tensor(6.6081, dtype=torch.float64)\n",
      "13.674748420715332\n",
      "current at batch: 431 tensor(6.1543, dtype=torch.float64)\n",
      "14.779008388519287\n",
      "current at batch: 432 tensor(6.1216, dtype=torch.float64)\n",
      "14.450751066207886\n",
      "current at batch: 433 tensor(5.8818, dtype=torch.float64)\n",
      "13.094046115875244\n",
      "current at batch: 434 tensor(6.0744, dtype=torch.float64)\n",
      "13.547149896621704\n",
      "current at batch: 435 tensor(6.5869, dtype=torch.float64)\n",
      "12.75434160232544\n",
      "current at batch: 436 tensor(6.0745, dtype=torch.float64)\n",
      "13.062769174575806\n",
      "current at batch: 437 tensor(6.0162, dtype=torch.float64)\n",
      "13.062774896621704\n",
      "current at batch: 438 tensor(6.0459, dtype=torch.float64)\n",
      "15.195809602737427\n",
      "current at batch: 439 tensor(6.4781, dtype=torch.float64)\n",
      "13.890917778015137\n",
      "current at batch: 440 tensor(6.5282, dtype=torch.float64)\n",
      "12.156503200531006\n",
      "current at batch: 441 tensor(5.8030, dtype=torch.float64)\n",
      "13.060526371002197\n",
      "current at batch: 442 tensor(6.4090, dtype=torch.float64)\n",
      "15.234680652618408\n",
      "current at batch: 443 tensor(5.8413, dtype=torch.float64)\n",
      "13.03151249885559\n",
      "current at batch: 444 tensor(5.8895, dtype=torch.float64)\n",
      "13.488197565078735\n",
      "current at batch: 445 tensor(5.8407, dtype=torch.float64)\n",
      "13.906543731689453\n",
      "current at batch: 446 tensor(5.9670, dtype=torch.float64)\n",
      "11.67099642753601\n",
      "current at batch: 447 tensor(6.5338, dtype=torch.float64)\n",
      "15.039331912994385\n",
      "current at batch: 448 tensor(6.2472, dtype=torch.float64)\n",
      "15.658534526824951\n",
      "current at batch: 449 tensor(6.0576, dtype=torch.float64)\n",
      "14.196182012557983\n",
      "current at batch: 450 tensor(5.4613, dtype=torch.float64)\n",
      "14.21261715888977\n",
      "current at batch: 451 tensor(6.0658, dtype=torch.float64)\n",
      "13.591434001922607\n",
      "current at batch: 452 tensor(6.0906, dtype=torch.float64)\n",
      "13.531522750854492\n",
      "current at batch: 453 tensor(6.4675, dtype=torch.float64)\n",
      "13.406522274017334\n",
      "current at batch: 454 tensor(6.1644, dtype=torch.float64)\n",
      "13.08222770690918\n",
      "current at batch: 455 tensor(5.9327, dtype=torch.float64)\n",
      "14.140911102294922\n",
      "current at batch: 456 tensor(6.0790, dtype=torch.float64)\n",
      "14.48915433883667\n",
      "current at batch: 457 tensor(5.6850, dtype=torch.float64)\n",
      "13.489163637161255\n",
      "current at batch: 458 tensor(6.0957, dtype=torch.float64)\n",
      "13.578409194946289\n",
      "current at batch: 459 tensor(5.8604, dtype=torch.float64)\n",
      "12.68775725364685\n",
      "current at batch: 460 tensor(6.2542, dtype=torch.float64)\n",
      "11.795891523361206\n",
      "current at batch: 461 tensor(5.8415, dtype=torch.float64)\n",
      "14.447982788085938\n",
      "current at batch: 462 tensor(6.4937, dtype=torch.float64)\n",
      "16.609724283218384\n",
      "current at batch: 463 tensor(6.3246, dtype=torch.float64)\n",
      "14.385392189025879\n",
      "current at batch: 464 tensor(6.4459, dtype=torch.float64)\n",
      "12.953387975692749\n",
      "current at batch: 465 tensor(6.2721, dtype=torch.float64)\n",
      "13.64261245727539\n",
      "current at batch: 466 tensor(5.6677, dtype=torch.float64)\n",
      "11.960590839385986\n",
      "current at batch: 467 tensor(6.1573, dtype=torch.float64)\n",
      "13.360791683197021\n",
      "current at batch: 468 tensor(6.2817, dtype=torch.float64)\n",
      "14.791289567947388\n",
      "current at batch: 469 tensor(6.2388, dtype=torch.float64)\n",
      "13.406522989273071\n",
      "current at batch: 470 tensor(5.8491, dtype=torch.float64)\n",
      "12.338402032852173\n",
      "current at batch: 471 tensor(6.2270, dtype=torch.float64)\n",
      "15.026108980178833\n",
      "current at batch: 472 tensor(4.6761, dtype=torch.float64)\n",
      "1.796924352645874\n",
      "epoch =  3 \n",
      " tensor(2893.3926, dtype=torch.float64)\n",
      "current at batch: 1 tensor(6.5988, dtype=torch.float64)\n",
      "15.234684705734253\n",
      "current at batch: 2 tensor(5.8694, dtype=torch.float64)\n",
      "13.352529764175415\n",
      "current at batch: 3 tensor(6.3740, dtype=torch.float64)\n",
      "13.812782526016235\n",
      "current at batch: 4 tensor(5.5183, dtype=torch.float64)\n",
      "12.865357398986816\n",
      "current at batch: 5 tensor(5.9262, dtype=torch.float64)\n",
      "13.254575490951538\n",
      "current at batch: 6 tensor(6.5800, dtype=torch.float64)\n",
      "14.57899022102356\n",
      "current at batch: 7 tensor(5.6367, dtype=torch.float64)\n",
      "12.687771320343018\n",
      "current at batch: 8 tensor(6.2896, dtype=torch.float64)\n",
      "13.218588829040527\n",
      "current at batch: 9 tensor(6.0763, dtype=torch.float64)\n",
      "13.95591139793396\n",
      "current at batch: 10 tensor(5.4967, dtype=torch.float64)\n",
      "13.828402042388916\n",
      "current at batch: 11 tensor(5.9083, dtype=torch.float64)\n",
      "14.551169633865356\n",
      "current at batch: 12 tensor(5.9006, dtype=torch.float64)\n",
      "14.750304698944092\n",
      "current at batch: 13 tensor(7.0482, dtype=torch.float64)\n",
      "13.969037532806396\n",
      "current at batch: 14 tensor(5.7660, dtype=torch.float64)\n",
      "14.338854551315308\n",
      "current at batch: 15 tensor(5.7410, dtype=torch.float64)\n",
      "11.861467123031616\n",
      "current at batch: 16 tensor(5.8869, dtype=torch.float64)\n",
      "13.062766790390015\n",
      "current at batch: 17 tensor(5.7860, dtype=torch.float64)\n",
      "13.344032764434814\n",
      "current at batch: 18 tensor(6.2937, dtype=torch.float64)\n",
      "13.435856342315674\n",
      "current at batch: 19 tensor(5.7750, dtype=torch.float64)\n",
      "12.79224967956543\n",
      "current at batch: 20 tensor(6.7072, dtype=torch.float64)\n",
      "13.125282526016235\n",
      "current at batch: 21 tensor(6.0815, dtype=torch.float64)\n",
      "14.46427321434021\n",
      "current at batch: 22 tensor(5.7018, dtype=torch.float64)\n",
      "12.343998193740845\n",
      "current at batch: 23 tensor(6.0544, dtype=torch.float64)\n",
      "14.07841682434082\n",
      "current at batch: 24 tensor(5.9171, dtype=torch.float64)\n",
      "13.651944875717163\n",
      "current at batch: 25 tensor(6.2333, dtype=torch.float64)\n",
      "13.415333032608032\n",
      "current at batch: 26 tensor(6.2300, dtype=torch.float64)\n",
      "12.312748670578003\n",
      "current at batch: 27 tensor(6.6573, dtype=torch.float64)\n",
      "15.042296648025513\n",
      "current at batch: 28 tensor(6.1170, dtype=torch.float64)\n",
      "14.169235229492188\n",
      "current at batch: 29 tensor(5.6866, dtype=torch.float64)\n",
      "12.654289245605469\n",
      "current at batch: 30 tensor(5.2918, dtype=torch.float64)\n",
      "13.085299968719482\n",
      "current at batch: 31 tensor(5.7122, dtype=torch.float64)\n",
      "13.97190523147583\n",
      "current at batch: 32 tensor(6.0157, dtype=torch.float64)\n",
      "11.281551599502563\n",
      "current at batch: 33 tensor(5.8580, dtype=torch.float64)\n",
      "12.73471999168396\n",
      "current at batch: 34 tensor(5.9688, dtype=torch.float64)\n",
      "15.215665340423584\n",
      "current at batch: 35 tensor(5.2890, dtype=torch.float64)\n",
      "14.19864535331726\n",
      "current at batch: 36 tensor(5.8941, dtype=torch.float64)\n",
      "12.422206401824951\n",
      "current at batch: 37 tensor(5.8364, dtype=torch.float64)\n",
      "11.948335886001587\n",
      "current at batch: 38 tensor(6.5367, dtype=torch.float64)\n",
      "13.199472427368164\n",
      "current at batch: 39 tensor(6.1164, dtype=torch.float64)\n",
      "13.256621599197388\n",
      "current at batch: 40 tensor(6.0575, dtype=torch.float64)\n",
      "13.261203289031982\n",
      "current at batch: 41 tensor(5.8456, dtype=torch.float64)\n",
      "14.193127393722534\n",
      "current at batch: 42 tensor(6.4847, dtype=torch.float64)\n",
      "12.812849044799805\n",
      "current at batch: 43 tensor(5.7807, dtype=torch.float64)\n",
      "12.09407925605774\n",
      "current at batch: 44 tensor(5.9398, dtype=torch.float64)\n",
      "14.37284541130066\n",
      "current at batch: 45 tensor(5.7850, dtype=torch.float64)\n",
      "14.141001462936401\n",
      "current at batch: 46 tensor(6.6486, dtype=torch.float64)\n",
      "13.031601428985596\n",
      "current at batch: 47 tensor(6.5392, dtype=torch.float64)\n",
      "14.23323655128479\n",
      "current at batch: 48 tensor(6.0894, dtype=torch.float64)\n",
      "13.984753608703613\n",
      "current at batch: 49 tensor(5.5990, dtype=torch.float64)\n",
      "12.194511890411377\n",
      "current at batch: 50 tensor(5.9211, dtype=torch.float64)\n",
      "13.390894889831543\n",
      "current at batch: 51 tensor(5.8020, dtype=torch.float64)\n",
      "14.86148977279663\n",
      "current at batch: 52 tensor(5.6101, dtype=torch.float64)\n",
      "13.29714560508728\n",
      "current at batch: 53 tensor(5.9304, dtype=torch.float64)\n",
      "12.68775224685669\n",
      "current at batch: 54 tensor(5.9113, dtype=torch.float64)\n",
      "14.46198058128357\n",
      "current at batch: 55 tensor(6.0320, dtype=torch.float64)\n",
      "12.765884637832642\n",
      "current at batch: 56 tensor(5.7090, dtype=torch.float64)\n",
      "12.422123432159424\n",
      "current at batch: 57 tensor(5.9651, dtype=torch.float64)\n",
      "14.553582906723022\n",
      "current at batch: 58 tensor(6.0256, dtype=torch.float64)\n",
      "13.969032287597656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 59 tensor(5.8785, dtype=torch.float64)\n",
      "12.761072635650635\n",
      "current at batch: 60 tensor(6.2095, dtype=torch.float64)\n",
      "12.031501531600952\n",
      "current at batch: 61 tensor(6.3492, dtype=torch.float64)\n",
      "14.763693571090698\n",
      "current at batch: 62 tensor(5.7830, dtype=torch.float64)\n",
      "13.672152519226074\n",
      "current at batch: 63 tensor(6.0354, dtype=torch.float64)\n",
      "12.672144651412964\n",
      "current at batch: 64 tensor(5.8511, dtype=torch.float64)\n",
      "13.742508172988892\n",
      "current at batch: 65 tensor(6.0067, dtype=torch.float64)\n",
      "12.750262022018433\n",
      "current at batch: 66 tensor(5.9892, dtype=torch.float64)\n",
      "13.359643936157227\n",
      "current at batch: 67 tensor(6.0925, dtype=torch.float64)\n",
      "14.258811235427856\n",
      "current at batch: 68 tensor(5.7902, dtype=torch.float64)\n",
      "13.434951066970825\n",
      "current at batch: 69 tensor(6.1744, dtype=torch.float64)\n",
      "12.649287462234497\n",
      "current at batch: 70 tensor(5.4068, dtype=torch.float64)\n",
      "15.159606695175171\n",
      "current at batch: 71 tensor(6.1481, dtype=torch.float64)\n",
      "13.500281810760498\n",
      "current at batch: 72 tensor(5.7312, dtype=torch.float64)\n",
      "11.593981742858887\n",
      "current at batch: 73 tensor(6.3176, dtype=torch.float64)\n",
      "13.969039916992188\n",
      "current at batch: 74 tensor(5.5156, dtype=torch.float64)\n",
      "13.950299263000488\n",
      "current at batch: 75 tensor(5.6234, dtype=torch.float64)\n",
      "12.656505346298218\n",
      "current at batch: 76 tensor(6.0699, dtype=torch.float64)\n",
      "13.469024896621704\n",
      "current at batch: 77 tensor(6.4652, dtype=torch.float64)\n",
      "13.240426301956177\n",
      "current at batch: 78 tensor(6.2541, dtype=torch.float64)\n",
      "11.625232696533203\n",
      "current at batch: 79 tensor(6.0146, dtype=torch.float64)\n",
      "14.620102882385254\n",
      "current at batch: 80 tensor(5.9707, dtype=torch.float64)\n",
      "15.326879501342773\n",
      "current at batch: 81 tensor(6.0582, dtype=torch.float64)\n",
      "11.875237941741943\n",
      "current at batch: 82 tensor(6.1977, dtype=torch.float64)\n",
      "13.937781810760498\n",
      "current at batch: 83 tensor(5.7584, dtype=torch.float64)\n",
      "14.506145477294922\n",
      "current at batch: 84 tensor(5.9693, dtype=torch.float64)\n",
      "12.527326583862305\n",
      "current at batch: 85 tensor(5.8330, dtype=torch.float64)\n",
      "13.187778234481812\n",
      "current at batch: 86 tensor(6.0372, dtype=torch.float64)\n",
      "15.031554937362671\n",
      "current at batch: 87 tensor(5.8351, dtype=torch.float64)\n",
      "12.436041831970215\n",
      "current at batch: 88 tensor(6.1627, dtype=torch.float64)\n",
      "12.545328378677368\n",
      "current at batch: 89 tensor(6.3520, dtype=torch.float64)\n",
      "14.672181844711304\n",
      "current at batch: 90 tensor(5.6687, dtype=torch.float64)\n",
      "10.95688533782959\n",
      "current at batch: 91 tensor(5.9570, dtype=torch.float64)\n",
      "12.562756538391113\n",
      "current at batch: 92 tensor(6.2850, dtype=torch.float64)\n",
      "14.71904730796814\n",
      "current at batch: 93 tensor(6.2660, dtype=torch.float64)\n",
      "13.378328561782837\n",
      "current at batch: 94 tensor(6.3443, dtype=torch.float64)\n",
      "12.33330750465393\n",
      "current at batch: 95 tensor(6.1292, dtype=torch.float64)\n",
      "14.594144821166992\n",
      "current at batch: 96 tensor(6.3752, dtype=torch.float64)\n",
      "12.859714984893799\n",
      "current at batch: 97 tensor(5.5563, dtype=torch.float64)\n",
      "12.680112361907959\n",
      "current at batch: 98 tensor(6.2764, dtype=torch.float64)\n",
      "14.852193117141724\n",
      "current at batch: 99 tensor(5.8589, dtype=torch.float64)\n",
      "12.165332078933716\n",
      "current at batch: 100 tensor(6.2878, dtype=torch.float64)\n",
      "12.47746992111206\n",
      "current at batch: 101 tensor(6.3159, dtype=torch.float64)\n",
      "15.422297954559326\n",
      "current at batch: 102 tensor(6.4241, dtype=torch.float64)\n",
      "12.906599044799805\n",
      "current at batch: 103 tensor(5.5794, dtype=torch.float64)\n",
      "14.163798570632935\n",
      "current at batch: 104 tensor(5.6385, dtype=torch.float64)\n",
      "14.274307012557983\n",
      "current at batch: 105 tensor(6.2783, dtype=torch.float64)\n",
      "15.187905073165894\n",
      "current at batch: 106 tensor(5.4032, dtype=torch.float64)\n",
      "12.281579732894897\n",
      "current at batch: 107 tensor(5.9073, dtype=torch.float64)\n",
      "13.137657165527344\n",
      "current at batch: 108 tensor(6.5952, dtype=torch.float64)\n",
      "14.578513860702515\n",
      "current at batch: 109 tensor(5.7742, dtype=torch.float64)\n",
      "12.916031837463379\n",
      "current at batch: 110 tensor(6.4301, dtype=torch.float64)\n",
      "14.407696008682251\n",
      "current at batch: 111 tensor(5.8335, dtype=torch.float64)\n",
      "13.687870264053345\n",
      "current at batch: 112 tensor(6.2033, dtype=torch.float64)\n",
      "14.730274200439453\n",
      "current at batch: 113 tensor(5.8037, dtype=torch.float64)\n",
      "13.898754358291626\n",
      "current at batch: 114 tensor(6.0211, dtype=torch.float64)\n",
      "12.328453779220581\n",
      "current at batch: 115 tensor(6.1226, dtype=torch.float64)\n",
      "14.687838792800903\n",
      "current at batch: 116 tensor(5.3534, dtype=torch.float64)\n",
      "12.238601922988892\n",
      "current at batch: 117 tensor(6.1299, dtype=torch.float64)\n",
      "14.441324234008789\n",
      "current at batch: 118 tensor(5.8626, dtype=torch.float64)\n",
      "15.651776790618896\n",
      "current at batch: 119 tensor(6.4130, dtype=torch.float64)\n",
      "15.247853994369507\n",
      "current at batch: 120 tensor(5.8471, dtype=torch.float64)\n",
      "10.625216007232666\n",
      "current at batch: 121 tensor(5.8247, dtype=torch.float64)\n",
      "14.412144899368286\n",
      "current at batch: 122 tensor(5.8446, dtype=torch.float64)\n",
      "12.156510353088379\n",
      "current at batch: 123 tensor(6.5008, dtype=torch.float64)\n",
      "13.245341777801514\n",
      "current at batch: 124 tensor(6.0995, dtype=torch.float64)\n",
      "14.906555891036987\n",
      "current at batch: 125 tensor(6.4270, dtype=torch.float64)\n",
      "13.312768936157227\n",
      "current at batch: 126 tensor(6.3711, dtype=torch.float64)\n",
      "12.767312049865723\n",
      "current at batch: 127 tensor(5.9446, dtype=torch.float64)\n",
      "12.603867053985596\n",
      "current at batch: 128 tensor(5.6130, dtype=torch.float64)\n",
      "14.492223501205444\n",
      "current at batch: 129 tensor(6.7038, dtype=torch.float64)\n",
      "14.112780570983887\n",
      "current at batch: 130 tensor(6.3242, dtype=torch.float64)\n",
      "12.484627723693848\n",
      "current at batch: 131 tensor(6.1595, dtype=torch.float64)\n",
      "14.599940061569214\n",
      "current at batch: 132 tensor(6.0362, dtype=torch.float64)\n",
      "12.906523942947388\n",
      "current at batch: 133 tensor(5.6217, dtype=torch.float64)\n",
      "12.192756414413452\n",
      "current at batch: 134 tensor(5.0316, dtype=torch.float64)\n",
      "13.687788248062134\n",
      "current at batch: 135 tensor(6.1805, dtype=torch.float64)\n",
      "11.437729835510254\n",
      "current at batch: 136 tensor(5.8269, dtype=torch.float64)\n",
      "14.669123888015747\n",
      "current at batch: 137 tensor(6.0511, dtype=torch.float64)\n",
      "14.589668035507202\n",
      "current at batch: 138 tensor(6.4167, dtype=torch.float64)\n",
      "14.285041332244873\n",
      "current at batch: 139 tensor(5.9744, dtype=torch.float64)\n",
      "12.669967651367188\n",
      "current at batch: 140 tensor(6.3525, dtype=torch.float64)\n",
      "12.140872478485107\n",
      "current at batch: 141 tensor(6.1108, dtype=torch.float64)\n",
      "14.078147172927856\n",
      "current at batch: 142 tensor(6.0906, dtype=torch.float64)\n",
      "12.469001770019531\n",
      "current at batch: 143 tensor(5.8501, dtype=torch.float64)\n",
      "14.30983829498291\n",
      "current at batch: 144 tensor(6.2786, dtype=torch.float64)\n",
      "15.344061851501465\n",
      "current at batch: 145 tensor(5.9147, dtype=torch.float64)\n",
      "12.703385353088379\n",
      "current at batch: 146 tensor(5.9473, dtype=torch.float64)\n",
      "11.716022729873657\n",
      "current at batch: 147 tensor(5.4860, dtype=torch.float64)\n",
      "13.812778234481812\n",
      "current at batch: 148 tensor(5.7707, dtype=torch.float64)\n",
      "13.670101165771484\n",
      "current at batch: 149 tensor(5.4616, dtype=torch.float64)\n",
      "13.405562400817871\n",
      "current at batch: 150 tensor(5.9755, dtype=torch.float64)\n",
      "12.531510829925537\n",
      "current at batch: 151 tensor(5.9790, dtype=torch.float64)\n",
      "13.96988582611084\n",
      "current at batch: 152 tensor(5.6610, dtype=torch.float64)\n",
      "13.203397512435913\n",
      "current at batch: 153 tensor(5.4316, dtype=torch.float64)\n",
      "13.283373832702637\n",
      "current at batch: 154 tensor(6.2964, dtype=torch.float64)\n",
      "14.888561010360718\n",
      "current at batch: 155 tensor(6.2595, dtype=torch.float64)\n",
      "13.086772441864014\n",
      "current at batch: 156 tensor(6.2731, dtype=torch.float64)\n",
      "14.829723834991455\n",
      "current at batch: 157 tensor(6.3545, dtype=torch.float64)\n",
      "15.35968565940857\n",
      "current at batch: 158 tensor(6.0484, dtype=torch.float64)\n",
      "12.73012399673462\n",
      "current at batch: 159 tensor(5.6250, dtype=torch.float64)\n",
      "13.30464243888855\n",
      "current at batch: 160 tensor(6.0290, dtype=torch.float64)\n",
      "12.777024984359741\n",
      "current at batch: 161 tensor(6.5038, dtype=torch.float64)\n",
      "14.484666347503662\n",
      "current at batch: 162 tensor(5.5482, dtype=torch.float64)\n",
      "12.92214035987854\n",
      "current at batch: 163 tensor(6.0927, dtype=torch.float64)\n",
      "14.281938314437866\n",
      "current at batch: 164 tensor(6.1398, dtype=torch.float64)\n",
      "15.156563758850098\n",
      "current at batch: 165 tensor(6.0238, dtype=torch.float64)\n",
      "12.435306549072266\n",
      "current at batch: 166 tensor(6.0759, dtype=torch.float64)\n",
      "13.98302435874939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 167 tensor(5.5864, dtype=torch.float64)\n",
      "14.5784170627594\n",
      "current at batch: 168 tensor(6.0190, dtype=torch.float64)\n",
      "12.83628225326538\n",
      "current at batch: 169 tensor(5.9085, dtype=torch.float64)\n",
      "15.208360195159912\n",
      "current at batch: 170 tensor(5.8717, dtype=torch.float64)\n",
      "14.062788724899292\n",
      "current at batch: 171 tensor(5.6767, dtype=torch.float64)\n",
      "14.781561613082886\n",
      "current at batch: 172 tensor(6.1406, dtype=torch.float64)\n",
      "14.790571212768555\n",
      "current at batch: 173 tensor(5.2797, dtype=torch.float64)\n",
      "11.611958742141724\n",
      "current at batch: 174 tensor(6.0753, dtype=torch.float64)\n",
      "15.982859373092651\n",
      "current at batch: 175 tensor(6.1835, dtype=torch.float64)\n",
      "13.21177625656128\n",
      "current at batch: 176 tensor(5.8878, dtype=torch.float64)\n",
      "12.781509160995483\n",
      "current at batch: 177 tensor(5.3835, dtype=torch.float64)\n",
      "13.90653133392334\n",
      "current at batch: 178 tensor(5.9389, dtype=torch.float64)\n",
      "14.586883306503296\n",
      "current at batch: 179 tensor(5.9769, dtype=torch.float64)\n",
      "14.037584066390991\n",
      "current at batch: 180 tensor(6.0199, dtype=torch.float64)\n",
      "13.125309228897095\n",
      "current at batch: 181 tensor(5.9504, dtype=torch.float64)\n",
      "15.344167470932007\n",
      "current at batch: 182 tensor(5.8721, dtype=torch.float64)\n",
      "13.566499710083008\n",
      "current at batch: 183 tensor(6.0330, dtype=torch.float64)\n",
      "12.769339561462402\n",
      "current at batch: 184 tensor(5.9235, dtype=torch.float64)\n",
      "15.797288417816162\n",
      "current at batch: 185 tensor(6.1320, dtype=torch.float64)\n",
      "12.600794553756714\n",
      "current at batch: 186 tensor(5.6980, dtype=torch.float64)\n",
      "11.844062089920044\n",
      "current at batch: 187 tensor(6.4712, dtype=torch.float64)\n",
      "13.64099907875061\n",
      "current at batch: 188 tensor(5.9911, dtype=torch.float64)\n",
      "13.999787092208862\n",
      "current at batch: 189 tensor(5.9604, dtype=torch.float64)\n",
      "13.297237873077393\n",
      "current at batch: 190 tensor(5.8232, dtype=torch.float64)\n",
      "13.234730243682861\n",
      "current at batch: 191 tensor(6.4587, dtype=torch.float64)\n",
      "15.625415086746216\n",
      "current at batch: 192 tensor(6.1481, dtype=torch.float64)\n",
      "13.5163414478302\n",
      "current at batch: 193 tensor(6.0949, dtype=torch.float64)\n",
      "12.331073760986328\n",
      "current at batch: 194 tensor(5.6799, dtype=torch.float64)\n",
      "13.656622648239136\n",
      "current at batch: 195 tensor(6.3460, dtype=torch.float64)\n",
      "13.901161432266235\n",
      "current at batch: 196 tensor(6.0849, dtype=torch.float64)\n",
      "13.437860250473022\n",
      "current at batch: 197 tensor(5.4208, dtype=torch.float64)\n",
      "12.250333786010742\n",
      "current at batch: 198 tensor(6.3830, dtype=torch.float64)\n",
      "14.718717098236084\n",
      "current at batch: 199 tensor(6.2028, dtype=torch.float64)\n",
      "13.967347621917725\n",
      "current at batch: 200 tensor(5.3275, dtype=torch.float64)\n",
      "11.545287370681763\n",
      "current at batch: 201 tensor(6.1202, dtype=torch.float64)\n",
      "15.047273397445679\n",
      "current at batch: 202 tensor(6.1008, dtype=torch.float64)\n",
      "15.008357524871826\n",
      "current at batch: 203 tensor(5.8099, dtype=torch.float64)\n",
      "13.265892744064331\n",
      "current at batch: 204 tensor(5.1301, dtype=torch.float64)\n",
      "15.547188997268677\n",
      "current at batch: 205 tensor(6.2007, dtype=torch.float64)\n",
      "14.979084968566895\n",
      "current at batch: 206 tensor(6.1241, dtype=torch.float64)\n",
      "12.906511545181274\n",
      "current at batch: 207 tensor(5.6371, dtype=torch.float64)\n",
      "12.307819366455078\n",
      "current at batch: 208 tensor(6.3071, dtype=torch.float64)\n",
      "14.417960405349731\n",
      "current at batch: 209 tensor(5.9036, dtype=torch.float64)\n",
      "14.250290393829346\n",
      "current at batch: 210 tensor(5.7797, dtype=torch.float64)\n",
      "12.562760591506958\n",
      "current at batch: 211 tensor(6.0399, dtype=torch.float64)\n",
      "15.566417217254639\n",
      "current at batch: 212 tensor(6.0328, dtype=torch.float64)\n",
      "15.457424402236938\n",
      "current at batch: 213 tensor(6.1164, dtype=torch.float64)\n",
      "12.828385353088379\n",
      "current at batch: 214 tensor(5.6839, dtype=torch.float64)\n",
      "13.448227405548096\n",
      "current at batch: 215 tensor(5.9670, dtype=torch.float64)\n",
      "13.172142028808594\n",
      "current at batch: 216 tensor(5.8534, dtype=torch.float64)\n",
      "12.750256538391113\n",
      "current at batch: 217 tensor(6.1614, dtype=torch.float64)\n",
      "12.663074731826782\n",
      "current at batch: 218 tensor(5.7316, dtype=torch.float64)\n",
      "14.411407709121704\n",
      "current at batch: 219 tensor(5.8062, dtype=torch.float64)\n",
      "13.6409010887146\n",
      "current at batch: 220 tensor(5.8070, dtype=torch.float64)\n",
      "13.140890121459961\n",
      "current at batch: 221 tensor(6.5577, dtype=torch.float64)\n",
      "16.174960136413574\n",
      "current at batch: 222 tensor(5.8405, dtype=torch.float64)\n",
      "14.195467710494995\n",
      "current at batch: 223 tensor(5.9538, dtype=torch.float64)\n",
      "12.390883922576904\n",
      "current at batch: 224 tensor(6.2822, dtype=torch.float64)\n",
      "15.670696020126343\n",
      "current at batch: 225 tensor(6.5584, dtype=torch.float64)\n",
      "14.40982437133789\n",
      "current at batch: 226 tensor(5.7397, dtype=torch.float64)\n",
      "13.15479302406311\n",
      "current at batch: 227 tensor(5.5010, dtype=torch.float64)\n",
      "13.389135360717773\n",
      "current at batch: 228 tensor(6.4607, dtype=torch.float64)\n",
      "13.854162454605103\n",
      "current at batch: 229 tensor(5.9602, dtype=torch.float64)\n",
      "14.31278944015503\n",
      "current at batch: 230 tensor(6.0544, dtype=torch.float64)\n",
      "12.922141075134277\n",
      "current at batch: 231 tensor(6.0692, dtype=torch.float64)\n",
      "15.830700635910034\n",
      "current at batch: 232 tensor(5.7179, dtype=torch.float64)\n",
      "13.687780380249023\n",
      "current at batch: 233 tensor(5.8731, dtype=torch.float64)\n",
      "12.953387022018433\n",
      "current at batch: 234 tensor(5.5817, dtype=torch.float64)\n",
      "13.297821283340454\n",
      "current at batch: 235 tensor(6.3199, dtype=torch.float64)\n",
      "14.531554222106934\n",
      "current at batch: 236 tensor(6.0797, dtype=torch.float64)\n",
      "15.322866439819336\n",
      "current at batch: 237 tensor(6.3400, dtype=torch.float64)\n",
      "13.200891256332397\n",
      "current at batch: 238 tensor(6.0281, dtype=torch.float64)\n",
      "15.297183990478516\n",
      "current at batch: 239 tensor(5.8416, dtype=torch.float64)\n",
      "16.547221660614014\n",
      "current at batch: 240 tensor(5.2208, dtype=torch.float64)\n",
      "12.294400453567505\n",
      "current at batch: 241 tensor(5.6976, dtype=torch.float64)\n",
      "13.311626434326172\n",
      "current at batch: 242 tensor(6.1192, dtype=torch.float64)\n",
      "14.547171592712402\n",
      "current at batch: 243 tensor(6.2068, dtype=torch.float64)\n",
      "12.422124147415161\n",
      "current at batch: 244 tensor(5.8625, dtype=torch.float64)\n",
      "14.471596956253052\n",
      "current at batch: 245 tensor(5.3090, dtype=torch.float64)\n",
      "13.436288595199585\n",
      "current at batch: 246 tensor(5.9456, dtype=torch.float64)\n",
      "14.992597579956055\n",
      "current at batch: 247 tensor(6.3543, dtype=torch.float64)\n",
      "13.203566312789917\n",
      "current at batch: 248 tensor(5.2195, dtype=torch.float64)\n",
      "12.281577110290527\n",
      "current at batch: 249 tensor(5.9912, dtype=torch.float64)\n",
      "13.836668729782104\n",
      "current at batch: 250 tensor(6.2991, dtype=torch.float64)\n",
      "13.331909656524658\n",
      "current at batch: 251 tensor(5.8062, dtype=torch.float64)\n",
      "12.700595378875732\n",
      "current at batch: 252 tensor(5.9575, dtype=torch.float64)\n",
      "14.01600170135498\n",
      "current at batch: 253 tensor(5.8566, dtype=torch.float64)\n",
      "13.969129800796509\n",
      "current at batch: 254 tensor(5.5073, dtype=torch.float64)\n",
      "11.575220584869385\n",
      "current at batch: 255 tensor(6.1716, dtype=torch.float64)\n",
      "14.094127893447876\n",
      "current at batch: 256 tensor(5.7424, dtype=torch.float64)\n",
      "11.398160219192505\n",
      "current at batch: 257 tensor(5.6627, dtype=torch.float64)\n",
      "13.179913520812988\n",
      "current at batch: 258 tensor(5.3345, dtype=torch.float64)\n",
      "12.40658164024353\n",
      "current at batch: 259 tensor(6.0975, dtype=torch.float64)\n",
      "13.109726667404175\n",
      "current at batch: 260 tensor(6.0647, dtype=torch.float64)\n",
      "11.997584104537964\n",
      "current at batch: 261 tensor(5.9145, dtype=torch.float64)\n",
      "12.957831144332886\n",
      "current at batch: 262 tensor(6.0179, dtype=torch.float64)\n",
      "11.978650569915771\n",
      "current at batch: 263 tensor(6.1980, dtype=torch.float64)\n",
      "14.125373601913452\n",
      "current at batch: 264 tensor(6.2903, dtype=torch.float64)\n",
      "13.20557713508606\n",
      "current at batch: 265 tensor(5.6739, dtype=torch.float64)\n",
      "11.125300168991089\n",
      "current at batch: 266 tensor(6.0609, dtype=torch.float64)\n",
      "14.172252655029297\n",
      "current at batch: 267 tensor(6.5425, dtype=torch.float64)\n",
      "12.577428340911865\n",
      "current at batch: 268 tensor(6.0084, dtype=torch.float64)\n",
      "13.565237045288086\n",
      "current at batch: 269 tensor(6.2373, dtype=torch.float64)\n",
      "12.25024127960205\n",
      "current at batch: 270 tensor(5.5107, dtype=torch.float64)\n",
      "11.64085054397583\n",
      "current at batch: 271 tensor(5.9001, dtype=torch.float64)\n",
      "12.140870809555054\n",
      "current at batch: 272 tensor(5.9004, dtype=torch.float64)\n",
      "14.528711557388306\n",
      "current at batch: 273 tensor(6.1803, dtype=torch.float64)\n",
      "12.328371524810791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 274 tensor(5.6349, dtype=torch.float64)\n",
      "12.672135591506958\n",
      "current at batch: 275 tensor(5.4272, dtype=torch.float64)\n",
      "12.736984729766846\n",
      "current at batch: 276 tensor(6.4185, dtype=torch.float64)\n",
      "12.062743186950684\n",
      "current at batch: 277 tensor(6.3388, dtype=torch.float64)\n",
      "12.828396320343018\n",
      "current at batch: 278 tensor(5.2459, dtype=torch.float64)\n",
      "12.890886306762695\n",
      "current at batch: 279 tensor(6.0065, dtype=torch.float64)\n",
      "12.533992767333984\n",
      "current at batch: 280 tensor(5.8470, dtype=torch.float64)\n",
      "12.741823196411133\n",
      "current at batch: 281 tensor(5.9471, dtype=torch.float64)\n",
      "14.328423976898193\n",
      "current at batch: 282 tensor(5.7751, dtype=torch.float64)\n",
      "12.464510202407837\n",
      "current at batch: 283 tensor(5.8447, dtype=torch.float64)\n",
      "14.6631178855896\n",
      "current at batch: 284 tensor(6.1396, dtype=torch.float64)\n",
      "14.76591682434082\n",
      "current at batch: 285 tensor(5.9679, dtype=torch.float64)\n",
      "13.500474691390991\n",
      "current at batch: 286 tensor(5.6215, dtype=torch.float64)\n",
      "12.984636545181274\n",
      "current at batch: 287 tensor(5.4428, dtype=torch.float64)\n",
      "12.672134637832642\n",
      "current at batch: 288 tensor(6.1357, dtype=torch.float64)\n",
      "12.135300397872925\n",
      "current at batch: 289 tensor(5.6296, dtype=torch.float64)\n",
      "11.688563585281372\n",
      "current at batch: 290 tensor(6.3352, dtype=torch.float64)\n",
      "15.015934705734253\n",
      "current at batch: 291 tensor(6.2408, dtype=torch.float64)\n",
      "11.98461627960205\n",
      "current at batch: 292 tensor(5.3983, dtype=torch.float64)\n",
      "12.672130107879639\n",
      "current at batch: 293 tensor(6.3034, dtype=torch.float64)\n",
      "12.835567474365234\n",
      "current at batch: 294 tensor(6.3079, dtype=torch.float64)\n",
      "12.15304160118103\n",
      "current at batch: 295 tensor(6.0757, dtype=torch.float64)\n",
      "14.229959964752197\n",
      "current at batch: 296 tensor(6.1709, dtype=torch.float64)\n",
      "15.41352891921997\n",
      "current at batch: 297 tensor(5.9514, dtype=torch.float64)\n",
      "12.687764644622803\n",
      "current at batch: 298 tensor(5.5598, dtype=torch.float64)\n",
      "12.727969884872437\n",
      "current at batch: 299 tensor(5.6885, dtype=torch.float64)\n",
      "15.109532117843628\n",
      "current at batch: 300 tensor(6.0565, dtype=torch.float64)\n",
      "12.936107397079468\n",
      "current at batch: 301 tensor(5.4923, dtype=torch.float64)\n",
      "13.297139406204224\n",
      "current at batch: 302 tensor(6.0175, dtype=torch.float64)\n",
      "13.312767744064331\n",
      "current at batch: 303 tensor(6.6771, dtype=torch.float64)\n",
      "13.423429727554321\n",
      "current at batch: 304 tensor(6.4465, dtype=torch.float64)\n",
      "13.469033002853394\n",
      "current at batch: 305 tensor(5.8976, dtype=torch.float64)\n",
      "13.105711460113525\n",
      "current at batch: 306 tensor(6.2815, dtype=torch.float64)\n",
      "13.708075284957886\n",
      "current at batch: 307 tensor(6.4947, dtype=torch.float64)\n",
      "11.718985319137573\n",
      "current at batch: 308 tensor(6.2079, dtype=torch.float64)\n",
      "14.414584636688232\n",
      "current at batch: 309 tensor(5.7138, dtype=torch.float64)\n",
      "13.358479022979736\n",
      "current at batch: 310 tensor(5.4782, dtype=torch.float64)\n",
      "14.280408143997192\n",
      "current at batch: 311 tensor(6.1870, dtype=torch.float64)\n",
      "11.500236749649048\n",
      "current at batch: 312 tensor(6.5639, dtype=torch.float64)\n",
      "14.206691265106201\n",
      "current at batch: 313 tensor(6.2077, dtype=torch.float64)\n",
      "11.798766136169434\n",
      "current at batch: 314 tensor(6.1990, dtype=torch.float64)\n",
      "13.26590347290039\n",
      "current at batch: 315 tensor(6.3154, dtype=torch.float64)\n",
      "14.77204155921936\n",
      "current at batch: 316 tensor(5.8426, dtype=torch.float64)\n",
      "12.236048460006714\n",
      "current at batch: 317 tensor(6.1455, dtype=torch.float64)\n",
      "12.828383922576904\n",
      "current at batch: 318 tensor(5.6840, dtype=torch.float64)\n",
      "12.182442903518677\n",
      "current at batch: 319 tensor(6.1113, dtype=torch.float64)\n",
      "12.187768459320068\n",
      "current at batch: 320 tensor(6.1047, dtype=torch.float64)\n",
      "12.603048324584961\n",
      "current at batch: 321 tensor(6.6762, dtype=torch.float64)\n",
      "14.812814712524414\n",
      "current at batch: 322 tensor(5.7264, dtype=torch.float64)\n",
      "10.984597444534302\n",
      "current at batch: 323 tensor(6.0717, dtype=torch.float64)\n",
      "14.140917778015137\n",
      "current at batch: 324 tensor(6.4062, dtype=torch.float64)\n",
      "14.587152481079102\n",
      "current at batch: 325 tensor(5.6296, dtype=torch.float64)\n",
      "11.406491756439209\n",
      "current at batch: 326 tensor(6.3377, dtype=torch.float64)\n",
      "13.281524658203125\n",
      "current at batch: 327 tensor(5.6759, dtype=torch.float64)\n",
      "13.152640104293823\n",
      "current at batch: 328 tensor(5.6770, dtype=torch.float64)\n",
      "12.922136068344116\n",
      "current at batch: 329 tensor(5.8198, dtype=torch.float64)\n",
      "13.28003454208374\n",
      "current at batch: 330 tensor(6.0065, dtype=torch.float64)\n",
      "13.848355054855347\n",
      "current at batch: 331 tensor(6.2437, dtype=torch.float64)\n",
      "12.026617050170898\n",
      "current at batch: 332 tensor(5.9036, dtype=torch.float64)\n",
      "15.020273447036743\n",
      "current at batch: 333 tensor(5.8393, dtype=torch.float64)\n",
      "12.328377485275269\n",
      "current at batch: 334 tensor(5.4208, dtype=torch.float64)\n",
      "12.835703372955322\n",
      "current at batch: 335 tensor(6.0654, dtype=torch.float64)\n",
      "14.216006517410278\n",
      "current at batch: 336 tensor(6.2926, dtype=torch.float64)\n",
      "13.469107151031494\n",
      "current at batch: 337 tensor(5.8461, dtype=torch.float64)\n",
      "11.589976787567139\n",
      "current at batch: 338 tensor(6.1234, dtype=torch.float64)\n",
      "12.65658974647522\n",
      "current at batch: 339 tensor(5.6625, dtype=torch.float64)\n",
      "13.672239542007446\n",
      "current at batch: 340 tensor(5.7979, dtype=torch.float64)\n",
      "11.521576881408691\n",
      "current at batch: 341 tensor(6.2378, dtype=torch.float64)\n",
      "14.384702205657959\n",
      "current at batch: 342 tensor(5.6780, dtype=torch.float64)\n",
      "11.422173261642456\n",
      "current at batch: 343 tensor(6.2568, dtype=torch.float64)\n",
      "14.047256469726562\n",
      "current at batch: 344 tensor(6.0560, dtype=torch.float64)\n",
      "14.09890103340149\n",
      "current at batch: 345 tensor(6.5662, dtype=torch.float64)\n",
      "15.016025066375732\n",
      "current at batch: 346 tensor(5.6149, dtype=torch.float64)\n",
      "11.469059228897095\n",
      "current at batch: 347 tensor(5.8781, dtype=torch.float64)\n",
      "14.531640529632568\n",
      "current at batch: 348 tensor(5.9471, dtype=torch.float64)\n",
      "13.57473087310791\n",
      "current at batch: 349 tensor(5.5920, dtype=torch.float64)\n",
      "12.54578685760498\n",
      "current at batch: 350 tensor(5.5351, dtype=torch.float64)\n",
      "13.328484296798706\n",
      "current at batch: 351 tensor(5.9691, dtype=torch.float64)\n",
      "13.065926313400269\n",
      "current at batch: 352 tensor(5.5847, dtype=torch.float64)\n",
      "12.500324010848999\n",
      "current at batch: 353 tensor(6.2215, dtype=torch.float64)\n",
      "13.797240018844604\n",
      "current at batch: 354 tensor(6.1512, dtype=torch.float64)\n",
      "14.613909721374512\n",
      "current at batch: 355 tensor(6.0241, dtype=torch.float64)\n",
      "11.53345799446106\n",
      "current at batch: 356 tensor(5.7048, dtype=torch.float64)\n",
      "14.250375986099243\n",
      "current at batch: 357 tensor(5.7864, dtype=torch.float64)\n",
      "13.062791109085083\n",
      "current at batch: 358 tensor(6.0623, dtype=torch.float64)\n",
      "13.275335788726807\n",
      "current at batch: 359 tensor(5.8929, dtype=torch.float64)\n",
      "12.8283851146698\n",
      "current at batch: 360 tensor(5.7003, dtype=torch.float64)\n",
      "13.586900472640991\n",
      "current at batch: 361 tensor(5.7718, dtype=torch.float64)\n",
      "13.547150373458862\n",
      "current at batch: 362 tensor(6.4024, dtype=torch.float64)\n",
      "14.630626201629639\n",
      "current at batch: 363 tensor(6.0961, dtype=torch.float64)\n",
      "14.094036102294922\n",
      "current at batch: 364 tensor(6.7174, dtype=torch.float64)\n",
      "12.206466436386108\n",
      "current at batch: 365 tensor(7.0649, dtype=torch.float64)\n",
      "15.140315055847168\n",
      "current at batch: 366 tensor(5.9423, dtype=torch.float64)\n",
      "13.375270366668701\n",
      "current at batch: 367 tensor(5.7537, dtype=torch.float64)\n",
      "15.187813997268677\n",
      "current at batch: 368 tensor(6.1228, dtype=torch.float64)\n",
      "11.757102727890015\n",
      "current at batch: 369 tensor(6.1543, dtype=torch.float64)\n",
      "14.656548023223877\n",
      "current at batch: 370 tensor(5.3485, dtype=torch.float64)\n",
      "12.565455675125122\n",
      "current at batch: 371 tensor(6.0856, dtype=torch.float64)\n",
      "13.734646797180176\n",
      "current at batch: 372 tensor(6.0203, dtype=torch.float64)\n",
      "14.603473901748657\n",
      "current at batch: 373 tensor(6.6836, dtype=torch.float64)\n",
      "14.281538248062134\n",
      "current at batch: 374 tensor(5.9909, dtype=torch.float64)\n",
      "12.71346402168274\n",
      "current at batch: 375 tensor(6.0854, dtype=torch.float64)\n",
      "12.817518472671509\n",
      "current at batch: 376 tensor(6.0151, dtype=torch.float64)\n",
      "15.015930414199829\n",
      "current at batch: 377 tensor(5.5319, dtype=torch.float64)\n",
      "11.547107696533203\n",
      "current at batch: 378 tensor(6.0150, dtype=torch.float64)\n",
      "13.297152042388916\n",
      "current at batch: 379 tensor(5.1481, dtype=torch.float64)\n",
      "11.84345006942749\n",
      "current at batch: 380 tensor(5.8502, dtype=torch.float64)\n",
      "12.70823621749878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 381 tensor(6.1700, dtype=torch.float64)\n",
      "12.312750101089478\n",
      "current at batch: 382 tensor(5.9395, dtype=torch.float64)\n",
      "15.103827953338623\n",
      "current at batch: 383 tensor(5.7587, dtype=torch.float64)\n",
      "13.125266551971436\n",
      "current at batch: 384 tensor(5.9659, dtype=torch.float64)\n",
      "12.660419464111328\n",
      "current at batch: 385 tensor(6.1631, dtype=torch.float64)\n",
      "14.499216079711914\n",
      "current at batch: 386 tensor(5.6903, dtype=torch.float64)\n",
      "12.057693243026733\n",
      "current at batch: 387 tensor(5.5181, dtype=torch.float64)\n",
      "12.56275200843811\n",
      "current at batch: 388 tensor(5.9387, dtype=torch.float64)\n",
      "12.890887022018433\n",
      "current at batch: 389 tensor(5.5932, dtype=torch.float64)\n",
      "12.220235586166382\n",
      "current at batch: 390 tensor(6.5107, dtype=torch.float64)\n",
      "12.715786457061768\n",
      "current at batch: 391 tensor(5.1773, dtype=torch.float64)\n",
      "14.094038486480713\n",
      "current at batch: 392 tensor(5.9222, dtype=torch.float64)\n",
      "11.625239372253418\n",
      "current at batch: 393 tensor(6.0191, dtype=torch.float64)\n",
      "15.197709083557129\n",
      "current at batch: 394 tensor(5.4121, dtype=torch.float64)\n",
      "11.842764139175415\n",
      "current at batch: 395 tensor(6.1142, dtype=torch.float64)\n",
      "12.952574729919434\n",
      "current at batch: 396 tensor(5.8518, dtype=torch.float64)\n",
      "12.206241130828857\n",
      "current at batch: 397 tensor(6.1788, dtype=torch.float64)\n",
      "15.71908187866211\n",
      "current at batch: 398 tensor(5.6537, dtype=torch.float64)\n",
      "12.500254154205322\n",
      "current at batch: 399 tensor(6.3075, dtype=torch.float64)\n",
      "15.112434148788452\n",
      "current at batch: 400 tensor(5.8951, dtype=torch.float64)\n",
      "16.691823482513428\n",
      "current at batch: 401 tensor(6.4232, dtype=torch.float64)\n",
      "14.541197061538696\n",
      "current at batch: 402 tensor(5.9169, dtype=torch.float64)\n",
      "13.86703109741211\n",
      "current at batch: 403 tensor(6.3190, dtype=torch.float64)\n",
      "15.322798252105713\n",
      "current at batch: 404 tensor(5.7579, dtype=torch.float64)\n",
      "17.272918939590454\n",
      "current at batch: 405 tensor(5.6698, dtype=torch.float64)\n",
      "13.552911520004272\n",
      "current at batch: 406 tensor(6.1152, dtype=torch.float64)\n",
      "13.901474237442017\n",
      "current at batch: 407 tensor(6.1157, dtype=torch.float64)\n",
      "13.369948387145996\n",
      "current at batch: 408 tensor(6.0223, dtype=torch.float64)\n",
      "13.542026996612549\n",
      "current at batch: 409 tensor(6.1021, dtype=torch.float64)\n",
      "13.24234127998352\n",
      "current at batch: 410 tensor(6.2057, dtype=torch.float64)\n",
      "15.854528188705444\n",
      "current at batch: 411 tensor(6.5289, dtype=torch.float64)\n",
      "15.192700624465942\n",
      "current at batch: 412 tensor(5.7009, dtype=torch.float64)\n",
      "13.64436650276184\n",
      "current at batch: 413 tensor(5.8102, dtype=torch.float64)\n",
      "16.342320919036865\n",
      "current at batch: 414 tensor(5.5551, dtype=torch.float64)\n",
      "11.27537751197815\n",
      "current at batch: 415 tensor(6.0715, dtype=torch.float64)\n",
      "8.84490966796875\n",
      "current at batch: 416 tensor(5.9524, dtype=torch.float64)\n",
      "9.105233430862427\n",
      "current at batch: 417 tensor(6.5155, dtype=torch.float64)\n",
      "11.284416675567627\n",
      "current at batch: 418 tensor(5.7611, dtype=torch.float64)\n",
      "11.081454753875732\n",
      "current at batch: 419 tensor(5.6666, dtype=torch.float64)\n",
      "9.937707662582397\n",
      "current at batch: 420 tensor(6.2777, dtype=torch.float64)\n",
      "9.372819662094116\n",
      "current at batch: 421 tensor(5.7163, dtype=torch.float64)\n",
      "10.811372756958008\n",
      "current at batch: 422 tensor(5.4598, dtype=torch.float64)\n",
      "11.184308052062988\n",
      "current at batch: 423 tensor(6.0434, dtype=torch.float64)\n",
      "8.656420946121216\n",
      "current at batch: 424 tensor(6.1812, dtype=torch.float64)\n",
      "10.050799369812012\n",
      "current at batch: 425 tensor(6.2010, dtype=torch.float64)\n",
      "11.685307264328003\n",
      "current at batch: 426 tensor(6.0016, dtype=torch.float64)\n",
      "7.861646890640259\n",
      "current at batch: 427 tensor(6.5643, dtype=torch.float64)\n",
      "8.436282634735107\n",
      "current at batch: 428 tensor(6.1218, dtype=torch.float64)\n",
      "10.77181077003479\n",
      "current at batch: 429 tensor(5.6640, dtype=torch.float64)\n",
      "10.437777996063232\n",
      "current at batch: 430 tensor(6.4301, dtype=torch.float64)\n",
      "10.021212577819824\n",
      "current at batch: 431 tensor(6.7243, dtype=torch.float64)\n",
      "11.247061967849731\n",
      "current at batch: 432 tensor(6.3914, dtype=torch.float64)\n",
      "11.211480855941772\n",
      "current at batch: 433 tensor(5.6760, dtype=torch.float64)\n",
      "9.156506061553955\n",
      "current at batch: 434 tensor(6.0369, dtype=torch.float64)\n",
      "10.15972352027893\n",
      "current at batch: 435 tensor(5.8539, dtype=torch.float64)\n",
      "11.038934469223022\n",
      "current at batch: 436 tensor(6.3080, dtype=torch.float64)\n",
      "10.734661102294922\n",
      "current at batch: 437 tensor(6.1572, dtype=torch.float64)\n",
      "10.280914545059204\n",
      "current at batch: 438 tensor(6.5261, dtype=torch.float64)\n",
      "10.532938718795776\n",
      "current at batch: 439 tensor(6.0448, dtype=torch.float64)\n",
      "11.332881450653076\n",
      "current at batch: 440 tensor(6.0922, dtype=torch.float64)\n",
      "10.469037532806396\n",
      "current at batch: 441 tensor(6.2810, dtype=torch.float64)\n",
      "9.535295009613037\n",
      "current at batch: 442 tensor(6.0571, dtype=torch.float64)\n",
      "10.749582529067993\n",
      "current at batch: 443 tensor(6.0708, dtype=torch.float64)\n",
      "12.148400068283081\n",
      "current at batch: 444 tensor(5.9987, dtype=torch.float64)\n",
      "10.359652042388916\n",
      "current at batch: 445 tensor(5.6446, dtype=torch.float64)\n",
      "10.273723602294922\n",
      "current at batch: 446 tensor(5.6220, dtype=torch.float64)\n",
      "10.904390335083008\n",
      "current at batch: 447 tensor(5.8384, dtype=torch.float64)\n",
      "10.629133462905884\n",
      "current at batch: 448 tensor(5.8543, dtype=torch.float64)\n",
      "7.639436960220337\n",
      "current at batch: 449 tensor(5.6243, dtype=torch.float64)\n",
      "8.284322261810303\n",
      "current at batch: 450 tensor(5.7542, dtype=torch.float64)\n",
      "8.081473112106323\n",
      "current at batch: 451 tensor(5.8594, dtype=torch.float64)\n",
      "8.075281143188477\n",
      "current at batch: 452 tensor(5.6694, dtype=torch.float64)\n",
      "7.837983131408691\n",
      "current at batch: 453 tensor(6.0419, dtype=torch.float64)\n",
      "7.165019750595093\n",
      "current at batch: 454 tensor(6.0810, dtype=torch.float64)\n",
      "8.437740325927734\n",
      "current at batch: 455 tensor(5.7861, dtype=torch.float64)\n",
      "10.69434404373169\n",
      "current at batch: 456 tensor(6.4794, dtype=torch.float64)\n",
      "7.5001513957977295\n",
      "current at batch: 457 tensor(5.3945, dtype=torch.float64)\n",
      "6.922015905380249\n",
      "current at batch: 458 tensor(5.7499, dtype=torch.float64)\n",
      "7.750155925750732\n",
      "current at batch: 459 tensor(5.4584, dtype=torch.float64)\n",
      "7.569329261779785\n",
      "current at batch: 460 tensor(5.9316, dtype=torch.float64)\n",
      "6.843890428543091\n",
      "current at batch: 461 tensor(5.7511, dtype=torch.float64)\n",
      "6.687649250030518\n",
      "current at batch: 462 tensor(5.7746, dtype=torch.float64)\n",
      "7.187649965286255\n",
      "current at batch: 463 tensor(6.3169, dtype=torch.float64)\n",
      "7.949901342391968\n",
      "current at batch: 464 tensor(6.0297, dtype=torch.float64)\n",
      "6.828263282775879\n",
      "current at batch: 465 tensor(5.9946, dtype=torch.float64)\n",
      "7.193031311035156\n",
      "current at batch: 466 tensor(6.0349, dtype=torch.float64)\n",
      "7.46890115737915\n",
      "current at batch: 467 tensor(5.9810, dtype=torch.float64)\n",
      "7.203270196914673\n",
      "current at batch: 468 tensor(5.9293, dtype=torch.float64)\n",
      "7.495232820510864\n",
      "current at batch: 469 tensor(5.4465, dtype=torch.float64)\n",
      "7.265772581100464\n",
      "current at batch: 470 tensor(6.5987, dtype=torch.float64)\n",
      "7.828286170959473\n",
      "current at batch: 471 tensor(5.9663, dtype=torch.float64)\n",
      "7.378970146179199\n",
      "current at batch: 472 tensor(5.2821, dtype=torch.float64)\n",
      "1.3125243186950684\n",
      "epoch =  4 \n",
      " tensor(2822.1177, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Training process!\n",
    "import time\n",
    "# setting training parameters\n",
    "batchsize = 40\n",
    "epoch = 5\n",
    "lr = 5000\n",
    "lr_nmf = 5000\n",
    "lr_cl = 5000\n",
    "loss_lst = []\n",
    "# train!\n",
    "for epo in range(epoch):\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size = batchsize, shuffle = True)\n",
    "    total_loss = 0\n",
    "    for (i, (inputs, label)) in enumerate(dataloader):\n",
    "        t1 = time.time()\n",
    "        inputs = inputs.view([inputs.shape[0], inputs.shape[2]])\n",
    "        label = label.view([label.shape[0], -1])\n",
    "        inputs, label = Variable(inputs), Variable(label)\n",
    "       #train the lsqnonneg layers\n",
    "        net.zero_grad()\n",
    "        S_lst = net(inputs)\n",
    "        S = S_lst[-1]\n",
    "        B = pinv(S)\n",
    "        B = torch.mm(pinv(S),label)\n",
    "        pred = torch.mm(S,B)\n",
    "        loss = loss_func(inputs, S_lst,list(net.lsqnonneglst.parameters()),pred,label)\n",
    "        loss.backward()\n",
    "        loss_lst.append(loss.data)\n",
    "        total_loss += loss.data\n",
    "        print('current at batch:', i+1, loss.data)\n",
    "        t2 = time.time()\n",
    "        print(t2 - t1)\n",
    "        for A in net.parameters():\n",
    "            A.data = A.data.sub_(lr*A.grad.data)\n",
    "        for A in net.lsqnonneglst.parameters():\n",
    "            A.data = A.data.clamp(min = 0)\n",
    "    print('epoch = ', epo, '\\n', total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "np.savez(save_PATH + save_filename,\n",
    "         param_lst = list(net.parameters()), loss_lst = loss_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss curve\n",
    "# plt.plot(loss_lst)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current at batch: 100\n",
      "current at batch: 200\n",
      "current at batch: 300\n",
      "current at batch: 400\n",
      "current at batch: 500\n",
      "current at batch: 600\n",
      "current at batch: 700\n",
      "current at batch: 800\n",
      "current at batch: 900\n",
      "current at batch: 1000\n",
      "current at batch: 1100\n",
      "current at batch: 1200\n",
      "current at batch: 1300\n",
      "current at batch: 1400\n",
      "current at batch: 1500\n",
      "current at batch: 1600\n",
      "current at batch: 1700\n",
      "current at batch: 1800\n",
      "current at batch: 1900\n",
      "current at batch: 2000\n",
      "current at batch: 2100\n",
      "current at batch: 2200\n",
      "current at batch: 2300\n",
      "current at batch: 2400\n",
      "current at batch: 2500\n",
      "current at batch: 2600\n",
      "current at batch: 2700\n",
      "current at batch: 2800\n",
      "current at batch: 2900\n",
      "current at batch: 3000\n",
      "current at batch: 3100\n",
      "current at batch: 3200\n",
      "current at batch: 3300\n",
      "current at batch: 3400\n",
      "current at batch: 3500\n",
      "current at batch: 3600\n",
      "current at batch: 3700\n",
      "current at batch: 3800\n",
      "current at batch: 3900\n",
      "current at batch: 4000\n",
      "current at batch: 4100\n",
      "current at batch: 4200\n",
      "current at batch: 4300\n",
      "current at batch: 4400\n",
      "current at batch: 4500\n",
      "current at batch: 4600\n",
      "current at batch: 4700\n",
      "current at batch: 4800\n",
      "current at batch: 4900\n",
      "current at batch: 5000\n",
      "current at batch: 5100\n",
      "current at batch: 5200\n",
      "current at batch: 5300\n",
      "current at batch: 5400\n",
      "current at batch: 5500\n",
      "current at batch: 5600\n",
      "current at batch: 5700\n",
      "current at batch: 5800\n",
      "current at batch: 5900\n",
      "current at batch: 6000\n",
      "current at batch: 6100\n",
      "current at batch: 6200\n",
      "current at batch: 6300\n",
      "current at batch: 6400\n",
      "current at batch: 6500\n",
      "current at batch: 6600\n",
      "current at batch: 6700\n",
      "current at batch: 6800\n",
      "current at batch: 6900\n",
      "current at batch: 7000\n",
      "current at batch: 7100\n",
      "current at batch: 7200\n",
      "current at batch: 7300\n",
      "current at batch: 7400\n",
      "current at batch: 7500\n",
      "current at batch: 7600\n",
      "current at batch: 7700\n",
      "current at batch: 7800\n",
      "current at batch: 7900\n",
      "current at batch: 8000\n",
      "current at batch: 8100\n",
      "current at batch: 8200\n",
      "current at batch: 8300\n",
      "current at batch: 8400\n",
      "current at batch: 8500\n",
      "current at batch: 8600\n",
      "current at batch: 8700\n",
      "current at batch: 8800\n",
      "current at batch: 8900\n",
      "current at batch: 9000\n",
      "current at batch: 9100\n",
      "current at batch: 9200\n",
      "current at batch: 9300\n",
      "current at batch: 9400\n",
      "current at batch: 9500\n",
      "current at batch: 9600\n",
      "current at batch: 9700\n",
      "current at batch: 9800\n",
      "current at batch: 9900\n",
      "current at batch: 10000\n",
      "current at batch: 10100\n",
      "current at batch: 10200\n",
      "current at batch: 10300\n",
      "current at batch: 10400\n",
      "current at batch: 10500\n",
      "current at batch: 10600\n",
      "current at batch: 10700\n",
      "current at batch: 10800\n",
      "current at batch: 10900\n",
      "current at batch: 11000\n",
      "current at batch: 11100\n",
      "current at batch: 11200\n",
      "current at batch: 11300\n",
      "current at batch: 11400\n",
      "current at batch: 11500\n",
      "current at batch: 11600\n",
      "current at batch: 11700\n",
      "current at batch: 11800\n",
      "current at batch: 11900\n",
      "current at batch: 12000\n",
      "current at batch: 12100\n",
      "current at batch: 12200\n",
      "current at batch: 12300\n",
      "current at batch: 12400\n",
      "current at batch: 12500\n",
      "current at batch: 12600\n",
      "current at batch: 12700\n",
      "current at batch: 12800\n",
      "current at batch: 12900\n",
      "current at batch: 13000\n",
      "current at batch: 13100\n",
      "current at batch: 13200\n",
      "current at batch: 13300\n",
      "current at batch: 13400\n",
      "current at batch: 13500\n",
      "current at batch: 13600\n",
      "current at batch: 13700\n",
      "current at batch: 13800\n",
      "current at batch: 13900\n",
      "current at batch: 14000\n",
      "current at batch: 14100\n",
      "current at batch: 14200\n",
      "current at batch: 14300\n",
      "current at batch: 14400\n",
      "current at batch: 14500\n",
      "current at batch: 14600\n",
      "current at batch: 14700\n",
      "current at batch: 14800\n",
      "current at batch: 14900\n",
      "current at batch: 15000\n",
      "current at batch: 15100\n",
      "current at batch: 15200\n",
      "current at batch: 15300\n",
      "current at batch: 15400\n",
      "current at batch: 15500\n",
      "current at batch: 15600\n",
      "current at batch: 15700\n",
      "current at batch: 15800\n",
      "current at batch: 15900\n",
      "current at batch: 16000\n",
      "current at batch: 16100\n",
      "current at batch: 16200\n",
      "current at batch: 16300\n",
      "current at batch: 16400\n",
      "current at batch: 16500\n",
      "current at batch: 16600\n",
      "current at batch: 16700\n",
      "current at batch: 16800\n",
      "current at batch: 16900\n",
      "current at batch: 17000\n",
      "current at batch: 17100\n",
      "current at batch: 17200\n",
      "current at batch: 17300\n",
      "current at batch: 17400\n",
      "current at batch: 17500\n",
      "current at batch: 17600\n",
      "current at batch: 17700\n",
      "current at batch: 17800\n",
      "current at batch: 17900\n",
      "current at batch: 18000\n",
      "current at batch: 18100\n",
      "current at batch: 18200\n",
      "current at batch: 18300\n",
      "current at batch: 18400\n",
      "current at batch: 18500\n",
      "current at batch: 18600\n",
      "current at batch: 18700\n",
      "current at batch: 18800\n"
     ]
    }
   ],
   "source": [
    "history = Writer()\n",
    "for A in net.parameters():\n",
    "    A.requires_grad = False\n",
    "n = 18846\n",
    "for i in range(n):\n",
    "    if (i+1)%100 == 0:\n",
    "        print('current at batch:', i+1)\n",
    "    total_data = dataset[i]\n",
    "    inputs,label = total_data\n",
    "    S_lst = net(inputs)\n",
    "    S = S_lst[-1] \n",
    "    history.add_tensor('S', S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = history.get('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18846, 20])\n"
     ]
    }
   ],
   "source": [
    "S1 = torch.cat(S,0)\n",
    "print(S1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_np = S1.numpy()\n",
    "inv_S = np.linalg.pinv(S_np)\n",
    "Y_sub = Y[0:n,:]\n",
    "Y_pred = S_np@(inv_S@Y_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6938342353815133"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.argmax(Y_pred,1) == np.argmax(Y_sub,1))/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
